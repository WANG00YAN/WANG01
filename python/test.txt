1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onthe web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS825Fig. 1. Question answering over RDF dataset.(cid:1)(cid:1)! and u2u3Speciﬁcally, we resolve the ambiguity of natural language
questions at the time when matches of query are found. The
cost of disambiguation is saved if there is no match found.
We call this as the graph data-driven approach for RDF Q/A.
We illustrate the intuition of our method by an example.
Example 1. Consider a subgraph of graph G in Fig. 1a (the
(cid:1)(cid:1)!
subgraph induced by vertices u1, u2, u3 and c1). Edge u2c1
(cid:1)(cid:1)!
says that “Resident Evil: Retribution is a ﬁlm”. Edge u2u1
says that “The budget of Resident Evil: Retribution is $ 65
(cid:1)(cid:1)! says that “Paul W. S. Anderson directed
million”. Edge u2u3
the ﬁlm Resident Evil: Retribution”. The natural language
question N1 is “What is the budget of the ﬁlm directed by
Paul Anderson”. Obviously, the subgraph formed by edges
(cid:1)(cid:1)! is a match of N1. “6.5E7” is a correct
(cid:1)(cid:1)!, u2u1
u2c1
answer. On the other hand, we cannot ﬁnd a match (of N1)
containing h Paul_Anderson_(actor)i inc G, i.e., the phrase
“Paul Anderson” (in N1) cannot map to hPaul_Anderson_
(actor)i. Therefore, we address the ambiguity issue of
phrase linking when the matches are found. We can also
resolve the ambiguity of query graph structure following
the same idea. More details will be discussed in Section 5.
The above example illustrates the intuition of our graph
data-driven approach. A fundamental issue in our method
is how to deﬁne a “match” between a subgraph of G and a
natural language question N. Because N is unstructured
data and G is graph structure data, we should ﬁll the gap
between them. Therefore, we propose a semantic query
graph QS (deﬁned in Deﬁnition 1) to represent the question
semantics of N. An example of QS is given in Fig. 1c, which
represents the semantic of the question N. Answering natu-
ral language question equals to ﬁnding matches of QS over
the underlying RDF graph G. To build QS, we propose two
different frameworks: relation (edge)-ﬁrst and node-ﬁrst.1.2 Our Approach
Although there are still
two stages “question under-
standing” and “query evaluation” in our method, we do notgenerate SPARQL at the question understanding step as
existing solutions do. As we know, a SPARQL query can
also be represented as a query graph, which does not
include any ambiguity. Instead, our method builds a query
graph that represents users’ query intention, but it allows
for the ambiguity at the question understanding stage, such
as the ambiguity of phrase linking and query graph struc-
ture. We resolve the ambiguity when the matches are found
at the query evaluation.In the ﬁrst framework, we ﬁrst extract semantic relations
based on the dependency tree structure of question senten-
ces to build a semantic query graph QS. A semantic relation
is a triple hrel; arg1; arg2i, where rel is a relation phrase, and
arg1 and arg2 are its associated node phrases. For instance,
h“directed by”,“ﬁlm”,“Paul Anderson”i is a semantic rela-
tion. In QS, two edges share one common endpoint if the
two corresponding relations share one common node
phrase. Each node (entity/class mention) and edge (relation
mention) in QS may have multiple candidates. The ﬁrst
framework addresses the ambiguity of phrase linking when
the matches (see Deﬁnition 2) of QS are found. Note that the
ﬁrst framework does not address the ambiguity of query
graph’s structure and assumes that the query graph can be
uniquely ﬁxed at the question understanding step.The second framework takes another perspective. When
there exist some implicit or uncertain relations in N, the
relation-ﬁrst framework often fails to extract such relations.
Therefore, the second framework starts with extracting
nodes from the question sentence N and connects these
nodes to form a query graph. Furthermore, different from
the relation-ﬁrst
framework
allows for the ambiguity of query graph structure at the
beginning. It does not intend to build QS in the question
understanding step. Instead, it builds a super graph QU of
QS that includes uncertain edges. To match QU over the
underlying RDF graph G, we allow for mismatching some
edges in QU ,
i.e., approximate match (Deﬁnition 5). Wethe node-ﬁrstframework,826IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 1
NotationsNotationGðV; EÞ
N
Q
QS
QU
Y
DE=DR
vi/ui
Cvi /CvivjDeﬁnition and DescriptionRDF graph and vertex and edge sets
A natural language question
A SPARQL query (of N)
The Semantic Query Graph (of N)
The Super Semantic Query Graph (of N)
The dependency tree (of N)
The entity/relation mention dictionary
A vertex in query graph / RDF graph
Candidate mappings of vertex vi / edge vivjresolve the ambiguity of phrase linking and query graph
structure together when the approximate matches are
found. Actually, the approximate matching position (in
RDF graph G) deﬁnes the semantic query graph QS that we
aim to build. In other words, we push down resolving the
ambiguity of QS’s structure to the query evaluation stage.
In a nutshell, we make the following contribution.In the ﬁrst(1) We propose two graph data-driven frameworks for
RDF Q/A task, different from exiting solutions, in
which the disambiguation and query evaluation are
combined together.
framework, we
address ambiguity of phrase linking at the query
evaluation; while in the second framework,
the
ambiguity of phrase linking and query graph’s struc-
ture are both resolved. The graph data-driven frame-
works not only improve the precision but also speed
up query processing time greatly.
In the ofﬂine processing, we propose a graph mining
algorithm to build a relation mention dictionary, i.e.,
mapping natural language phrases to possible predi-
cates, which is used for question understanding in
RDF Q/A.
In the online processing, in order to speed up query
evaluation, we propose efﬁcient top-k (approximate)
graph matching algorithms of matching QS and QU
over RDF graph.(3)(2)(4) We conduct extensive experiments over several real
RDF datasets (including QALD benchmark and
WebQuestions benchmark) and compare our system
with some state-of-the-art systems. The performance
of our approach beat the other systems on QALD
benchmark while close to the best on the WebQues-
tions benchmark.2 OVERVIEWThe problem of this paper is to ﬁnd the answers to a natural
language question N over a RDF graph G. Table 1 lists the
notations used throughout this paper.There are two key issues in RDF Q/A problem. The ﬁrst
one is how to represent the query intention of the natural lan-
guage question N in a structural way. The second one is how
to address the ambiguity of natural language N. In this paper,
we focus on the ambiguity of phrase linking and query graph
structure (composition) that are mentioned in Section 1.1.2.1 Semantic Query Graph
We deﬁne a semantic query graph (Deﬁnition 1) to repre-
sent the query intention of the question N in a graph struc-
tured way.Deﬁnition 1 (Semantic Query Graph). A semantic query
graph (denoted as QS) is a graph, in which each vertex vi is
associated with an entity phrase, class phrase or wild-cards in
the question sentence N; and each edge vivj is associated with a
relation phrase in the question sentence N, 1 (cid:3) i; j (cid:3) jV ðQSÞj.1 is given in Fig. 2b. In QSGiven the question sentences N1, the corresponding
semantic query graphs QS
1 , nodes
v1, v2 and v3 are associated with “what” (wild-card), “ﬁlm”
(a class phrase) and “Paul Anderson” (an entity phrase),
respectively. The relation phrase “(be) budget of ” denotes
the relation between v1 and v2, as well as the relation phrase
“directed by” between v2 and v3.As mentioned in the introduction, we want to ﬁnd a
“match” of the semantic query graph QS over RDF graph G.
When the matches are found, we resolve the ambiguity of
natural language question sentence; meanwhile we ﬁnd the
answers to the question. Generally, a “match” is deﬁned
based on subgraph isomorphism. Given a node vi
in a
semantic query graph QS, if vi is an entity phrase or a class
phrase, we can use entity linking algorithm [5] to retrieve all
entity/class (in RDF graph G) that possibly correspond to vi,
denoted as CðviÞ; if vi is a wild-card (such as wh-word), we
assume that CðviÞ contains all vertices in RDF graph G. Anal-
ogously, each edge vivj in QS also maps to a list of candidate
predicates, denoted as Cvivj . Consider the semantic query
graph QS in Fig. 2b. We also visualizes the candidates
for each vertex and edge in QS in Fig. 2c. For example, v3
(“Paul Anderson”) corresponds to hPaul_Anderson_(actor)i,
hPaul_S._Andersoni and hPaul_W._S._Andersoni; and edge
“v2v3” maps to hdirectori, hwriteri and hproduceri. Formally,
we deﬁne the match as follows.
Deﬁnition 2 (Match). Consider a semantic query graph QS
with n nodes fv1; . . . ; vng. Each node vi has a candidate list
Cvi , i ¼ 1; . . . ; n. Each edge vivj also has a candidate list Cvivj ,
where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph M containing n vertices
fu1; . . . ; ung in RDF graph G is a match of QS if and only if
the following conditions hold:(1)(2)(3)If vi is mapping to an entity ui, i ¼ 1; . . . ; n, ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n, ui is an
entity whose type is ci (i.e., there is a triple hui rdf:type
cii in RDF graph) and ci must be in Cvi ; and
(cid:1)(cid:1)! 2 M. Furthermore,
8vivj 2 QS , uiuj
(cid:1)(cid:1)!) is in
(cid:1)(cid:1)! (or ujui
the predicate Pij associated with uiuj
Cvivj , 1 (cid:3) i; j (cid:3) n.(cid:1)(cid:1)! 2 M _ ujuiLet us see Fig. 2. The subgraph included by vertices c1, u1,
u2 and u3 (in RDF graph G) denotes a match of semantic query
graph QS in Fig. 2b. When the matches are found, we resolve
the ambiguity, e.g., “Paul Anderson” should refer to hPaul_W.
_S._Andersoni rather than others., meanwhile that we ﬁnd the
answers to the question, i.e., “6.5E7”1 is the ﬁlm budget.The core of our graph data-driven solution lies in two
aspects: one is how to build a semantic query graph QS accu-
rately and the other one is how to ﬁnd matches efﬁciently. In
order to address the above issues, we propose two different
frameworks. The ﬁrst one is called “relation (edge)-ﬁrst”. It
means that we always extract relations from the natural lan-
guage question sentence N and represent them as edges.
Then, we assemble these edges to form a semantic query1. Sixty-ﬁve millionHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS827Fig. 2. Question answering with semantic query graph in relation-ﬁrst framework.graph. The second framework takes another perspective,
called “node-ﬁrst”. It starts with ﬁnding nodes (entity/class
phrases and wild-cards) and try to introduce edges to con-
nect them to form a semantic query graph QS. Furthermore,
another major difference between the two frameworks is
that the node-ﬁrst framework deﬁnes a super graph (called
QU ) of QS when there exist some implicit or uncertain rela-
tions in the question sentence. In other words, the node-ﬁrst
framework is not to ﬁx the QS’s structure before subgraph
matching evaluation as the relation-ﬁrst framework does.2.2 Relation-First Framework
Given a natural language question sentence N, the relation-
ﬁrst framework begins with extracting semantic relations
(edge together with two end points) from N.
Deﬁnition 3 (Semantic Relation). A semantic relation is a
triple hrel; arg1; arg2i, where rel is a relation mention, arg1
and arg2 are the two node phrases.In the running example, h“directed by”, “ﬁlm”,“Paul
Anderson”i is a semantic relation, in which “directed by” is a
relation mention (phrase), “who” and “actor” are its associ-
ated node phrases. We can also ﬁnd another semantic relation
h“budget of”, “what”,“ﬁlm”i from the question sentence N1.2.2.1 Question Understanding
The goal of the question understanding in the ﬁrst frame-
work is to build a semantic query graph QS for representing
users’ query intention in N. Speciﬁcally, we ﬁrst extract all
semantic relations in N, each of which corresponds to an
edge in QS. The semantic relation extraction is based on the
dependency tree of users’ question sentence and a relation
mention dictionary (see more details in Section 4.1). If the
two semantic relations have one common node, they share
one endpoint in QS. In the running example, we get two
semantic relations, i.e., h“directed by”, “ﬁlm”,“Paul Ander-
son”i and h“budget of”, “what”,“ﬁlm”i, as shown in Fig. 2.
They can be combined through the common node phrase
“ﬁlm” as showed in Fig. 2c. In addition, if two node phrasesrefer to same thing after “coreference resolution” [6], we
also combine the corresponding two semantic relations.2.2.2 Query Executing
As mentioned earlier, a semantic query graph QS is a
structural representation of N. In order to answer N, we
need to ﬁnd subgraphs of RDF graph G that match QS. The
match is deﬁned according to the subgraph isomorphism
(see Deﬁnition 2)Each subgraph match has a score, which is derived from
the conﬁdences of each edge and vertex mapping. Deﬁnition
8 deﬁnes the score, which we will discuss later. Our goal is to
ﬁnd all subgraph matches with the top-k scores. A best-ﬁrst
algorithm is proposed in Section 4.2 to address this issue.
Each subgraph match of QS implies an answer to the natural
language question N, meanwhile, the ambiguity is resolved.2.3 Node-First Framework
The relation-ﬁrst framework has two main obstacles. The
ﬁrst is that some relations are difﬁcult to be extracted. If the
relation does not explicitly appeared in the question sen-
tence, it is difﬁcult to extract such semantic relations, since
our relation extraction relies on the relation mention in the
relation mention dictionary. Let us consider two examples
“show me all ﬁlms started by a Chinese actor”, “show me all
ﬁlms stared by an actor who was born in China”. Obviously,
the latter question has one explicit relation mention “(be)
born in”, where the relation in the former one is implicitly
mentioned. Therefore, it is difﬁcult to extract these implicit
relations. Second, in the relation-ﬁrst framework, semantic
relation extraction relies on the syntactic dependency tree of
users’ question sentence and heuristic linguistic rules. If the
syntactic dependency tree has some mistakes, it inevitably
leads to wrong semantic query graph QS’s structure and
wrong answers.Considering the above two obstacles, we design a robust
framework even in the presence of implicit relations and
mistakes in the dependency parse tree. There are two key
points in the second framework:828IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Fig. 3. Question answering with super semantic query graph in node-ﬁrst framework.(1)The ﬁrst step is to extract node phrases (such as
entity phrase, class phrase and wh-words) from the
question sentence N, instead of relation extraction in
the ﬁrst framework.(2) We do not intend to build a semantic query graph QS
at the question understanding step. Instead, we build
a super semantic query graph QU , which possibly has
some uncertain or implicit relations (i.e., edges). In
other words, we allows the structure ambiguity of
query graph in the question understanding step,
which will be resolved at the query evaluation step.
A super semantic query graph QU is analogue to QS (see Deﬁ-
nition 4), but allows for explicit or uncertain relations (edges).
Deﬁnition 4 (Super Semantic Query Graph). A super
semantic query graph (denoted as QU ) is a graph, in which
each vertex vi is associated with an entity phrase, class phrase or
wild-card in the question sentence N; and each edge vivj is asso-
ciated with a relation in N, 1 (cid:3) i; j (cid:3) jV ðQU Þj. If the relation is
explicit, the edge label is the relation mention occurring in N;
otherwise, the edge label is empty when the relation is implicit.The following example illustrates the intuition of the sec-ond framework.
Example 2. Consider N2 in Fig. 3. “What is the budget of the
ﬁlm directed by Paul Anderson and starred by a Chinese
actor?”. The correct SPARQL query of N2 has two addi-
tional triples than N1, which are t1 ¼ h?ﬁlm,starring, ?actori
and t2 ¼ h?actor, country,Chinai. The relation-ﬁrst frame-
work cannot generate t2 because the predicate “country”
has no explicit relation mention in N2. In the node-ﬁrst
framework, we introduce an edge between v4 (“actor”) and
v5 (“Chinese”) in Fig. 3b, whose edge label is empty. For
detected relation mention “starred by”, it is difﬁcult to
determine its corresponding two nodes. There are three can-
didate nodes: “Paul Anderson”, “ﬁlm”, and “actor”. In QU ,
we introduce two edges between “ﬁlm” and “actor”; and
“Paul Anderson” and “actor”. In the query evaluation step,
we perform the approximate match (deﬁned in Deﬁnition 5)
to match QU with RDF graph G, i.e., ﬁnding the occurrences
of QU in RDF graph G with (possible) mismatching edges.In this example, the ﬁnal match is denoted using bold lines
in Fig. 3, in which the edge between “Paul Anderson” and
“actor” (in QU ) is not matched.
It is easy to infer that an approximate match of QU equals to
an exact match of a connected spanning subgraph2 of QU ,
where the spanning subgraph is the semantic query graph
QS that we aim to build. Therefore, in the second framework,
we ﬁx the semantic query graph QS when the matches are
found; meanwhile the answers to the question have been
found. In other words, we resolve the “structure ambiguity”
of query graph at the time the matches are found. We also
brieﬂy discuss the two steps of the node-ﬁrst framework as
follows. More technical details are given in Section 5.2.3.1 Question Understanding
Given a natural language question sentence N, we ﬁrst
extract all constant nodes from N by applying entity extrac-
tion algorithms, which are referred to entities or classes. We
also extract all wh-words (such as who, what and which
et al.) from N as variable nodes. Then, to build QU , we need
to introduce an edge between two nodes if there is a seman-
tic relation between them. A naive solution is to introduce
an edge between any two nodes. Obviously, this method
introduces more noises and ambiguity for the query graph’s
structure. On the other hand, the approximate match in the
node-ﬁrst framework allows mis-matching one or more
edges in QU . The naive solution leads to Oð2nÞ possible
matching structures in the ﬁnal evaluation step, where n is
the number of nodes in QU . This is quite costly.To eliminate more noises and reduce the search space,we propose a simple yet effective assumption:
Assumption 1. Two nodes v1 and v2 has a semantic relation if
and only if there exists no other node v(cid:4) that occurs in the sim-
ple path between v1 and v2 of the dependency parse tree of ques-
tion sentence N.2. A spanning subgraph for graph Q is a subgraph of Q which con-tains every vertex of Q.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS829Although this method also depends on the dependency
parse tree, it is not like the ﬁrst framework, in which,
extracting semantic relations and node phrases (to build
QS) heavily depend on the parse tree’s structure, POS tag3
and dependency relation (such as subj, obj and et al.)4 In
other words, the node-ﬁrst framework (i.e., the second
framework) is more robust to dependency errors.Let us recall Example 2. We ﬁrst extract ﬁve nodes:
“what”, “ﬁlm”, “Paul Anderson”, “Chinese”, “actor” from
the question N2. Fig. 5 illustrates the dependency parse tree
Y ðN2Þ of question sentence N2. According to the assumption,
we introduce an edge v1v2 between two nodes v1 and v2 if
there is no other node v(cid:4) in the simple path between v1 and v2
over Y ðN2Þ. The words along the simple path between v1
and v2 form the edge label of v1v2. For example, the edge
label between nodes “what” and “ﬁlm” is “ (be) budget of”.
The edge label between nodes “Chinese” and “node” is
empty, which is the implicit relation. For nodes “Paul Ander-
son” and “actor”, there is no other nodes along the simple
path between them. According to Assumption 1, we intro-
duce an edge between them and the edge label is “directed
by started by”. Due to the same reason, there is another edge
between nodes “ﬁlm” and “actor”. Finally, we obtain the
super semantic query graph QU as shown in Fig. 3b.2.3.2 Query Executing
First, we ﬁnd candidates for each node and edge in QU ,
which is analogue to the query evaluation of QS in the ﬁrst
framework. According to the entity mention dictionary DE,
for each node, we can obtain a list of candidate entities, clas-
ses. If it is a wh-word, we assume that it can map all vertices
in RDF graph G. For each edge label (i.e., the relation men-
tion relv1v2 ), we also map it to all possible candidate predi-
cates based on the relation mention dictionary DR. If the
edge label relv1v2
is empty, e.g., the edge label between
nodes “Chinese” and “actor” is empty, we generate candi-
date predicates by applying a data mining method on G.
Section 4.1.3 gives more technical details.Then, based on the data-driven’s idea, we try to match QU
over RDF graph G. Different from the exact match of QS, in
the node-ﬁrst framework, we deﬁne the approximate match
(allowing dis-matching edges) of super semantic query
graph QU as follows:
Deﬁnition 5 (Approximate Match). Consider a super
semantic query graph QU with n vertices v1; . . . ; vn. Each ver-
tex vi has a candidate list Cvi , i ¼ 1; . . . ; n. Each edge vivj also
has a candidate list of Cvivj , where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph
M containing n vertices u1; . . . ; un in RDF graph G is an
approximate match of QU if and only if the following condi-
tions hold:1.2.If vi is mapping to an entity ui, i ¼ 1; . . . ; n; ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n; ui is an
is a triple
entity whosethereis ci(i.e.,type3. It is called part-of-speech tag, also grammatical tagging or word-
category disambiguation, which is the process of marking up a word in
a text (corpus) as corresponding to a particular part of speech, such as
nouns, verbs, adjectives, adverbs, etc.4. These grammatical relationships (called dependencies) that are
deﬁned in [7]. For example, “nsubj” refers to a nominal subject. It is a
noun phrase which is the syntactic subject of a clause.TABLE 2
Entity Mention Dictionary DEEntity MentionReferring Entity“Paul Anderson”
“Paul Anderson”
“USA”
“America”
. . .. . .hPaul_S._Andersoni
hPaul_W._S._Andersoni
hUnited_Statesi
hUnited_Statesi
. . .. . .Conﬁdence
Probability
0.8
0.6
1.0
1.0
. . .. . .huirdf : typecii in RDF graph) and ci must be in Cvi ;
and
(cid:1)(cid:1)! 2 M ) vivj 2 QU . Furthermore, the predicate
8uiuj
Pij associated with uiuj(cid:1)(cid:1)! is in Cvivj , 1 (cid:3) i; j (cid:3) n.3.The only difference between the approximate match and
match is item (3) of Deﬁnitions 2 and 5: some edges of QU
may not be matched. Let us recall Example 2. The ﬁnal
approximate match is denoted by the bold lines in Fig. 3d.
The edge between node “Paul Anderson” and “actor” (in
QU ) is not matched. The approximate match is used to
address the ambiguity of the query graph’s structure.3 OFFLINE PHASEIn the ofﬂine phase, we build two dictionaries, which are
entity mention dictionary DE and relation mention dictio-
nary DR. They will be used to extract entities and relations
from users’ question sentences in the online phase. Note
that both DE and DR are used in our two frameworks (rela-
tion-ﬁrst framework and node-ﬁrst framework).3.1 Build Entity Mention Dictionary
An entity mention is a surface string that refers to entities.
For example, “Paul Anderson” could refer to the person
hPaul_W._S._Andersoni or hPaul_S._Andersoni. We need to
build an entity mention dictionary DE, such as Table 2, to
map entity mentions to some candidate entities with
conﬁdence probabilities. There are lots of existing work
about entity-mention dictionary construction [8], [9] and the
dictionary-based entity linking [5], [10]. A popular way to
build such a dictionary DE is by crawling Web pages and
aggregating anchor links that point to Wikipedia entity
pages. The frequency with which a mention (anchor text),
m, links to a particular entity (anchor link), c, allows one to
estimate the conditional probability pðcjmÞ [8]. Entity-men-
tion dictionary construction is not our technical contribu-
tion, in this paper, we adopt CrossWikis dictionary [8],
which was computed from a Google crawler of the Web.
The dictionary contains more than 175 million unique
strings with the entities they may represent.3.2 Build Relation Mention Dictionary
A relation mention is a surface string that occurs between a
pair of entities in a sentence [11], such as “be directed by” and
“budget of” in the running example. We need to build a rela-
tion mention dictionary DR, such as Table 4, to map relation
mentions to some candidate predicates or predicate paths.In this paper, we do not discuss how to extract relation
mentions along with their corresponding entity pairs. Lots
of NLP literature about relation extraction study this prob-
lem, such as Patty [12] and ReVerb [13]. For example, Patty
[12] utilizes the dependency structure in sentences and830IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 3
Relation Mentions and Supporting Entity PairsTABLE 4
Relation Mention Dictionary DRRelation Mention“directed by”“uncle of”Supporting Entity Pairs(hResident_Evili, hPaul_W._S._Andersoni),
(hRoman_Holidayi, hWilliam_Wyleri),. . .. . .
(hTed_Kennedyi, hJohn_F._Kennedy,_Jr.i)
(hPeter_Corri, hJim_Corri),. . .. . .ReVerb [13] adopts the n-gram to ﬁnd relation mentions and
the corresponding support set. In this work, we assume that
the relation mentions and their support sets are given. For
example, Table 3 shows two sample relation mentions and
their supporting entity pairs.Suppose that we have a mention set T ¼ frel1; . . . ; relng,
where each reli is a relation mention, i ¼ 1; . . . ; n. Each reli
has a support set of entity pairs that occur in RDF graph,
i.e., Sup ðreliÞ ¼ f ðv1
i Þ; . . . ; ðvm
i Þg. For each reli,
i ¼ 1; . . . ; n, the goal is to mine top-k possible predicates or
predicate paths formed by consecutive predicate edges in
RDF graph, which have semantic equivalence with relation
mention reli.i ; v0mi ; v01Given a relation mention reli, considering each pair
i Þ in Sup ðreliÞ, we ﬁnd all simple paths between vj
i; v0j
ðvj
i
and v0j
i Þ. Let
i
PSðreliÞ ¼ fPathsðvjin RDF graph G, denoted as Pathsðvj
i Þj1 (cid:3) j (cid:3) mg.i ; v0ji; v0jFor efﬁciency considerations, we only ﬁnd simple paths
with no longer than a threshold5. We adopt a bi-directional
BFS (breath-ﬁrst-search) search from vertices vj
to
ﬁnd Pathsðvj
i ; v0j
i Þ. Note that we ignore edge directions (in
RDF graph) in a BFS process.i and v0jiIntuitively, if a predicate path is frequent in PSðreliÞ, it is
a good candidate that has semantic equivalence with rela-
tion mention reli. However, the above simple intuition may
introduce noises. For example, we ﬁnd that (hasGender,
hasGender) is the most frequent predicate path in PS
(“uncle of”). Obviously, it is not a good predicate path to
represent the semantic of relation mention “uncle of”. In
order to eliminate noises, we borrow the intuition of tf-idf
measure [14]. Although (hasGender, hasGender) is frequent
in PS (“uncle of”), it is also frequent in the path sets of other
relation mentions, such as PS (“is parent of”), PS (“is advi-
sor of”) and so on. Thus, (hasGender, hasGender) is not an
important feature for PS (“uncle of”). Formally, we deﬁne tf-
idf value of a predicate path L in the following deﬁnition.
Note that if L is a length-1 predicate path, L is a predicate P .
Deﬁnition 6. Given a predicate path L, the tf-value of L inPSðreliÞ is deﬁned as follows:tfðL; PSðreliÞÞ ¼jfPathsðvji; v0j
Pathsðvji ÞjL 2 Pathsðvj
i; v0ji Þ 2 PSðreliÞgji; v0j
i Þ;The idf-value of L over the whole relation mention setT ¼ frel1; . . . ; relng is deﬁned as follows:idfðL; T Þ ¼ logjT j
jfreli 2 T jL 2 PSðreliÞgj þ 15. We set the threshold as four in our experiments. More details
about the parameter setting will be discussed in Appendix B, available
in the online supplemental material.The tf-idf value of L is deﬁned as follows:tf(cid:5)idfðL; PSðreliÞ; T Þ ¼ tfðL; PSðreliÞÞ (cid:6) idfðL; T ÞWe deﬁne the conﬁdence probability of mapping relationmention rel to predicate or predicate path L as follows.dðrel; LÞ ¼ tf(cid:5)idfðL; PSðreliÞ; T Þ(1)Algorithm 1 in Appendix A, which can be found on
the Computer Society Digital Library at http://doi.
ieeecomputersociety.org/10.1109/TKDE.2017.2766634,
shows the details of ﬁnding top-k predicate paths for
each relation mention. All relation mentions and their corre-
sponding k predicate paths including tf-idf values are col-
lected to form a relation mention dictionary DR.4 RELATION-FIRST FRAMEWORK
4.1 Building Semantic Query Graph
This Section discusses how to identify semantic relations
in a natural language question N, based on which, we build
a semantic query graph QS to represent the query intention
in N.In order to extract the semantic relations in N, we need to
identify the relation mentions in question N. Obviously, we
can simply regard N as a sequence of words. The problem
is to ﬁnd which relation phrases (also regarded as a
sequence of words) are subsequences of N. However, the
ordering of words in a natural language sentence is not
ﬁxed, such as inverted sentences and preposition fronting. For
example, consider a question “In which movies did Li Bingb-
ing star?”. Obviously, “star in” is a relation mention though
it is not a subsequence of N. The phenomenon is known as
“long-distance dependency”. Some NLP (natural language
processing) literature suggest that the dependency structure
is more stable for the relation extraction [12].Therefore, in our work, we ﬁrst apply Stanford Parser [7]
to N to obtain the dependency tree Y . Let us recall the run-
ning example. Fig. 4 shows the dependency tree of N1,
denoted as Y ðN1Þ. The next question is to ﬁnd relation men-
tions occurring in Y ðN1Þ.
Deﬁnition 7. Let us consider a dependency tree Y of a natural
language question N and a relation mention rel. We say that
rel occurs in Y if and only if there exists a connected subtree y
(of Y ) satisfying the following conditions:(1)Each node in y contains one word in rel and y includes
all words in rel.(2) We cannot ﬁnd a subtree y0 of Y , where y0 also satisﬁesthe ﬁrst condition and y is a subtree of y0.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS831Fig. 4. Relationship extraction in Y ðN1Þ.In this case, y is an embedding of relation mention rel in Y .Given a dependency tree Y of a natural language question
N and a relation mention set T ¼ frel1; . . . ; relng, we need to
ﬁnd which relation mentions (in T ) are occurring in Y .4.1.1 Relation Recognition
Given a natural language question N, we propose an algo-
rithm (Algorithm 2 in Appendix A, available in the online sup-
plemental material) to identify all relation mentions in N. In
the ofﬂine phase, we build an inverted index over all relation
mentions in the relation mention dictionary DR. Speciﬁcally,
for each word, it links to a list of relation mentions containing
the word. The basic idea of Algorithm 2 is as follows: For each
node (i.e., a word) wi in Y , we ﬁnd the candidate pattern list
PLi (Lines 1-2). Then, for each node wi, we check whether
there exists a subtree rooted at wi including all words of some
relation mentions in PLi. In order to address this issue, we
propose a depth-ﬁrst search strategy. We probe each path
rooted at wi (Line 3). The search branch stops at a node w0,
where there does not exists a relation mention including w0
and all words along the path between w0 and wi (Note that, w0
is a descendant node of wi.)(Lines 3-4 in Probe function.) We
utilize rel½w(cid:7) to indicate the presence of word w of rel in the
subtree rooted at wi (Line 6). When we ﬁnish all search
branches, if rel½w(cid:7) ¼ 1 for all words w in relation mention rel,
it means that we have found a relation mention rel occurring
in Y and the embedding subtree is rooted at wi (Lines 8-11).
We can ﬁnd the exact embedding (i.e., the subtree) by probing
the paths rooted at wi. We omit the trivial details due to the
space limit. The time complexity of Algorithm 2 is OðjY j2Þ.4.1.2 Finding Associated Nodes
After ﬁnding a relation mention in Y , we then look for the
two associated nodes. If a phrase was recognized as entity/
class mention, it is regarded as a node. Besides, the nodes
are recognized also based on the grammatical subject-like
and object-like relations around the embedding, which are
listed as follow:(1)(2)subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
object-like relations: obj, pobj, dobj, iobjAssume that we ﬁnd an embedding subtree y of a rela-
tion mention rel. We recognize arg1 by checking for each
phrase w in y whether w is an entity/class mention or there
exists the above subject-like relations (by checking the edge
labels in the dependency tree) between w and one of itsFig. 5. Building super semantic query graph.children (note that, the child is not in the embedding sub-
tree). If a subject-like relationship exists, we add the child to
arg1. Likewise, arg2 is recognized by the object-like rela-
tions. When there are still more than one candidates for
each node, we choose the nearest one to rel.On the other hand, when arg1/arg2 is empty after this
step, we introduce several heuristic rules (based some
computational linguistics knowledge [3], [7]) to increase the
recall for ﬁnding nodes. The heuristic rules are applied until
arg1/arg2 becomes none empty.(cid:2) Rule 1: Extend the embedding t with some lightwords, such as prepositions, auxiliaries.(cid:2) Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.(cid:2) Rule 3: If the parent of the root node of t has subject-
like relations with its neighbors, add the child to arg1.
(cid:2) Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the ﬁrst noun phrase in t to arg1/arg2.
If we still cannot ﬁnd node phrases arg1/arg2 after
applying the above heuristical rules, we just discard the
relation mention rel in the further consideration. Finally, we
can ﬁnd all relation mentions occurring in N together with
their embeddings and their node phrases arg1/arg2.
Example 3. Let us recall dependency tree Y in Fig. 4. We get
“what” as the ﬁrst node of relation mention “budget of”
by applying Rule 4. And we can ﬁnd another node “ﬁlm”
as it is a class mention. Therefore, the ﬁrst semantic rela-
tion is h“budget of”, “what”, “ﬁlm”i. Likewise, we can
also ﬁnd another semantic relation h“direct by”, “ﬁlm”,
“Paul Anderson”i.After obtaining all semantic relations in a natural lan-
guage N, we need to build a semantic query graph QS.
Fig. 2b shows an example of QS. In order to build a semantic
query graph QS, we represent each semantic relation
hrel; arg1; arg2i as an edge. Two edges share one common
endpoint if their corresponding semantic relations have one
common node phrase. The formal deﬁnition of a semantic
query graph has been given in Deﬁnition 1.4.1.3 Phrases Mapping
In this Section, we discuss how to map the relation mentions
and node phrases to candidate predicates/predicate paths
and entities/classes, respectively.832IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Mapping Edges of QS. Each edge vivj in QS has a relation
mention relvivj . According to the relation mention dictionary
DR (see Section 3.2), it is straightforward to map relvivj to
some predicates P or predicate paths L. The list is denoted
as Cvivj . For simplicity of notations, we use L in the follow-
ing discussion. Each mapping is associated with a conﬁ-
dence probability dðrel; LÞ (deﬁned in Equation (1)). For
example, edge v2v3 has a relation mention relv2v3 = “direct
Its candidate list Cv2v3 contains three candidates,
by”.
hdirectori, hwriteri, and hproduceri, as shown in Fig. 2c.Mapping Vertices of QS. Let us consider any vertex v in QS.
The phrase associated with v is arg. If arg is a wild-card
(such as wh-word), it can be mapped to all vertices in RDF
graph G. Otherwise, given an constant arg (entity/class
mention), we adopt the dictionary-based entity linking
approach [5] to ﬁnd the candidate entities or classes. We use
notation Cv to denote all candidates with regard to vertex v
in QS. For example, “ﬁlm” in v2 (in Fig. 2) can be linked to a
class node hﬁlmi or an entity node hFilmexi. If arg is
mapped to an entity u or a class c, we use dðarg; uÞ or
dðarg; cÞ to denote the conﬁdence probability.4.2 Query Executing
Given a semantic query graph QS, we discuss how to ﬁnd
top-k subgraph matches over RDF graph G in this Section.
The formal deﬁnition of a subgraph match is given in Deﬁ-
nition 2. We assume that all candidate lists are ranked in the
non-ascending order of the conﬁdence probability. Figs. 2b
and 2c show an example of QS and the candidate lists,
respectively. Each subgraph match of QS has a score. It is
computed from the conﬁdence probabilities of each edge
and vertex mapping. The score is deﬁned as follows.
Deﬁnition 8. Given a semantic query graph QS with n nodes
fv1; . . . ; vng, a subgraph M containing n vertices fu1; . . . ; ung
in RDF graph G is a match of QS. The match score is deﬁned
as follows:ScoreðMÞ ¼ alog ðdðargi; uiÞÞXvi2V ðQS Þ
Xþ ð1 (cid:5) aÞvivj2EðQS Þlog ðdðrelvivj ; PijÞÞ(2)where argi is the phrase of vertex vi, and ui is an entity or a
class in RDF graph G, and relvivj is the relation mention of
edge vivj and Pij is a predicate of edge uiuj
The default value of weight a is 0.5, which means the entity
score and relation score have equivalent status. If we have
enough training data, a can be learned by some ranking mod-
els such as SVM-rank [15]. Details can be found in Section 6.(cid:1)(cid:1)!.
(cid:1)(cid:1)! or ujuiGiven a semantic query graph QS, our goal is to ﬁnd all sub-
graph matches of QS (over RDF graph G) with the top-k match
scores.6 To solve this problem, we designed an enumerative
algorithm (Algorithm 3 in Appendix A, available in the online
supplemental material) with two main pruning methods.The ﬁrst pruning method is to reduce the candidates of
each list (i.e, Cvi and Cvivj ) as many as possible. If a vertex ui
in Cvi cannot be in any subgraph match of QS, ui can be ﬁl-
tered out directly. Let us recall Fig. 2. Vertex u5 is a candi-
date in Cv3 . However, u5 does not have an adjacent
predicate that is mapping to phrase “direct by” in edge v2v3.6. Note that if more than one match have the identical score in the
top-k results, they are only counted once. In other words, we may
return more than k matches if some matches share the same scoreIt means that there exists no subgraph match of QS contain-
ing u5. Therefore, u5 can be pruned safely. This is called
neighborhood-based pruning. It is often used in subgraph
search problem, such as [16].The second method is to stop the search process based on
the top-k match score as early as possible. Obviously, enu-
merating all possible combination is inefﬁcient. If we main-
tain an appropriate enumeration order so that the current
matches are always better than undiscovered matches, we
can terminate the search space as early as possible. The
pseudo codes are given in Algorithm 3 in Appendix A, avail-
able in the online supplemental material. For ease of presen-
tation, we use “candidate list” to symbol relation candidate
list and entity/class candidate list together. Once we deter-
mine a candidate for each candidate list in QS, we obtain a
“selection”. The selection is expressed by a n-length vector,
which n is the total number of candidate list (Line 2 in Algo-
rithm 3). Initially the vector value is 0 which means we select
the ﬁrst candidate for each candidate list (Lines 3-4). Every
time we get the best selection from the heap top of H. We can
build a query graph Q(cid:4) by replacing all vertex/edge labels in
QS using the selected candidates (Lines 5-6). Line 7 applies
an existing subgraph isomorphism algorithm such as VF2 to
ﬁnd all subgraph matches of Q(cid:4) over G. Then we maintain
the maximum heap H to guarantee each selection we get
from H has the highest score among all untried selection as
showed in Line 8-10. For each candidate list Li, we add one
at the ith bit in current selection G to get a new selection and
put it into H. Thus we can early termination when we ﬁnd k
matches as showed in lines 11-12 in Algorithm 3.5 NODE-FIRST FRAMEWORK
5.1 Building Super Semantic Query Graph
There are three steps in building Super Semantic Query
graph QU : node recognition, query graph structure con-
struction and phrase mapping.5.1.1 Node Recognition
The ﬁrst step is to recognize all nodes from the question sen-
tence N. Generally, we extract entities, classes and wild-
cards as nodes. We adopt the dictionary-based entity linking
approach [5] to ﬁnd entities and classes. We collect all wh-
words and nouns which could not map to any entities and
classes as wild-cards. For example, given a question sen-
tence N2 = “What is the budget of the ﬁlm directed by Paul
Anderson and starred by a Chinese actor?”, the node recog-
nition result is illustrated in Fig. 3a, i.e., “what”, “ﬁlm”,
“Paul Anderson”, “Chinese”, “actor”.5.1.2 Structure Construction
Given that all nodes have been recognized, the next step is to
build a super semantic query graph QU . As mentioned in Sec-
tion 2.3, although our method still relies on the dependency
tree of the question sentence, it is more robust to dependency
errors compared with the relation-ﬁrst framework.Based on Assumption 1 (see Section 2.3.1), we construct the
super semantic query graph QU as follows: Given a node set V
(which has been recognized in the ﬁrst step) and a depen-
dency tree Y of question sentence, for any two nodes vi and vj
(2 V ), we introduce an edge between vi and vj if and only if
the simple path between vi and vj does not contain other node
in V . We propose a DFS based algorithm (see Algorithm 4 in
Appendix A, available in the online supplemental material,HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS833with time complexity OðjY jÞ) to ﬁnd neighbors for each node
and build the super semantic query graph QU .For the question sentence N2, the super semantic query
graph QU is shown in Fig. 5. The node labels are those asso-
ciated entity/class mentions or other phrases. The edge
label of vivj is the words along the simple path between vi
and vj in the dependency tree Y ðN2Þ. For example, the path
between “what” and “ﬁlm” in the dependency tree contains
three words: “is”, “budget” and “of”, thus, the edge label
between v1 and v2 (in QU ) is “(be) budget of ”. If the simple
path does not contain any word (such at the path between
“actor” and “Chinese”), the edge label is empty.5.1.3 Phrases Mapping
In this Section, we discuss how to ﬁnd candidate predicates
and entities/classes for edges and nodes. The methods of map-
ping nodes and labeled edges are the same as phrases map-
ping of QS (see Section 4.1.3). We only concentrate on how to
map the unlabeled edges to predicates in RDF graph G.Mapping Unlabeled Edges of QU . For an unlabeled edge
vivj, the relation between node vi and vj is implicit in given
question. For example, edge v4v5 denotes an implicit rela-
tion, the correspond word sequence in N2 is “Chinese
actor”. We try to infer the implicit relation between the two
given nodes vi and vj based on underlying knowledge
graph. First, we have the following assumptions:(1)Since there is an implicit relation between two nodes
vi and vj, we assume that the distance between vi
and vj in RDF graph G is short enough.(2) Assume that at least one node (vi or vj) is an entity or
a class. It is impossible that two connected nodes are
both wh-words.Similar with the bridging operation in [17], we generate
the candidate predicates as following. If two nodes are both
constants (i.e., entities or classes), such as v4 and v5 in Fig. 3b
(i.e., “Chinese actor”), we locate the two nodes at RDF graph
G and ﬁnd the predicate between them. If one node vi is a
wild-card and the other one vj is an entity or class, we locate
vj in RDF graph G and select the most frequent adjacent
predicates as the candidate predicates to match edge vivj.5.2 Query Executing
Given a super semantic query graph QU , we discuss how to
ﬁnd approximate matches over RDF graph G with the top-k
match scores, where the approximate match is deﬁned in
Deﬁnition 5 and the match score is analogue to Deﬁnition 8.
As mentioned in Deﬁnition 5, some edges (in QU ) are
allowed dis-matching but all nodes should be matched. Con-
sequently, the approximate match of QU is the same with the
exact match (see Deﬁnition 2) of one connected spanning sub-
graph of QU . Thus, a straightforward solution is to enumerate
all spanning subgraphs Si of QU . For each Si, we call Algo-
rithm 3 to ﬁnd the top-k matches of Si. Finally, we collect all
top-k matches for each Si to form answer set RS, and report
k matches with the largest match scores in RS.Obviously, the above solution is not efﬁcient, since there
are lots of common computations if two spanning subgraphs
share common structures with each other. Therefore, we pro-
pose another bottom-up solution. The pseudo codes are
given in Algorithm 5 in Appendix A, available in the
online supplemental material. Different from the baseline
algorithm, we do not decide the query graph at the begin-
ning. Instead we try to construct the “correct” graphstructure by expanding the current partial structure. Gen-
erally, in each step, we extend the current partial struc-
ture Q by expanding one more edge vix, i.e., Q ¼ Q [ vix
(Line 6 in Algorithm 5). Initially, Q only includes one
starting vertex s in QU . We select the vertex with the
smallest number of candidates as the starting vertex s. If
the new expanded partial structure Q can ﬁnd matches
over RDF graph G (Lines 7-11), we continue the search
branch. Furthermore, if Q has already been a spanning
subgraph of QU (Lines 9-11), we record the matches of Q
together with the match scores in answer set RS. We only
keep the current top-k matches in RS and the current
threshold d. If Q cannot ﬁnd matches over RDF graph G
(Lines 12-13), we backtrack the search branch.To improve the search performance, we can also perform
threshold-based pruning (like A(cid:4)-style algorithm) and early
terminate some search branches. For example, for a given
partial structure Q, we estimate the upper bound of the
match score if continually expanding Q. We can derive the
upper bound assuming that all un-mached vertices and
edges (of QU ) can match the candidates with the largest
score. If the upper bound is still smaller than the threshold
d, we can terminate the search branch. We do not discuss
this tangential issue any further.6 EXPERIMENTSWe evaluate our system on DBpedia and Freebase with two
benchmarks separately. For DBpedia, we use QALD7 as the
benchmark. As we know, QALD is a series of open-domain
question answering campaigns, which mainly based on
DBpedia. We compare our method with all systems in
QALD-6 competition as well as DEANNA [18] and Aqqu
[19]. For Freebase, we use WebQuestions [17] as the bench-
mark and compare our method with Sempre [17], Para-
Sempre [20], Aqqu [19], STAGG [21] and Yavuz et al.[22].
To build the relation mention dictionary, we utilize relation
phrases in Patty dataset [12]. We also use the CrossWikis [8]
as the entity mention dictionary. All experiments are imple-
mented in a PC server with Intel Xeon CPU 2 GB Hz, 64 GB
memory running Windows 2008. Our two frameworks (the
relation-ﬁrst framework and the node-ﬁrst framework) are
denoted as RFF and NFF, respectively.6.1 Datasets
DBpedia RDF Repository. (http://blog.dbpedia.org/) is a
comm-unity effort to extract structured information from
Wikipedia and to make this information available on the
Web [23]. We use the version of DBpedia 2014 and the statis-
tics are given in Table 5.Freebase. (https://developers.google.com/freebase/) is a
collaboratively edited knowledge base. We use the version
of Freebase 2013, which is same with [20]. The statistics are
given in Table 5.Patty Relation Mention Dataset[12]. contains a large
resource for textual patterns that denote binary relations
between entities. We use two different relation mention
datasets, wordnet-wikipedia and freebase-wikipedia. The
statistics are given in Table 6. The experiments of ofﬂine
performance can be found in Appendix B, available in the
online supplemental material.7. http://qald.sebastianwalter.org/834IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 5
Statistics of RDF GraphNumber of Entities
Number of Triples
Number of Predicates
Size of RDF Graphs (in GB)DBpedia5.4 million
110 million
9,708
8.7Freebase41 million
596 million
19,456
56.9TABLE 6
Statistics of Relation Mention Dataset# of Textual Patterns
# of Entity Pairs
Average Entity Pair # for each Patternwordnet-
wikipedia
350,568
3,862,304
11freebase-
wikipedia
1,631,530
15,802,947
96.2 Online Performance
Exp 1. (End-to-End Performance) We evaluate our system
both on QALD benchmark and WebQuestions benchmark.
For QALD dataset, we show the experiment results in the
QALD competition report format to enable the comparison
with all systems in QALD-6 (in Table 7). We also repro-
duced DEANNA [18] and Aqqu [19] using the codes pub-
lished by authors. For WebQuestions dataset, we show the
average F1 to compare with previous works. We repro-
duced Aqqu [19] and report the results of other works in
Table 8. In Table 7, “Processed” denotes the number of test
questions that can be processed and “Right” refers to the
number of questions that were answered correctly.For WebQuestions dataset, we use SVM-rank [15] to
learn the weight a of aggregation function (see Deﬁnition 8)
as there are enough training data in WebQuestions. To train
SVM-rank model, we generate several candidate query
graphs with certain entities and relations for each training
question. After matching these query graphs, we calculate
the F1 score as their ranking score. The ﬁnal a in our experi-
ment is 0.136. As there are only 350 training questions of
QALD-6, learning a perfect weight is hard. Therefore, we
use the default value a ¼ 0:5 directly.Effectiveness Evaluation. Our NFF method joined QALD-6
competition and won the second place at F-1 measure.8 NFF
can answer 68 questions correctly, while the relation-ﬁrst
framework (RFF) can answer 40 questions correctly. Gener-
ally, NFF can beat all systems in QALD-6 campaign in F-1
except for CANaLI [24]. Note that CANaLI aims to answer
controlled natural language questions, in which, users need to
specify the precise entities and predicates (denoted by URIs)
in the question sentences. In other words, CANaLI asks users
to do disambiguation task for phrase linking and CANaLI is
not a fully natural language question answering system.Table 8 shows the results on the test set of WebQuestions,
which contains 2032 questions. Different
from QALD
benchmark, WebQuestions has low diversity and most
questions are simple questions. The average F1 of our sys-
tem (49.6 percent) is little less than the state-of-art work [21]
(52.5 percent) and Yavuz et al. [22] (52.6 percent). Compared
by [22] and [21], our approach performs not very well in8. The result of QALD-6 campaign is available at http://qald.
sebastianwalter.org/6/documents/qald-6_results.pdf, and our team is
named NbFramework.TABLE 7
Evaluating QALD-6 Testing Questions
(Total Question Number = 100)Processed Right Recall PrecisionNFF
RFF
CANaLI
UTQA
KWGAnswer
SemGraphQA
UIQA1
UIQA2
DEANNA
Aqqu100
100
100
100
100
100
44
36
100
10068
40
83
63
52
20
21
14
20
360.70
0.43
0.89
0.69
0.59
0.25
0.63
0.53
0.21
0.370.89
0.77
0.89
0.82
0.85
0.70
0.54
0.43
0.74
0.39F-1
0.78
0.55
0.89
0.75
0.70
0.37
0.25
0.17
0.33
0.38TABLE 8
Evaluating WebQuestions Testing QuestionsNFF
RFF
Sempre
ParaSempre
Aqqu
STAGG
Yavuz et al. (2016)Average F149.6%
31.2%
35.7%
39.9%
49.4%
52.5%
52.6%relation extraction, which relies on the relation mention dic-
tionary. Actually, the advantage of our approach lies in
answering complex questions (i.e., multi-hop relation ques-
tions), such as some questions in QALD benchmark. As the
codes of [22] and [21] are not available to us, we compare
our method with Aqqu [19] on QALD. Aqqu performs well
on WebQuestions (49.4 percent) but has a poor performance
on QALD benchmark (38 percent in Table 7). It is because
that the questions in WebQuestions are simpler than QALD
and most of them could be translated into a “one-triple”
query, i.e, have only one entity and one relation. Aqqu
deﬁnes three query templates and try to match test ques-
tions to predeﬁned templates. These three templates cover
almost all of the questions in the WebQuestions benchmark
[19]. However, when Aqqu meets some other questions
which have different representation and could not be
matched to predeﬁned templates,
it would get wrong
answers. For instance, Aqqu could not answer “true-false”
questions such as “Does Trump have any children?”. How-
ever, those questions could be answered correctly by our
system because we do not rely on particular dataset and do
not use any predeﬁned query templates.Efﬁciency Evaluation. We compare the running time of our
two frameworks with DEANNA [18] using QALD-6 data-
set. Fig. 6 shows the experiment results. We test all ques-
tions that can be answered correctly by both DEANNA and
our methods. In the question understanding, DEANNA
needs to generate SPARQLs, our systems generates seman-
tic query graph QS or super semantic query graph QU . The
former has the exponential time complexity, but our meth-
ods have the polynomial time complexity in the question
understanding stage, as we reserved the ambiguity. The rea-
son of NFF is faster than RFF is that RFF spends more time
on relation extraction from a whole dependency tree Y .
Actually, RFF spends OðjY j2Þ time to extraction relations
and build QS (see Algorithm 2 in Appendix, available in the
online supplemental material) while NFF costs OðjY jÞ timeHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS835Fig. 6. Online running time comparison.TABLE 9
Pipeline AccuracyStep1RFF
NFF Node Recognition: 0.92Relation Recognition: 0.65Step2
Building QS: 0.54
Building QU : 0.92Final0.40
0.68to build QU (see Algorithm 4 in Appendix, available in the
online supplemental material).Exp 2. (Pipeline Accuracy of Two Frameworks) In this experi-
ment, we evaluate the accuracies of main steps in both RFF
and NFF using 100 test questions of QALD-6. Table 9 shows
the experiment results. QALD-6 competition report released
the gold standard SPARQL statement for each question sen-
tence in QALD-6. For each sentence N, we suppose that the
generated semantic query graph is QS and super semantic
query graph is QU and the correct SPARQL query is Q. In the
relation-ﬁrst framework (RFF), we say that “relation recog-
nition” is correct if exists a correct one-to-one mapping from
relation mentions (in QS) to predicate edges in SPARQL
query graph Q. Furthermore, we say that QS is correct if QS
is isomorphism to Q. Analogously, if there exists a one-to-
one mapping from nodes in QU to vertices in Q, we say that
the node recognition is correct. QU is correct if exists a con-
nected spanning graph of QU that is isomorphism to Q.By comparing the ﬁrst step (i.e, relation recognition and
node recognition) between RFF and NFF in 100 test ques-
tions, we can see that the node recognition (in NFF) is much
more accurate than relation recognition (in RFF), where the
former’s accuracy is 0.92 and the latter is 0.65. This is the
motivation of NFF framework. Furthermore, the accuracy
of QS is 0.54, which means that 11 questions found wrong
associated argument nodes after recognizing correct rela-
tions. On the contrary, the accuracy of QU is same as the
node recognition (0.92), which means that once all nodes
were recognized correctly, we can build a correct super
semantic query graph QU . In other words, Assumption 1 (in
Section 2.3) of building QU is effective.The ﬁnal accuracy of RFF and NFF are 0.40 and 0.68,
respectively, which means 40 and 68 percent of questions
that can be answered correctly in the two frameworks. In
some cases, even if we can generate a correct QS or QU , we
may get the wrong answers. The reason of that is mainly
because of out-of-dictionary entities/relations or complex
aggregation operations that cannot be handled by our frame-
works. The details of error analysis will be given in Exp 4.Exp 3. (Efﬁciency of Query Evaluation in NFF Framework) We
evaluate the efﬁciency of the two approximate subgraphFig. 7. Evaluation methods comparison.matching algorithms in Section 5.2 using the 100 test ques-
tions in QALD-6. The results of 10 questions randomly
selected and the average time of 100 questions are showed in
Fig. 7. For half of the cases, the bottom-up algorithm (Algo-
rithm 5) has obvious advantages, which veriﬁed our analysis
in Section 5.2. In some cases, the performance gap is not clear,
since QU of these questions is an acyclic graph, which means
the problem of approximate matching QU is degenerated into
matching QS. Generally, the average time of the bottom-up
algorithm is faster than the baseline solution by twice.Exp 4. (Failure Analysis) We provide the failure analysis of
our two methods. We consider about QALD benchmark
because it is harder than WebQuestions and more diversi-
ﬁed. The failure analysis will help the improvement of our
RDF Q/A system’s precision.There are four reasons for the failure of some questions
in RFF. The ﬁrst reason is the relation recognition problem,
which accounted for 58 percent. That because many rela-
tions could not be captured by mentions, such as the ques-
tion “Who was on the Apollo 11 mission”. Some relations
even be implicit such as “Czech movie”. The second one is
wrong nodes. For example, “In which countries do people
speak Japanese?”, the correct semantic relation is hspeak,
Japanese, countryi, however, we found the semantic rela-
tion hspeak, people, countryi. The latter two reasons are
same as the reasons in NFF. Notice that relation mapping
failure is a part of relation recognition failure. We give the
ratio of each reason with an example in Table 10.There are three reasons for the failure of some questions in
NFF. The ﬁrst reason is the node recognition problem. Some
phrases were recognized as nodes by mistake. For example,
“Who composed the soundtrack for Cameron’s Titanic”. We
regarded the noun “soundtrack” as a variable node, however,
it should be ignored. The second one is the failure of phrase
mapping, which means we could not ﬁnd the correct referred
entity/relation for a given mention. For example, “What is
Batman’s real name”. The correct relation halterEgoi is not
occurred in the candidate list of mention “real name” in our
relation mention dictionary DR. The third one is that our
method cannot answer some complex aggregation questions.
We give the ratio of each reason with an example in Table 11.7 RELATED WORKQ/A (natural language question answering) has a quite
long history since the seventies of last century [25]. Gener-
ally, the solutions of knowledge base QA can be mainly
divided into two categories.836IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 10
Failure Analysis of Relation-First FrameworkTABLE 11
Failure Analysis of Node-ﬁrst FrameworkReasonRelation FailureNodes Failure#(Ratio)35 (58 %)11 (18 %)Entity Mapping
Complex Aggregation5 (9 %)
9 (15 %)Sample ExampleReasonQ4: Who was on the
Apollo 11 mission?
Q55: In which countries do
people speak Japanese?
Q32: Who developed Slack?
Q80: How short is the
shortest active NBA player?Node Recognition
FailureEntity MappingRelation MappingComplex Aggregation#(Ratio)
8 (25 %) Q27: Who composed theSample Examplesoundtrack for Cameron’s
Titanic?5 (16 %) Q22: Which computer
scientist won an oscar?
10 (31 %) Q100: What is Batman’s
real name?9 (28 %) Q29: Show me allThe ﬁrst one is semantic parsing-based, where natural lan-
guage questions are translated into logical forms, such as
simple (cid:2)-DCS [17], [20], query graph [21], or executable
queries such as SPARQL [18], [19], [26]. [20] deﬁned a set of
logical form templates. DEANNA [18] builds a disambigua-
tion graph and reduces disambiguation as an integer linear
programming problem.The other category is information retrieval-based, where the
systems are not intended to parse the question to a formal
semantic interpretation.
they select candidate
Instead,
answers ﬁrst and then rank them by various methods [2],
[27], [28], [29], [30]. [29] utilizes subgraph embedding to pre-
dict the conﬁdence of candidate answers. [28] maximize the
similarity between the distributed representation of a ques-
tion and its answer candidates using Multi-Column Convo-
lutional Neural Networks (MCCNN), while [2] aims to
predicate the correct relations between topic entity and
answer candidates with text evidence.Our work belongs to the ﬁrst category and differs from
existing systems in three points. First, different from tem-
plate-based works such as [17], [19], [20], [31], our method
does not adopt any manually deﬁned templates. To gap the
mismatch between natural language and the knowledge base,
[20] generates canonical utterances for each candidate logical
form of the given question N, then it ranks the pairs of canoni-
cal utterance and logical form based on a paraphrase model.
However, users should deﬁne logical form templates and the
generation rules ﬁrst. [31] mines millions of operators from
unlabeled data, then learns to compose them to answer ques-
tions using evidence from multiple knowledge bases. It still
uses predeﬁned templates to map questions to queries. Simi-
larly, [19] designs three query templates and try to match the
given question N to those templates, then generates and ranks
SPARQL queries of each matched template. However, both
the templates and the generation rules are heavily relied on
the particular dataset and could not handle some other ques-
tions. For example, none of above systems could answer true-
false questions like “Does Trump have any children?”. In con-
trast, our system does not rely on templates and could answer
more kinds of questions. We evaluate [19] on the QALD-6
benchmark and the results could be found in Table 7.Second, different from most semantic parsing based sys-
tems, we push down the disambiguation into the query
evaluation stage. Existing solutions, like [26] and [18], gen-
erate the SPARQLs as the intermediate results in the ques-
tion understanding stage. Obviously,
they need to do
disambiguation in this step. For example, DEANNA [18]
proposes an integer
linear programming (ILP)-based
method to address the disambiguation issue. As we know,
ILP is a classical NP-hard problem. Then, in the query eval-
uation stage, the existing methods need to answer these
generated SPARQL queries. Answering SPARQL queriesbasketball players that
are higher than 2 meters.equals to ﬁnding subgraph matches of query graphs Q over
RDF graph [32], which is also an NP-hard problem.Third, our approach have stronger representation power
than most existing solutions. Information retrieval solutions
like [2], ﬁnd the topic entity and try to predicate the relation-
ship between the answer and the topic entity which can
only solve simple questions with one triple. For the ques-
tions have two entities, they utilize predeﬁned patterns in
dependency parse tree to decompose the complex question
to two simple question. However, the precision of such sys-
tem highly depends on the accuracy of the dependency
parse tree, which is pretty low when the question is com-
plex. In contrast, our work (especially NFF) is more robust
to the errors of dependency parse trees.Two recent semantic parsing methods [21] and [22]
achieve the state-of-the-art precisions on WebQuestions
benchmark. [21] builds query graphs from question sen-
tence according to a state transition chain. It ﬁrst recognizes
a topic entity and an inference the relation between the topic
entity and the answer. Further it allows other entities to
restrict the answer node. The representation power of [21] is
limited because the ﬁnal query graph structure must be a
tree with diameter less than 3. [22] improves semantic
parsing via answer type inference. It transforms a question
to a “subject, relation, object” order by dependency parse
tree patterns and proposes a BLSTM model to predict the
answer type. Finally the answer type can be used to prune
the candidate logic forms generated by the semantic parsing
baseline. This approach cannot tackle the questions uncov-
ered by patterns or complex questions. Different from the
above systems, our approach has stronger representation
power as we do not restrict the query graph’s structure.8 CONCLUSIONIn this paper, we propose a graph data-driven framework to
answer natural language questions over RDF graphs. Differ-
ent from existing work, we allow the ambiguity both of
phrases and structure in the question understanding stage.
We push down the disambiguation into the query evalua-
tion stage. Based on the query results over RDF graphs, we
can address the ambiguity issue efﬁciently. In other words,
we combine the disambiguation and query evaluation in an
the graph data-driven
uniform process. Consequently,
framework not only improves the precision but also speeds
up the whole performance of RDF Q/A system.ACKNOWLEDGMENTSThis work was supported by The National Key Research and
Development Program of China under grant 2016YFB1000603HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS837and NSFC under grants 61622201, 61532010, and 61370055. Jef-
frey Xu Yu was supported by the Research Grants Council of
the Hong Kong SAR, China No. 14221716 and No. 12258116.REFERENCES[1] V. Lopez, C. Unger, P. Cimiano, and E. Motta, “Evaluating question
answering over linked data,” J. Web Sem., vol. 21, pp. 3–13, 2013.
[2] K. Xu, S. Reddy, Y. Feng, S. Huang, and D. Zhao, “Question answer-
ing on freebase via relation extraction and textual evidence,” in Proc.
54th Annu. Meet. Assoc. Comput. Linguistics, 2016, pp. 2326–2336.
J. Bao, N. Duan, M. Zhou, and T. Zhao, “Knowledge-based ques-
tion answering as machine translation,” in Proc. 52nd Annu. Meet.
Assoc. Comput. Linguistics, 2014, pp. 967–976.[3][4] M. Yahya, K. Berberich, S. Elbassuoni, and G. Weikum, “Robust
question answering over the web of linked data,” in Proc. 22nd
ACM Int. Conf. Inf. Knowl. Manage., 2013, pp. 1107–1116.[5] D. Deng, G. Li, J. Feng, Y. Duan, and Z. Gong, “A uniﬁed frame-
work for approximate dictionary-based entity extraction,” VLDB
J., vol. 24, no. 1, pp. 143–167, 2015.[6] W. M. Soon, H. T. Ng, and D. C. Y. Lim, “A machine learning
approach to coreference resolution of noun phrases,” Comput. Lin-
guist., vol. 27, no. 4, pp. 521–544, 2001.[7] M.-C. de Marneffe and C. D. Manning, “Stanford typed depen-
[Online]. Available: https://nlp.dencies manual,” (2016).
stanford.edu/software/dependencies_manual.pdf[8] V. I. Spitkovsky and A. X. Chang, “A cross-lingual dictionary for
english wikipedia concepts,” in Proc. 8th Int. Conf. Language
Resources Eval., 2012, pp. 3168–3175.[9] A. Chisholm and B. Hachey, “Entity disambiguation with weblinks,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 145–156, 2015.[10] X. Ling, S. Singh, and D. S. Weld, “Design challenges for entity link-
ing,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 315–328, 2015.
[11] N. Nakashole, G. Weikum, and F. M. Suchanek, “Discovering and
exploring relations on the web,” Proc. VLDB Endowment, vol. 5,
no. 12, 2012.[12] N. Nakashole, G. Weikum, and F. M. Suchanek, “PATTY: A tax-
onomy of relational patterns with semantic types,” in Proc. Joint
Conf. Empirical Methods Natural Language Process. Comput. Natural
Language Learn., 2012, pp. 1135–1145.[13] A. Fader, S. Soderland, and O. Etzioni, “Identifying relations for
open information extraction,” in Proc. Conf. Empirical Methods Nat-
ural Language Process., 2011, pp. 1535–1545.[14] C. D. Manning, P. Raghavan, and H. Sch€utze, Introduction to Infor-mation Retrieval. New York: Cambridge Univ. Press, 2008.[15] T.Joachims, “Optimizing search engines using clickthrough
data,” in Proc. ACM Conf. Knowl. Discovery Data Mining, 2002,
pp. 133–142.[16] P. Zhao and J. Han, “On graph query optimization in large
networks,” Proc. VLDB Endowment, vol. 3, no. 1, pp. 340–351, 2010.
J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on
freebase from question-answer pairs,” in Proc. Conf. Empirical
Methods Natural Language Process., 2013, pp. 1533–1544.[17][18] M. Yahya, K. Berberich, S. Elbassuoni, M. Ramanath, V. Tresp,
and G. Weikum, “Natural language questions for the web of
data,” in Proc. Joint Conf. Empirical Methods Natural Language Pro-
cess. Computat. Natural Language Learn., 2012, pp. 379–390.[20][19] H. Bast and E. Haussmann, “More accurate question answering
on freebase,” in Proc. 24th ACM Int. Conf. Inf. Knowl. Manag., 2015,
pp. 1431–1440.
J. Berant and P. Liang, “Semantic parsing via paraphrasing,” in Proc.
52nd Annu. Meet. Assoc. Comput. Linguistics, 2014, pp. 1415–1425.
[21] W. Yih, M. Chang, X. He, and J. Gao, “Semantic parsing via staged
query graph generation: Question answering with knowledge
base,” in Proc. 53rd Annu. Meet. Assoc. Comput. Linguistics 7th Int.
Joint Conf. Natural Language Process. Asian Fed. Natural Language
Process., 2015, pp. 1321–1331.[22] S. Yavuz, I. Gur, Y. Su, M. Srivatsa, and X. Yan, “Improving
semantic parsing via answer type inference,” in Proc. Conf. Empiri-
cal Methods Natural Language Process., 2016, pp. 149–159.[23] C. Bizer, et al., “DBpedia - a crystallization point for the web ofdata,” J. Web Sem., vol. 7, no. 3, pp. 154–165, 2009.[24] G. M. Mazzeo and C. Zaniolo, “Answering controlled natural lan-
guage questions on RDF knowledge bases,” in Proc. 19th Int. Conf.
Extending Database Technol., 2016, pp. 608–611.[25] R. F. Simmons, “Natural language question-answering systems:1969,” Commun. ACM, vol. 13, no. 1, pp. 15–30, Jan. 1970.[26] C. Unger, L. B€uhmann, J. Lehmann, A.-C. N. Ngomo, D. Gerber,
and P. Cimiano, “Template-based question answering over RDF
data,” in Proc. World Wide Web, 2012, pp. 639–648.[27] A. P. B. Veyseh, “Cross-lingual question answering using common
semantic space,” in Proc. TextGraphs@NAACL-HLT: 10th Workshop
Graph-based Methods Natural Language Process., 2016, pp. 15–19.
[28] L. Dong, F. Wei, M. Zhou, and K. Xu, “Question answering over free-
base with multi-column convolutional neural networks,” in Proc. 53rd
Annu. Meet. Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Lan-
guage Process. Asian Fed. Natural Language Process., 2015, pp. 260–269.[29] A. Bordes, S. Chopra, and J. Weston, “Question answering with
subgraph embeddings,” in Proc. 2014 Conf. Empirical Methods Nat-
ural Language Process., 2014, pp. 615–620.[30] X. Yao and B. V. Durme, “Information extraction over structured
data: Question answering with freebase,” in Proc. 52nd Annu.
Meet. Assoc. Comput. Linguistics, 2014, pp. 956–966.[31] A. Fader, L. Zettlemoyer, and O. Etzioni, “Open question answering
over curated and extracted knowledge bases,” in Proc. 20th ACM
SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 1156–1165.
[32] L. Zou, J. Mo, L. Chen, M. T. €Ozsu, and D. Zhao, “gStore: Answer-
ing SPARQL queries via subgraph matching,” Proc. VLDB Endow-
ment, vol. 4, no. 8, pp. 482–493, 2011.Sen Hu received the BS degree in computer sci-
ence and technology from the Beijing University
of Posts and Telecommunications in 2015. He is
currently working toward the PhD degree in the
Institute of Computer Science and Technology at
Peking University, focusing on knowledge graph
and question answering.Lei Zou received the BS and PhD degrees in
computer science from the Huazhong University
of Science and Technology (HUST), in 2003 and
2009, respectively. Now, he is an associate pro-
fessor in the Institute of Computer Science and
Technology at Peking University. He is also a fac-
ulty member in the Big Data Center at Peking
University and the Beijing Institute of Big Data
Research. His research interests include graph
database and semantic data management.Jeffrey Yu Xu has held teaching positions in the
Institute of Information Sciences an Electronics,
University of Tsukuba, and in the Department of
Computer Science, Australian National University,
Australia. Currently, he is professor in the Depart-
ment of Systems Engineering and Engineering
Management, Chinese University of Hong Kong,
Hong Kong. His current research interests include
graph database, graph mining, and social network
analysis.Haixun Wang received the bachelor’s and mas-
ter’s degrees in computer science from Shanghai
Jiao Tong University in 1994 and 1996, respec-
tively, and the PhD degree in computer science
from the University of California, Louisiana, in
2000. He joined Google Research, Mountain
View, California, in 2013. His research interests
include text analytics, natural language process-
ing, knowledge base, semantic network, artiﬁcial
intelligence, graph data management, etc.Dongyan Zhao received the BS, MS, and PhD
degree from Peking University in 1991, 1994,
and 2000, respectively. Now, he is a professor in
the Institute of Computer Science and Technol-
ogy of Peking University. His research interest is
on information processing and knowledge man-
agement,
including computer network, graph
database, and intelligent agent.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onthe web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS825Fig. 1. Question answering over RDF dataset.(cid:1)(cid:1)! and u2u3Speciﬁcally, we resolve the ambiguity of natural language
questions at the time when matches of query are found. The
cost of disambiguation is saved if there is no match found.
We call this as the graph data-driven approach for RDF Q/A.
We illustrate the intuition of our method by an example.
Example 1. Consider a subgraph of graph G in Fig. 1a (the
(cid:1)(cid:1)!
subgraph induced by vertices u1, u2, u3 and c1). Edge u2c1
(cid:1)(cid:1)!
says that “Resident Evil: Retribution is a ﬁlm”. Edge u2u1
says that “The budget of Resident Evil: Retribution is $ 65
(cid:1)(cid:1)! says that “Paul W. S. Anderson directed
million”. Edge u2u3
the ﬁlm Resident Evil: Retribution”. The natural language
question N1 is “What is the budget of the ﬁlm directed by
Paul Anderson”. Obviously, the subgraph formed by edges
(cid:1)(cid:1)! is a match of N1. “6.5E7” is a correct
(cid:1)(cid:1)!, u2u1
u2c1
answer. On the other hand, we cannot ﬁnd a match (of N1)
containing h Paul_Anderson_(actor)i inc G, i.e., the phrase
“Paul Anderson” (in N1) cannot map to hPaul_Anderson_
(actor)i. Therefore, we address the ambiguity issue of
phrase linking when the matches are found. We can also
resolve the ambiguity of query graph structure following
the same idea. More details will be discussed in Section 5.
The above example illustrates the intuition of our graph
data-driven approach. A fundamental issue in our method
is how to deﬁne a “match” between a subgraph of G and a
natural language question N. Because N is unstructured
data and G is graph structure data, we should ﬁll the gap
between them. Therefore, we propose a semantic query
graph QS (deﬁned in Deﬁnition 1) to represent the question
semantics of N. An example of QS is given in Fig. 1c, which
represents the semantic of the question N. Answering natu-
ral language question equals to ﬁnding matches of QS over
the underlying RDF graph G. To build QS, we propose two
different frameworks: relation (edge)-ﬁrst and node-ﬁrst.1.2 Our Approach
Although there are still
two stages “question under-
standing” and “query evaluation” in our method, we do notgenerate SPARQL at the question understanding step as
existing solutions do. As we know, a SPARQL query can
also be represented as a query graph, which does not
include any ambiguity. Instead, our method builds a query
graph that represents users’ query intention, but it allows
for the ambiguity at the question understanding stage, such
as the ambiguity of phrase linking and query graph struc-
ture. We resolve the ambiguity when the matches are found
at the query evaluation.In the ﬁrst framework, we ﬁrst extract semantic relations
based on the dependency tree structure of question senten-
ces to build a semantic query graph QS. A semantic relation
is a triple hrel; arg1; arg2i, where rel is a relation phrase, and
arg1 and arg2 are its associated node phrases. For instance,
h“directed by”,“ﬁlm”,“Paul Anderson”i is a semantic rela-
tion. In QS, two edges share one common endpoint if the
two corresponding relations share one common node
phrase. Each node (entity/class mention) and edge (relation
mention) in QS may have multiple candidates. The ﬁrst
framework addresses the ambiguity of phrase linking when
the matches (see Deﬁnition 2) of QS are found. Note that the
ﬁrst framework does not address the ambiguity of query
graph’s structure and assumes that the query graph can be
uniquely ﬁxed at the question understanding step.The second framework takes another perspective. When
there exist some implicit or uncertain relations in N, the
relation-ﬁrst framework often fails to extract such relations.
Therefore, the second framework starts with extracting
nodes from the question sentence N and connects these
nodes to form a query graph. Furthermore, different from
the relation-ﬁrst
framework
allows for the ambiguity of query graph structure at the
beginning. It does not intend to build QS in the question
understanding step. Instead, it builds a super graph QU of
QS that includes uncertain edges. To match QU over the
underlying RDF graph G, we allow for mismatching some
edges in QU ,
i.e., approximate match (Deﬁnition 5). Wethe node-ﬁrstframework,826IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 1
NotationsNotationGðV; EÞ
N
Q
QS
QU
Y
DE=DR
vi/ui
Cvi /CvivjDeﬁnition and DescriptionRDF graph and vertex and edge sets
A natural language question
A SPARQL query (of N)
The Semantic Query Graph (of N)
The Super Semantic Query Graph (of N)
The dependency tree (of N)
The entity/relation mention dictionary
A vertex in query graph / RDF graph
Candidate mappings of vertex vi / edge vivjresolve the ambiguity of phrase linking and query graph
structure together when the approximate matches are
found. Actually, the approximate matching position (in
RDF graph G) deﬁnes the semantic query graph QS that we
aim to build. In other words, we push down resolving the
ambiguity of QS’s structure to the query evaluation stage.
In a nutshell, we make the following contribution.In the ﬁrst(1) We propose two graph data-driven frameworks for
RDF Q/A task, different from exiting solutions, in
which the disambiguation and query evaluation are
combined together.
framework, we
address ambiguity of phrase linking at the query
evaluation; while in the second framework,
the
ambiguity of phrase linking and query graph’s struc-
ture are both resolved. The graph data-driven frame-
works not only improve the precision but also speed
up query processing time greatly.
In the ofﬂine processing, we propose a graph mining
algorithm to build a relation mention dictionary, i.e.,
mapping natural language phrases to possible predi-
cates, which is used for question understanding in
RDF Q/A.
In the online processing, in order to speed up query
evaluation, we propose efﬁcient top-k (approximate)
graph matching algorithms of matching QS and QU
over RDF graph.(3)(2)(4) We conduct extensive experiments over several real
RDF datasets (including QALD benchmark and
WebQuestions benchmark) and compare our system
with some state-of-the-art systems. The performance
of our approach beat the other systems on QALD
benchmark while close to the best on the WebQues-
tions benchmark.2 OVERVIEWThe problem of this paper is to ﬁnd the answers to a natural
language question N over a RDF graph G. Table 1 lists the
notations used throughout this paper.There are two key issues in RDF Q/A problem. The ﬁrst
one is how to represent the query intention of the natural lan-
guage question N in a structural way. The second one is how
to address the ambiguity of natural language N. In this paper,
we focus on the ambiguity of phrase linking and query graph
structure (composition) that are mentioned in Section 1.1.2.1 Semantic Query Graph
We deﬁne a semantic query graph (Deﬁnition 1) to repre-
sent the query intention of the question N in a graph struc-
tured way.Deﬁnition 1 (Semantic Query Graph). A semantic query
graph (denoted as QS) is a graph, in which each vertex vi is
associated with an entity phrase, class phrase or wild-cards in
the question sentence N; and each edge vivj is associated with a
relation phrase in the question sentence N, 1 (cid:3) i; j (cid:3) jV ðQSÞj.1 is given in Fig. 2b. In QSGiven the question sentences N1, the corresponding
semantic query graphs QS
1 , nodes
v1, v2 and v3 are associated with “what” (wild-card), “ﬁlm”
(a class phrase) and “Paul Anderson” (an entity phrase),
respectively. The relation phrase “(be) budget of ” denotes
the relation between v1 and v2, as well as the relation phrase
“directed by” between v2 and v3.As mentioned in the introduction, we want to ﬁnd a
“match” of the semantic query graph QS over RDF graph G.
When the matches are found, we resolve the ambiguity of
natural language question sentence; meanwhile we ﬁnd the
answers to the question. Generally, a “match” is deﬁned
based on subgraph isomorphism. Given a node vi
in a
semantic query graph QS, if vi is an entity phrase or a class
phrase, we can use entity linking algorithm [5] to retrieve all
entity/class (in RDF graph G) that possibly correspond to vi,
denoted as CðviÞ; if vi is a wild-card (such as wh-word), we
assume that CðviÞ contains all vertices in RDF graph G. Anal-
ogously, each edge vivj in QS also maps to a list of candidate
predicates, denoted as Cvivj . Consider the semantic query
graph QS in Fig. 2b. We also visualizes the candidates
for each vertex and edge in QS in Fig. 2c. For example, v3
(“Paul Anderson”) corresponds to hPaul_Anderson_(actor)i,
hPaul_S._Andersoni and hPaul_W._S._Andersoni; and edge
“v2v3” maps to hdirectori, hwriteri and hproduceri. Formally,
we deﬁne the match as follows.
Deﬁnition 2 (Match). Consider a semantic query graph QS
with n nodes fv1; . . . ; vng. Each node vi has a candidate list
Cvi , i ¼ 1; . . . ; n. Each edge vivj also has a candidate list Cvivj ,
where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph M containing n vertices
fu1; . . . ; ung in RDF graph G is a match of QS if and only if
the following conditions hold:(1)(2)(3)If vi is mapping to an entity ui, i ¼ 1; . . . ; n, ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n, ui is an
entity whose type is ci (i.e., there is a triple hui rdf:type
cii in RDF graph) and ci must be in Cvi ; and
(cid:1)(cid:1)! 2 M. Furthermore,
8vivj 2 QS , uiuj
(cid:1)(cid:1)!) is in
(cid:1)(cid:1)! (or ujui
the predicate Pij associated with uiuj
Cvivj , 1 (cid:3) i; j (cid:3) n.(cid:1)(cid:1)! 2 M _ ujuiLet us see Fig. 2. The subgraph included by vertices c1, u1,
u2 and u3 (in RDF graph G) denotes a match of semantic query
graph QS in Fig. 2b. When the matches are found, we resolve
the ambiguity, e.g., “Paul Anderson” should refer to hPaul_W.
_S._Andersoni rather than others., meanwhile that we ﬁnd the
answers to the question, i.e., “6.5E7”1 is the ﬁlm budget.The core of our graph data-driven solution lies in two
aspects: one is how to build a semantic query graph QS accu-
rately and the other one is how to ﬁnd matches efﬁciently. In
order to address the above issues, we propose two different
frameworks. The ﬁrst one is called “relation (edge)-ﬁrst”. It
means that we always extract relations from the natural lan-
guage question sentence N and represent them as edges.
Then, we assemble these edges to form a semantic query1. Sixty-ﬁve millionHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS827Fig. 2. Question answering with semantic query graph in relation-ﬁrst framework.graph. The second framework takes another perspective,
called “node-ﬁrst”. It starts with ﬁnding nodes (entity/class
phrases and wild-cards) and try to introduce edges to con-
nect them to form a semantic query graph QS. Furthermore,
another major difference between the two frameworks is
that the node-ﬁrst framework deﬁnes a super graph (called
QU ) of QS when there exist some implicit or uncertain rela-
tions in the question sentence. In other words, the node-ﬁrst
framework is not to ﬁx the QS’s structure before subgraph
matching evaluation as the relation-ﬁrst framework does.2.2 Relation-First Framework
Given a natural language question sentence N, the relation-
ﬁrst framework begins with extracting semantic relations
(edge together with two end points) from N.
Deﬁnition 3 (Semantic Relation). A semantic relation is a
triple hrel; arg1; arg2i, where rel is a relation mention, arg1
and arg2 are the two node phrases.In the running example, h“directed by”, “ﬁlm”,“Paul
Anderson”i is a semantic relation, in which “directed by” is a
relation mention (phrase), “who” and “actor” are its associ-
ated node phrases. We can also ﬁnd another semantic relation
h“budget of”, “what”,“ﬁlm”i from the question sentence N1.2.2.1 Question Understanding
The goal of the question understanding in the ﬁrst frame-
work is to build a semantic query graph QS for representing
users’ query intention in N. Speciﬁcally, we ﬁrst extract all
semantic relations in N, each of which corresponds to an
edge in QS. The semantic relation extraction is based on the
dependency tree of users’ question sentence and a relation
mention dictionary (see more details in Section 4.1). If the
two semantic relations have one common node, they share
one endpoint in QS. In the running example, we get two
semantic relations, i.e., h“directed by”, “ﬁlm”,“Paul Ander-
son”i and h“budget of”, “what”,“ﬁlm”i, as shown in Fig. 2.
They can be combined through the common node phrase
“ﬁlm” as showed in Fig. 2c. In addition, if two node phrasesrefer to same thing after “coreference resolution” [6], we
also combine the corresponding two semantic relations.2.2.2 Query Executing
As mentioned earlier, a semantic query graph QS is a
structural representation of N. In order to answer N, we
need to ﬁnd subgraphs of RDF graph G that match QS. The
match is deﬁned according to the subgraph isomorphism
(see Deﬁnition 2)Each subgraph match has a score, which is derived from
the conﬁdences of each edge and vertex mapping. Deﬁnition
8 deﬁnes the score, which we will discuss later. Our goal is to
ﬁnd all subgraph matches with the top-k scores. A best-ﬁrst
algorithm is proposed in Section 4.2 to address this issue.
Each subgraph match of QS implies an answer to the natural
language question N, meanwhile, the ambiguity is resolved.2.3 Node-First Framework
The relation-ﬁrst framework has two main obstacles. The
ﬁrst is that some relations are difﬁcult to be extracted. If the
relation does not explicitly appeared in the question sen-
tence, it is difﬁcult to extract such semantic relations, since
our relation extraction relies on the relation mention in the
relation mention dictionary. Let us consider two examples
“show me all ﬁlms started by a Chinese actor”, “show me all
ﬁlms stared by an actor who was born in China”. Obviously,
the latter question has one explicit relation mention “(be)
born in”, where the relation in the former one is implicitly
mentioned. Therefore, it is difﬁcult to extract these implicit
relations. Second, in the relation-ﬁrst framework, semantic
relation extraction relies on the syntactic dependency tree of
users’ question sentence and heuristic linguistic rules. If the
syntactic dependency tree has some mistakes, it inevitably
leads to wrong semantic query graph QS’s structure and
wrong answers.Considering the above two obstacles, we design a robust
framework even in the presence of implicit relations and
mistakes in the dependency parse tree. There are two key
points in the second framework:828IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Fig. 3. Question answering with super semantic query graph in node-ﬁrst framework.(1)The ﬁrst step is to extract node phrases (such as
entity phrase, class phrase and wh-words) from the
question sentence N, instead of relation extraction in
the ﬁrst framework.(2) We do not intend to build a semantic query graph QS
at the question understanding step. Instead, we build
a super semantic query graph QU , which possibly has
some uncertain or implicit relations (i.e., edges). In
other words, we allows the structure ambiguity of
query graph in the question understanding step,
which will be resolved at the query evaluation step.
A super semantic query graph QU is analogue to QS (see Deﬁ-
nition 4), but allows for explicit or uncertain relations (edges).
Deﬁnition 4 (Super Semantic Query Graph). A super
semantic query graph (denoted as QU ) is a graph, in which
each vertex vi is associated with an entity phrase, class phrase or
wild-card in the question sentence N; and each edge vivj is asso-
ciated with a relation in N, 1 (cid:3) i; j (cid:3) jV ðQU Þj. If the relation is
explicit, the edge label is the relation mention occurring in N;
otherwise, the edge label is empty when the relation is implicit.The following example illustrates the intuition of the sec-ond framework.
Example 2. Consider N2 in Fig. 3. “What is the budget of the
ﬁlm directed by Paul Anderson and starred by a Chinese
actor?”. The correct SPARQL query of N2 has two addi-
tional triples than N1, which are t1 ¼ h?ﬁlm,starring, ?actori
and t2 ¼ h?actor, country,Chinai. The relation-ﬁrst frame-
work cannot generate t2 because the predicate “country”
has no explicit relation mention in N2. In the node-ﬁrst
framework, we introduce an edge between v4 (“actor”) and
v5 (“Chinese”) in Fig. 3b, whose edge label is empty. For
detected relation mention “starred by”, it is difﬁcult to
determine its corresponding two nodes. There are three can-
didate nodes: “Paul Anderson”, “ﬁlm”, and “actor”. In QU ,
we introduce two edges between “ﬁlm” and “actor”; and
“Paul Anderson” and “actor”. In the query evaluation step,
we perform the approximate match (deﬁned in Deﬁnition 5)
to match QU with RDF graph G, i.e., ﬁnding the occurrences
of QU in RDF graph G with (possible) mismatching edges.In this example, the ﬁnal match is denoted using bold lines
in Fig. 3, in which the edge between “Paul Anderson” and
“actor” (in QU ) is not matched.
It is easy to infer that an approximate match of QU equals to
an exact match of a connected spanning subgraph2 of QU ,
where the spanning subgraph is the semantic query graph
QS that we aim to build. Therefore, in the second framework,
we ﬁx the semantic query graph QS when the matches are
found; meanwhile the answers to the question have been
found. In other words, we resolve the “structure ambiguity”
of query graph at the time the matches are found. We also
brieﬂy discuss the two steps of the node-ﬁrst framework as
follows. More technical details are given in Section 5.2.3.1 Question Understanding
Given a natural language question sentence N, we ﬁrst
extract all constant nodes from N by applying entity extrac-
tion algorithms, which are referred to entities or classes. We
also extract all wh-words (such as who, what and which
et al.) from N as variable nodes. Then, to build QU , we need
to introduce an edge between two nodes if there is a seman-
tic relation between them. A naive solution is to introduce
an edge between any two nodes. Obviously, this method
introduces more noises and ambiguity for the query graph’s
structure. On the other hand, the approximate match in the
node-ﬁrst framework allows mis-matching one or more
edges in QU . The naive solution leads to Oð2nÞ possible
matching structures in the ﬁnal evaluation step, where n is
the number of nodes in QU . This is quite costly.To eliminate more noises and reduce the search space,we propose a simple yet effective assumption:
Assumption 1. Two nodes v1 and v2 has a semantic relation if
and only if there exists no other node v(cid:4) that occurs in the sim-
ple path between v1 and v2 of the dependency parse tree of ques-
tion sentence N.2. A spanning subgraph for graph Q is a subgraph of Q which con-tains every vertex of Q.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS829Although this method also depends on the dependency
parse tree, it is not like the ﬁrst framework, in which,
extracting semantic relations and node phrases (to build
QS) heavily depend on the parse tree’s structure, POS tag3
and dependency relation (such as subj, obj and et al.)4 In
other words, the node-ﬁrst framework (i.e., the second
framework) is more robust to dependency errors.Let us recall Example 2. We ﬁrst extract ﬁve nodes:
“what”, “ﬁlm”, “Paul Anderson”, “Chinese”, “actor” from
the question N2. Fig. 5 illustrates the dependency parse tree
Y ðN2Þ of question sentence N2. According to the assumption,
we introduce an edge v1v2 between two nodes v1 and v2 if
there is no other node v(cid:4) in the simple path between v1 and v2
over Y ðN2Þ. The words along the simple path between v1
and v2 form the edge label of v1v2. For example, the edge
label between nodes “what” and “ﬁlm” is “ (be) budget of”.
The edge label between nodes “Chinese” and “node” is
empty, which is the implicit relation. For nodes “Paul Ander-
son” and “actor”, there is no other nodes along the simple
path between them. According to Assumption 1, we intro-
duce an edge between them and the edge label is “directed
by started by”. Due to the same reason, there is another edge
between nodes “ﬁlm” and “actor”. Finally, we obtain the
super semantic query graph QU as shown in Fig. 3b.2.3.2 Query Executing
First, we ﬁnd candidates for each node and edge in QU ,
which is analogue to the query evaluation of QS in the ﬁrst
framework. According to the entity mention dictionary DE,
for each node, we can obtain a list of candidate entities, clas-
ses. If it is a wh-word, we assume that it can map all vertices
in RDF graph G. For each edge label (i.e., the relation men-
tion relv1v2 ), we also map it to all possible candidate predi-
cates based on the relation mention dictionary DR. If the
edge label relv1v2
is empty, e.g., the edge label between
nodes “Chinese” and “actor” is empty, we generate candi-
date predicates by applying a data mining method on G.
Section 4.1.3 gives more technical details.Then, based on the data-driven’s idea, we try to match QU
over RDF graph G. Different from the exact match of QS, in
the node-ﬁrst framework, we deﬁne the approximate match
(allowing dis-matching edges) of super semantic query
graph QU as follows:
Deﬁnition 5 (Approximate Match). Consider a super
semantic query graph QU with n vertices v1; . . . ; vn. Each ver-
tex vi has a candidate list Cvi , i ¼ 1; . . . ; n. Each edge vivj also
has a candidate list of Cvivj , where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph
M containing n vertices u1; . . . ; un in RDF graph G is an
approximate match of QU if and only if the following condi-
tions hold:1.2.If vi is mapping to an entity ui, i ¼ 1; . . . ; n; ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n; ui is an
is a triple
entity whosethereis ci(i.e.,type3. It is called part-of-speech tag, also grammatical tagging or word-
category disambiguation, which is the process of marking up a word in
a text (corpus) as corresponding to a particular part of speech, such as
nouns, verbs, adjectives, adverbs, etc.4. These grammatical relationships (called dependencies) that are
deﬁned in [7]. For example, “nsubj” refers to a nominal subject. It is a
noun phrase which is the syntactic subject of a clause.TABLE 2
Entity Mention Dictionary DEEntity MentionReferring Entity“Paul Anderson”
“Paul Anderson”
“USA”
“America”
. . .. . .hPaul_S._Andersoni
hPaul_W._S._Andersoni
hUnited_Statesi
hUnited_Statesi
. . .. . .Conﬁdence
Probability
0.8
0.6
1.0
1.0
. . .. . .huirdf : typecii in RDF graph) and ci must be in Cvi ;
and
(cid:1)(cid:1)! 2 M ) vivj 2 QU . Furthermore, the predicate
8uiuj
Pij associated with uiuj(cid:1)(cid:1)! is in Cvivj , 1 (cid:3) i; j (cid:3) n.3.The only difference between the approximate match and
match is item (3) of Deﬁnitions 2 and 5: some edges of QU
may not be matched. Let us recall Example 2. The ﬁnal
approximate match is denoted by the bold lines in Fig. 3d.
The edge between node “Paul Anderson” and “actor” (in
QU ) is not matched. The approximate match is used to
address the ambiguity of the query graph’s structure.3 OFFLINE PHASEIn the ofﬂine phase, we build two dictionaries, which are
entity mention dictionary DE and relation mention dictio-
nary DR. They will be used to extract entities and relations
from users’ question sentences in the online phase. Note
that both DE and DR are used in our two frameworks (rela-
tion-ﬁrst framework and node-ﬁrst framework).3.1 Build Entity Mention Dictionary
An entity mention is a surface string that refers to entities.
For example, “Paul Anderson” could refer to the person
hPaul_W._S._Andersoni or hPaul_S._Andersoni. We need to
build an entity mention dictionary DE, such as Table 2, to
map entity mentions to some candidate entities with
conﬁdence probabilities. There are lots of existing work
about entity-mention dictionary construction [8], [9] and the
dictionary-based entity linking [5], [10]. A popular way to
build such a dictionary DE is by crawling Web pages and
aggregating anchor links that point to Wikipedia entity
pages. The frequency with which a mention (anchor text),
m, links to a particular entity (anchor link), c, allows one to
estimate the conditional probability pðcjmÞ [8]. Entity-men-
tion dictionary construction is not our technical contribu-
tion, in this paper, we adopt CrossWikis dictionary [8],
which was computed from a Google crawler of the Web.
The dictionary contains more than 175 million unique
strings with the entities they may represent.3.2 Build Relation Mention Dictionary
A relation mention is a surface string that occurs between a
pair of entities in a sentence [11], such as “be directed by” and
“budget of” in the running example. We need to build a rela-
tion mention dictionary DR, such as Table 4, to map relation
mentions to some candidate predicates or predicate paths.In this paper, we do not discuss how to extract relation
mentions along with their corresponding entity pairs. Lots
of NLP literature about relation extraction study this prob-
lem, such as Patty [12] and ReVerb [13]. For example, Patty
[12] utilizes the dependency structure in sentences and830IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 3
Relation Mentions and Supporting Entity PairsTABLE 4
Relation Mention Dictionary DRRelation Mention“directed by”“uncle of”Supporting Entity Pairs(hResident_Evili, hPaul_W._S._Andersoni),
(hRoman_Holidayi, hWilliam_Wyleri),. . .. . .
(hTed_Kennedyi, hJohn_F._Kennedy,_Jr.i)
(hPeter_Corri, hJim_Corri),. . .. . .ReVerb [13] adopts the n-gram to ﬁnd relation mentions and
the corresponding support set. In this work, we assume that
the relation mentions and their support sets are given. For
example, Table 3 shows two sample relation mentions and
their supporting entity pairs.Suppose that we have a mention set T ¼ frel1; . . . ; relng,
where each reli is a relation mention, i ¼ 1; . . . ; n. Each reli
has a support set of entity pairs that occur in RDF graph,
i.e., Sup ðreliÞ ¼ f ðv1
i Þ; . . . ; ðvm
i Þg. For each reli,
i ¼ 1; . . . ; n, the goal is to mine top-k possible predicates or
predicate paths formed by consecutive predicate edges in
RDF graph, which have semantic equivalence with relation
mention reli.i ; v0mi ; v01Given a relation mention reli, considering each pair
i Þ in Sup ðreliÞ, we ﬁnd all simple paths between vj
i; v0j
ðvj
i
and v0j
i Þ. Let
i
PSðreliÞ ¼ fPathsðvjin RDF graph G, denoted as Pathsðvj
i Þj1 (cid:3) j (cid:3) mg.i ; v0ji; v0jFor efﬁciency considerations, we only ﬁnd simple paths
with no longer than a threshold5. We adopt a bi-directional
BFS (breath-ﬁrst-search) search from vertices vj
to
ﬁnd Pathsðvj
i ; v0j
i Þ. Note that we ignore edge directions (in
RDF graph) in a BFS process.i and v0jiIntuitively, if a predicate path is frequent in PSðreliÞ, it is
a good candidate that has semantic equivalence with rela-
tion mention reli. However, the above simple intuition may
introduce noises. For example, we ﬁnd that (hasGender,
hasGender) is the most frequent predicate path in PS
(“uncle of”). Obviously, it is not a good predicate path to
represent the semantic of relation mention “uncle of”. In
order to eliminate noises, we borrow the intuition of tf-idf
measure [14]. Although (hasGender, hasGender) is frequent
in PS (“uncle of”), it is also frequent in the path sets of other
relation mentions, such as PS (“is parent of”), PS (“is advi-
sor of”) and so on. Thus, (hasGender, hasGender) is not an
important feature for PS (“uncle of”). Formally, we deﬁne tf-
idf value of a predicate path L in the following deﬁnition.
Note that if L is a length-1 predicate path, L is a predicate P .
Deﬁnition 6. Given a predicate path L, the tf-value of L inPSðreliÞ is deﬁned as follows:tfðL; PSðreliÞÞ ¼jfPathsðvji; v0j
Pathsðvji ÞjL 2 Pathsðvj
i; v0ji Þ 2 PSðreliÞgji; v0j
i Þ;The idf-value of L over the whole relation mention setT ¼ frel1; . . . ; relng is deﬁned as follows:idfðL; T Þ ¼ logjT j
jfreli 2 T jL 2 PSðreliÞgj þ 15. We set the threshold as four in our experiments. More details
about the parameter setting will be discussed in Appendix B, available
in the online supplemental material.The tf-idf value of L is deﬁned as follows:tf(cid:5)idfðL; PSðreliÞ; T Þ ¼ tfðL; PSðreliÞÞ (cid:6) idfðL; T ÞWe deﬁne the conﬁdence probability of mapping relationmention rel to predicate or predicate path L as follows.dðrel; LÞ ¼ tf(cid:5)idfðL; PSðreliÞ; T Þ(1)Algorithm 1 in Appendix A, which can be found on
the Computer Society Digital Library at http://doi.
ieeecomputersociety.org/10.1109/TKDE.2017.2766634,
shows the details of ﬁnding top-k predicate paths for
each relation mention. All relation mentions and their corre-
sponding k predicate paths including tf-idf values are col-
lected to form a relation mention dictionary DR.4 RELATION-FIRST FRAMEWORK
4.1 Building Semantic Query Graph
This Section discusses how to identify semantic relations
in a natural language question N, based on which, we build
a semantic query graph QS to represent the query intention
in N.In order to extract the semantic relations in N, we need to
identify the relation mentions in question N. Obviously, we
can simply regard N as a sequence of words. The problem
is to ﬁnd which relation phrases (also regarded as a
sequence of words) are subsequences of N. However, the
ordering of words in a natural language sentence is not
ﬁxed, such as inverted sentences and preposition fronting. For
example, consider a question “In which movies did Li Bingb-
ing star?”. Obviously, “star in” is a relation mention though
it is not a subsequence of N. The phenomenon is known as
“long-distance dependency”. Some NLP (natural language
processing) literature suggest that the dependency structure
is more stable for the relation extraction [12].Therefore, in our work, we ﬁrst apply Stanford Parser [7]
to N to obtain the dependency tree Y . Let us recall the run-
ning example. Fig. 4 shows the dependency tree of N1,
denoted as Y ðN1Þ. The next question is to ﬁnd relation men-
tions occurring in Y ðN1Þ.
Deﬁnition 7. Let us consider a dependency tree Y of a natural
language question N and a relation mention rel. We say that
rel occurs in Y if and only if there exists a connected subtree y
(of Y ) satisfying the following conditions:(1)Each node in y contains one word in rel and y includes
all words in rel.(2) We cannot ﬁnd a subtree y0 of Y , where y0 also satisﬁesthe ﬁrst condition and y is a subtree of y0.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS831Fig. 4. Relationship extraction in Y ðN1Þ.In this case, y is an embedding of relation mention rel in Y .Given a dependency tree Y of a natural language question
N and a relation mention set T ¼ frel1; . . . ; relng, we need to
ﬁnd which relation mentions (in T ) are occurring in Y .4.1.1 Relation Recognition
Given a natural language question N, we propose an algo-
rithm (Algorithm 2 in Appendix A, available in the online sup-
plemental material) to identify all relation mentions in N. In
the ofﬂine phase, we build an inverted index over all relation
mentions in the relation mention dictionary DR. Speciﬁcally,
for each word, it links to a list of relation mentions containing
the word. The basic idea of Algorithm 2 is as follows: For each
node (i.e., a word) wi in Y , we ﬁnd the candidate pattern list
PLi (Lines 1-2). Then, for each node wi, we check whether
there exists a subtree rooted at wi including all words of some
relation mentions in PLi. In order to address this issue, we
propose a depth-ﬁrst search strategy. We probe each path
rooted at wi (Line 3). The search branch stops at a node w0,
where there does not exists a relation mention including w0
and all words along the path between w0 and wi (Note that, w0
is a descendant node of wi.)(Lines 3-4 in Probe function.) We
utilize rel½w(cid:7) to indicate the presence of word w of rel in the
subtree rooted at wi (Line 6). When we ﬁnish all search
branches, if rel½w(cid:7) ¼ 1 for all words w in relation mention rel,
it means that we have found a relation mention rel occurring
in Y and the embedding subtree is rooted at wi (Lines 8-11).
We can ﬁnd the exact embedding (i.e., the subtree) by probing
the paths rooted at wi. We omit the trivial details due to the
space limit. The time complexity of Algorithm 2 is OðjY j2Þ.4.1.2 Finding Associated Nodes
After ﬁnding a relation mention in Y , we then look for the
two associated nodes. If a phrase was recognized as entity/
class mention, it is regarded as a node. Besides, the nodes
are recognized also based on the grammatical subject-like
and object-like relations around the embedding, which are
listed as follow:(1)(2)subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
object-like relations: obj, pobj, dobj, iobjAssume that we ﬁnd an embedding subtree y of a rela-
tion mention rel. We recognize arg1 by checking for each
phrase w in y whether w is an entity/class mention or there
exists the above subject-like relations (by checking the edge
labels in the dependency tree) between w and one of itsFig. 5. Building super semantic query graph.children (note that, the child is not in the embedding sub-
tree). If a subject-like relationship exists, we add the child to
arg1. Likewise, arg2 is recognized by the object-like rela-
tions. When there are still more than one candidates for
each node, we choose the nearest one to rel.On the other hand, when arg1/arg2 is empty after this
step, we introduce several heuristic rules (based some
computational linguistics knowledge [3], [7]) to increase the
recall for ﬁnding nodes. The heuristic rules are applied until
arg1/arg2 becomes none empty.(cid:2) Rule 1: Extend the embedding t with some lightwords, such as prepositions, auxiliaries.(cid:2) Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.(cid:2) Rule 3: If the parent of the root node of t has subject-
like relations with its neighbors, add the child to arg1.
(cid:2) Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the ﬁrst noun phrase in t to arg1/arg2.
If we still cannot ﬁnd node phrases arg1/arg2 after
applying the above heuristical rules, we just discard the
relation mention rel in the further consideration. Finally, we
can ﬁnd all relation mentions occurring in N together with
their embeddings and their node phrases arg1/arg2.
Example 3. Let us recall dependency tree Y in Fig. 4. We get
“what” as the ﬁrst node of relation mention “budget of”
by applying Rule 4. And we can ﬁnd another node “ﬁlm”
as it is a class mention. Therefore, the ﬁrst semantic rela-
tion is h“budget of”, “what”, “ﬁlm”i. Likewise, we can
also ﬁnd another semantic relation h“direct by”, “ﬁlm”,
“Paul Anderson”i.After obtaining all semantic relations in a natural lan-
guage N, we need to build a semantic query graph QS.
Fig. 2b shows an example of QS. In order to build a semantic
query graph QS, we represent each semantic relation
hrel; arg1; arg2i as an edge. Two edges share one common
endpoint if their corresponding semantic relations have one
common node phrase. The formal deﬁnition of a semantic
query graph has been given in Deﬁnition 1.4.1.3 Phrases Mapping
In this Section, we discuss how to map the relation mentions
and node phrases to candidate predicates/predicate paths
and entities/classes, respectively.832IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Mapping Edges of QS. Each edge vivj in QS has a relation
mention relvivj . According to the relation mention dictionary
DR (see Section 3.2), it is straightforward to map relvivj to
some predicates P or predicate paths L. The list is denoted
as Cvivj . For simplicity of notations, we use L in the follow-
ing discussion. Each mapping is associated with a conﬁ-
dence probability dðrel; LÞ (deﬁned in Equation (1)). For
example, edge v2v3 has a relation mention relv2v3 = “direct
Its candidate list Cv2v3 contains three candidates,
by”.
hdirectori, hwriteri, and hproduceri, as shown in Fig. 2c.Mapping Vertices of QS. Let us consider any vertex v in QS.
The phrase associated with v is arg. If arg is a wild-card
(such as wh-word), it can be mapped to all vertices in RDF
graph G. Otherwise, given an constant arg (entity/class
mention), we adopt the dictionary-based entity linking
approach [5] to ﬁnd the candidate entities or classes. We use
notation Cv to denote all candidates with regard to vertex v
in QS. For example, “ﬁlm” in v2 (in Fig. 2) can be linked to a
class node hﬁlmi or an entity node hFilmexi. If arg is
mapped to an entity u or a class c, we use dðarg; uÞ or
dðarg; cÞ to denote the conﬁdence probability.4.2 Query Executing
Given a semantic query graph QS, we discuss how to ﬁnd
top-k subgraph matches over RDF graph G in this Section.
The formal deﬁnition of a subgraph match is given in Deﬁ-
nition 2. We assume that all candidate lists are ranked in the
non-ascending order of the conﬁdence probability. Figs. 2b
and 2c show an example of QS and the candidate lists,
respectively. Each subgraph match of QS has a score. It is
computed from the conﬁdence probabilities of each edge
and vertex mapping. The score is deﬁned as follows.
Deﬁnition 8. Given a semantic query graph QS with n nodes
fv1; . . . ; vng, a subgraph M containing n vertices fu1; . . . ; ung
in RDF graph G is a match of QS. The match score is deﬁned
as follows:ScoreðMÞ ¼ alog ðdðargi; uiÞÞXvi2V ðQS Þ
Xþ ð1 (cid:5) aÞvivj2EðQS Þlog ðdðrelvivj ; PijÞÞ(2)where argi is the phrase of vertex vi, and ui is an entity or a
class in RDF graph G, and relvivj is the relation mention of
edge vivj and Pij is a predicate of edge uiuj
The default value of weight a is 0.5, which means the entity
score and relation score have equivalent status. If we have
enough training data, a can be learned by some ranking mod-
els such as SVM-rank [15]. Details can be found in Section 6.(cid:1)(cid:1)!.
(cid:1)(cid:1)! or ujuiGiven a semantic query graph QS, our goal is to ﬁnd all sub-
graph matches of QS (over RDF graph G) with the top-k match
scores.6 To solve this problem, we designed an enumerative
algorithm (Algorithm 3 in Appendix A, available in the online
supplemental material) with two main pruning methods.The ﬁrst pruning method is to reduce the candidates of
each list (i.e, Cvi and Cvivj ) as many as possible. If a vertex ui
in Cvi cannot be in any subgraph match of QS, ui can be ﬁl-
tered out directly. Let us recall Fig. 2. Vertex u5 is a candi-
date in Cv3 . However, u5 does not have an adjacent
predicate that is mapping to phrase “direct by” in edge v2v3.6. Note that if more than one match have the identical score in the
top-k results, they are only counted once. In other words, we may
return more than k matches if some matches share the same scoreIt means that there exists no subgraph match of QS contain-
ing u5. Therefore, u5 can be pruned safely. This is called
neighborhood-based pruning. It is often used in subgraph
search problem, such as [16].The second method is to stop the search process based on
the top-k match score as early as possible. Obviously, enu-
merating all possible combination is inefﬁcient. If we main-
tain an appropriate enumeration order so that the current
matches are always better than undiscovered matches, we
can terminate the search space as early as possible. The
pseudo codes are given in Algorithm 3 in Appendix A, avail-
able in the online supplemental material. For ease of presen-
tation, we use “candidate list” to symbol relation candidate
list and entity/class candidate list together. Once we deter-
mine a candidate for each candidate list in QS, we obtain a
“selection”. The selection is expressed by a n-length vector,
which n is the total number of candidate list (Line 2 in Algo-
rithm 3). Initially the vector value is 0 which means we select
the ﬁrst candidate for each candidate list (Lines 3-4). Every
time we get the best selection from the heap top of H. We can
build a query graph Q(cid:4) by replacing all vertex/edge labels in
QS using the selected candidates (Lines 5-6). Line 7 applies
an existing subgraph isomorphism algorithm such as VF2 to
ﬁnd all subgraph matches of Q(cid:4) over G. Then we maintain
the maximum heap H to guarantee each selection we get
from H has the highest score among all untried selection as
showed in Line 8-10. For each candidate list Li, we add one
at the ith bit in current selection G to get a new selection and
put it into H. Thus we can early termination when we ﬁnd k
matches as showed in lines 11-12 in Algorithm 3.5 NODE-FIRST FRAMEWORK
5.1 Building Super Semantic Query Graph
There are three steps in building Super Semantic Query
graph QU : node recognition, query graph structure con-
struction and phrase mapping.5.1.1 Node Recognition
The ﬁrst step is to recognize all nodes from the question sen-
tence N. Generally, we extract entities, classes and wild-
cards as nodes. We adopt the dictionary-based entity linking
approach [5] to ﬁnd entities and classes. We collect all wh-
words and nouns which could not map to any entities and
classes as wild-cards. For example, given a question sen-
tence N2 = “What is the budget of the ﬁlm directed by Paul
Anderson and starred by a Chinese actor?”, the node recog-
nition result is illustrated in Fig. 3a, i.e., “what”, “ﬁlm”,
“Paul Anderson”, “Chinese”, “actor”.5.1.2 Structure Construction
Given that all nodes have been recognized, the next step is to
build a super semantic query graph QU . As mentioned in Sec-
tion 2.3, although our method still relies on the dependency
tree of the question sentence, it is more robust to dependency
errors compared with the relation-ﬁrst framework.Based on Assumption 1 (see Section 2.3.1), we construct the
super semantic query graph QU as follows: Given a node set V
(which has been recognized in the ﬁrst step) and a depen-
dency tree Y of question sentence, for any two nodes vi and vj
(2 V ), we introduce an edge between vi and vj if and only if
the simple path between vi and vj does not contain other node
in V . We propose a DFS based algorithm (see Algorithm 4 in
Appendix A, available in the online supplemental material,HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS833with time complexity OðjY jÞ) to ﬁnd neighbors for each node
and build the super semantic query graph QU .For the question sentence N2, the super semantic query
graph QU is shown in Fig. 5. The node labels are those asso-
ciated entity/class mentions or other phrases. The edge
label of vivj is the words along the simple path between vi
and vj in the dependency tree Y ðN2Þ. For example, the path
between “what” and “ﬁlm” in the dependency tree contains
three words: “is”, “budget” and “of”, thus, the edge label
between v1 and v2 (in QU ) is “(be) budget of ”. If the simple
path does not contain any word (such at the path between
“actor” and “Chinese”), the edge label is empty.5.1.3 Phrases Mapping
In this Section, we discuss how to ﬁnd candidate predicates
and entities/classes for edges and nodes. The methods of map-
ping nodes and labeled edges are the same as phrases map-
ping of QS (see Section 4.1.3). We only concentrate on how to
map the unlabeled edges to predicates in RDF graph G.Mapping Unlabeled Edges of QU . For an unlabeled edge
vivj, the relation between node vi and vj is implicit in given
question. For example, edge v4v5 denotes an implicit rela-
tion, the correspond word sequence in N2 is “Chinese
actor”. We try to infer the implicit relation between the two
given nodes vi and vj based on underlying knowledge
graph. First, we have the following assumptions:(1)Since there is an implicit relation between two nodes
vi and vj, we assume that the distance between vi
and vj in RDF graph G is short enough.(2) Assume that at least one node (vi or vj) is an entity or
a class. It is impossible that two connected nodes are
both wh-words.Similar with the bridging operation in [17], we generate
the candidate predicates as following. If two nodes are both
constants (i.e., entities or classes), such as v4 and v5 in Fig. 3b
(i.e., “Chinese actor”), we locate the two nodes at RDF graph
G and ﬁnd the predicate between them. If one node vi is a
wild-card and the other one vj is an entity or class, we locate
vj in RDF graph G and select the most frequent adjacent
predicates as the candidate predicates to match edge vivj.5.2 Query Executing
Given a super semantic query graph QU , we discuss how to
ﬁnd approximate matches over RDF graph G with the top-k
match scores, where the approximate match is deﬁned in
Deﬁnition 5 and the match score is analogue to Deﬁnition 8.
As mentioned in Deﬁnition 5, some edges (in QU ) are
allowed dis-matching but all nodes should be matched. Con-
sequently, the approximate match of QU is the same with the
exact match (see Deﬁnition 2) of one connected spanning sub-
graph of QU . Thus, a straightforward solution is to enumerate
all spanning subgraphs Si of QU . For each Si, we call Algo-
rithm 3 to ﬁnd the top-k matches of Si. Finally, we collect all
top-k matches for each Si to form answer set RS, and report
k matches with the largest match scores in RS.Obviously, the above solution is not efﬁcient, since there
are lots of common computations if two spanning subgraphs
share common structures with each other. Therefore, we pro-
pose another bottom-up solution. The pseudo codes are
given in Algorithm 5 in Appendix A, available in the
online supplemental material. Different from the baseline
algorithm, we do not decide the query graph at the begin-
ning. Instead we try to construct the “correct” graphstructure by expanding the current partial structure. Gen-
erally, in each step, we extend the current partial struc-
ture Q by expanding one more edge vix, i.e., Q ¼ Q [ vix
(Line 6 in Algorithm 5). Initially, Q only includes one
starting vertex s in QU . We select the vertex with the
smallest number of candidates as the starting vertex s. If
the new expanded partial structure Q can ﬁnd matches
over RDF graph G (Lines 7-11), we continue the search
branch. Furthermore, if Q has already been a spanning
subgraph of QU (Lines 9-11), we record the matches of Q
together with the match scores in answer set RS. We only
keep the current top-k matches in RS and the current
threshold d. If Q cannot ﬁnd matches over RDF graph G
(Lines 12-13), we backtrack the search branch.To improve the search performance, we can also perform
threshold-based pruning (like A(cid:4)-style algorithm) and early
terminate some search branches. For example, for a given
partial structure Q, we estimate the upper bound of the
match score if continually expanding Q. We can derive the
upper bound assuming that all un-mached vertices and
edges (of QU ) can match the candidates with the largest
score. If the upper bound is still smaller than the threshold
d, we can terminate the search branch. We do not discuss
this tangential issue any further.6 EXPERIMENTSWe evaluate our system on DBpedia and Freebase with two
benchmarks separately. For DBpedia, we use QALD7 as the
benchmark. As we know, QALD is a series of open-domain
question answering campaigns, which mainly based on
DBpedia. We compare our method with all systems in
QALD-6 competition as well as DEANNA [18] and Aqqu
[19]. For Freebase, we use WebQuestions [17] as the bench-
mark and compare our method with Sempre [17], Para-
Sempre [20], Aqqu [19], STAGG [21] and Yavuz et al.[22].
To build the relation mention dictionary, we utilize relation
phrases in Patty dataset [12]. We also use the CrossWikis [8]
as the entity mention dictionary. All experiments are imple-
mented in a PC server with Intel Xeon CPU 2 GB Hz, 64 GB
memory running Windows 2008. Our two frameworks (the
relation-ﬁrst framework and the node-ﬁrst framework) are
denoted as RFF and NFF, respectively.6.1 Datasets
DBpedia RDF Repository. (http://blog.dbpedia.org/) is a
comm-unity effort to extract structured information from
Wikipedia and to make this information available on the
Web [23]. We use the version of DBpedia 2014 and the statis-
tics are given in Table 5.Freebase. (https://developers.google.com/freebase/) is a
collaboratively edited knowledge base. We use the version
of Freebase 2013, which is same with [20]. The statistics are
given in Table 5.Patty Relation Mention Dataset[12]. contains a large
resource for textual patterns that denote binary relations
between entities. We use two different relation mention
datasets, wordnet-wikipedia and freebase-wikipedia. The
statistics are given in Table 6. The experiments of ofﬂine
performance can be found in Appendix B, available in the
online supplemental material.7. http://qald.sebastianwalter.org/834IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 5
Statistics of RDF GraphNumber of Entities
Number of Triples
Number of Predicates
Size of RDF Graphs (in GB)DBpedia5.4 million
110 million
9,708
8.7Freebase41 million
596 million
19,456
56.9TABLE 6
Statistics of Relation Mention Dataset# of Textual Patterns
# of Entity Pairs
Average Entity Pair # for each Patternwordnet-
wikipedia
350,568
3,862,304
11freebase-
wikipedia
1,631,530
15,802,947
96.2 Online Performance
Exp 1. (End-to-End Performance) We evaluate our system
both on QALD benchmark and WebQuestions benchmark.
For QALD dataset, we show the experiment results in the
QALD competition report format to enable the comparison
with all systems in QALD-6 (in Table 7). We also repro-
duced DEANNA [18] and Aqqu [19] using the codes pub-
lished by authors. For WebQuestions dataset, we show the
average F1 to compare with previous works. We repro-
duced Aqqu [19] and report the results of other works in
Table 8. In Table 7, “Processed” denotes the number of test
questions that can be processed and “Right” refers to the
number of questions that were answered correctly.For WebQuestions dataset, we use SVM-rank [15] to
learn the weight a of aggregation function (see Deﬁnition 8)
as there are enough training data in WebQuestions. To train
SVM-rank model, we generate several candidate query
graphs with certain entities and relations for each training
question. After matching these query graphs, we calculate
the F1 score as their ranking score. The ﬁnal a in our experi-
ment is 0.136. As there are only 350 training questions of
QALD-6, learning a perfect weight is hard. Therefore, we
use the default value a ¼ 0:5 directly.Effectiveness Evaluation. Our NFF method joined QALD-6
competition and won the second place at F-1 measure.8 NFF
can answer 68 questions correctly, while the relation-ﬁrst
framework (RFF) can answer 40 questions correctly. Gener-
ally, NFF can beat all systems in QALD-6 campaign in F-1
except for CANaLI [24]. Note that CANaLI aims to answer
controlled natural language questions, in which, users need to
specify the precise entities and predicates (denoted by URIs)
in the question sentences. In other words, CANaLI asks users
to do disambiguation task for phrase linking and CANaLI is
not a fully natural language question answering system.Table 8 shows the results on the test set of WebQuestions,
which contains 2032 questions. Different
from QALD
benchmark, WebQuestions has low diversity and most
questions are simple questions. The average F1 of our sys-
tem (49.6 percent) is little less than the state-of-art work [21]
(52.5 percent) and Yavuz et al. [22] (52.6 percent). Compared
by [22] and [21], our approach performs not very well in8. The result of QALD-6 campaign is available at http://qald.
sebastianwalter.org/6/documents/qald-6_results.pdf, and our team is
named NbFramework.TABLE 7
Evaluating QALD-6 Testing Questions
(Total Question Number = 100)Processed Right Recall PrecisionNFF
RFF
CANaLI
UTQA
KWGAnswer
SemGraphQA
UIQA1
UIQA2
DEANNA
Aqqu100
100
100
100
100
100
44
36
100
10068
40
83
63
52
20
21
14
20
360.70
0.43
0.89
0.69
0.59
0.25
0.63
0.53
0.21
0.370.89
0.77
0.89
0.82
0.85
0.70
0.54
0.43
0.74
0.39F-1
0.78
0.55
0.89
0.75
0.70
0.37
0.25
0.17
0.33
0.38TABLE 8
Evaluating WebQuestions Testing QuestionsNFF
RFF
Sempre
ParaSempre
Aqqu
STAGG
Yavuz et al. (2016)Average F149.6%
31.2%
35.7%
39.9%
49.4%
52.5%
52.6%relation extraction, which relies on the relation mention dic-
tionary. Actually, the advantage of our approach lies in
answering complex questions (i.e., multi-hop relation ques-
tions), such as some questions in QALD benchmark. As the
codes of [22] and [21] are not available to us, we compare
our method with Aqqu [19] on QALD. Aqqu performs well
on WebQuestions (49.4 percent) but has a poor performance
on QALD benchmark (38 percent in Table 7). It is because
that the questions in WebQuestions are simpler than QALD
and most of them could be translated into a “one-triple”
query, i.e, have only one entity and one relation. Aqqu
deﬁnes three query templates and try to match test ques-
tions to predeﬁned templates. These three templates cover
almost all of the questions in the WebQuestions benchmark
[19]. However, when Aqqu meets some other questions
which have different representation and could not be
matched to predeﬁned templates,
it would get wrong
answers. For instance, Aqqu could not answer “true-false”
questions such as “Does Trump have any children?”. How-
ever, those questions could be answered correctly by our
system because we do not rely on particular dataset and do
not use any predeﬁned query templates.Efﬁciency Evaluation. We compare the running time of our
two frameworks with DEANNA [18] using QALD-6 data-
set. Fig. 6 shows the experiment results. We test all ques-
tions that can be answered correctly by both DEANNA and
our methods. In the question understanding, DEANNA
needs to generate SPARQLs, our systems generates seman-
tic query graph QS or super semantic query graph QU . The
former has the exponential time complexity, but our meth-
ods have the polynomial time complexity in the question
understanding stage, as we reserved the ambiguity. The rea-
son of NFF is faster than RFF is that RFF spends more time
on relation extraction from a whole dependency tree Y .
Actually, RFF spends OðjY j2Þ time to extraction relations
and build QS (see Algorithm 2 in Appendix, available in the
online supplemental material) while NFF costs OðjY jÞ timeHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS835Fig. 6. Online running time comparison.TABLE 9
Pipeline AccuracyStep1RFF
NFF Node Recognition: 0.92Relation Recognition: 0.65Step2
Building QS: 0.54
Building QU : 0.92Final0.40
0.68to build QU (see Algorithm 4 in Appendix, available in the
online supplemental material).Exp 2. (Pipeline Accuracy of Two Frameworks) In this experi-
ment, we evaluate the accuracies of main steps in both RFF
and NFF using 100 test questions of QALD-6. Table 9 shows
the experiment results. QALD-6 competition report released
the gold standard SPARQL statement for each question sen-
tence in QALD-6. For each sentence N, we suppose that the
generated semantic query graph is QS and super semantic
query graph is QU and the correct SPARQL query is Q. In the
relation-ﬁrst framework (RFF), we say that “relation recog-
nition” is correct if exists a correct one-to-one mapping from
relation mentions (in QS) to predicate edges in SPARQL
query graph Q. Furthermore, we say that QS is correct if QS
is isomorphism to Q. Analogously, if there exists a one-to-
one mapping from nodes in QU to vertices in Q, we say that
the node recognition is correct. QU is correct if exists a con-
nected spanning graph of QU that is isomorphism to Q.By comparing the ﬁrst step (i.e, relation recognition and
node recognition) between RFF and NFF in 100 test ques-
tions, we can see that the node recognition (in NFF) is much
more accurate than relation recognition (in RFF), where the
former’s accuracy is 0.92 and the latter is 0.65. This is the
motivation of NFF framework. Furthermore, the accuracy
of QS is 0.54, which means that 11 questions found wrong
associated argument nodes after recognizing correct rela-
tions. On the contrary, the accuracy of QU is same as the
node recognition (0.92), which means that once all nodes
were recognized correctly, we can build a correct super
semantic query graph QU . In other words, Assumption 1 (in
Section 2.3) of building QU is effective.The ﬁnal accuracy of RFF and NFF are 0.40 and 0.68,
respectively, which means 40 and 68 percent of questions
that can be answered correctly in the two frameworks. In
some cases, even if we can generate a correct QS or QU , we
may get the wrong answers. The reason of that is mainly
because of out-of-dictionary entities/relations or complex
aggregation operations that cannot be handled by our frame-
works. The details of error analysis will be given in Exp 4.Exp 3. (Efﬁciency of Query Evaluation in NFF Framework) We
evaluate the efﬁciency of the two approximate subgraphFig. 7. Evaluation methods comparison.matching algorithms in Section 5.2 using the 100 test ques-
tions in QALD-6. The results of 10 questions randomly
selected and the average time of 100 questions are showed in
Fig. 7. For half of the cases, the bottom-up algorithm (Algo-
rithm 5) has obvious advantages, which veriﬁed our analysis
in Section 5.2. In some cases, the performance gap is not clear,
since QU of these questions is an acyclic graph, which means
the problem of approximate matching QU is degenerated into
matching QS. Generally, the average time of the bottom-up
algorithm is faster than the baseline solution by twice.Exp 4. (Failure Analysis) We provide the failure analysis of
our two methods. We consider about QALD benchmark
because it is harder than WebQuestions and more diversi-
ﬁed. The failure analysis will help the improvement of our
RDF Q/A system’s precision.There are four reasons for the failure of some questions
in RFF. The ﬁrst reason is the relation recognition problem,
which accounted for 58 percent. That because many rela-
tions could not be captured by mentions, such as the ques-
tion “Who was on the Apollo 11 mission”. Some relations
even be implicit such as “Czech movie”. The second one is
wrong nodes. For example, “In which countries do people
speak Japanese?”, the correct semantic relation is hspeak,
Japanese, countryi, however, we found the semantic rela-
tion hspeak, people, countryi. The latter two reasons are
same as the reasons in NFF. Notice that relation mapping
failure is a part of relation recognition failure. We give the
ratio of each reason with an example in Table 10.There are three reasons for the failure of some questions in
NFF. The ﬁrst reason is the node recognition problem. Some
phrases were recognized as nodes by mistake. For example,
“Who composed the soundtrack for Cameron’s Titanic”. We
regarded the noun “soundtrack” as a variable node, however,
it should be ignored. The second one is the failure of phrase
mapping, which means we could not ﬁnd the correct referred
entity/relation for a given mention. For example, “What is
Batman’s real name”. The correct relation halterEgoi is not
occurred in the candidate list of mention “real name” in our
relation mention dictionary DR. The third one is that our
method cannot answer some complex aggregation questions.
We give the ratio of each reason with an example in Table 11.7 RELATED WORKQ/A (natural language question answering) has a quite
long history since the seventies of last century [25]. Gener-
ally, the solutions of knowledge base QA can be mainly
divided into two categories.836IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018TABLE 10
Failure Analysis of Relation-First FrameworkTABLE 11
Failure Analysis of Node-ﬁrst FrameworkReasonRelation FailureNodes Failure#(Ratio)35 (58 %)11 (18 %)Entity Mapping
Complex Aggregation5 (9 %)
9 (15 %)Sample ExampleReasonQ4: Who was on the
Apollo 11 mission?
Q55: In which countries do
people speak Japanese?
Q32: Who developed Slack?
Q80: How short is the
shortest active NBA player?Node Recognition
FailureEntity MappingRelation MappingComplex Aggregation#(Ratio)
8 (25 %) Q27: Who composed theSample Examplesoundtrack for Cameron’s
Titanic?5 (16 %) Q22: Which computer
scientist won an oscar?
10 (31 %) Q100: What is Batman’s
real name?9 (28 %) Q29: Show me allThe ﬁrst one is semantic parsing-based, where natural lan-
guage questions are translated into logical forms, such as
simple (cid:2)-DCS [17], [20], query graph [21], or executable
queries such as SPARQL [18], [19], [26]. [20] deﬁned a set of
logical form templates. DEANNA [18] builds a disambigua-
tion graph and reduces disambiguation as an integer linear
programming problem.The other category is information retrieval-based, where the
systems are not intended to parse the question to a formal
semantic interpretation.
they select candidate
Instead,
answers ﬁrst and then rank them by various methods [2],
[27], [28], [29], [30]. [29] utilizes subgraph embedding to pre-
dict the conﬁdence of candidate answers. [28] maximize the
similarity between the distributed representation of a ques-
tion and its answer candidates using Multi-Column Convo-
lutional Neural Networks (MCCNN), while [2] aims to
predicate the correct relations between topic entity and
answer candidates with text evidence.Our work belongs to the ﬁrst category and differs from
existing systems in three points. First, different from tem-
plate-based works such as [17], [19], [20], [31], our method
does not adopt any manually deﬁned templates. To gap the
mismatch between natural language and the knowledge base,
[20] generates canonical utterances for each candidate logical
form of the given question N, then it ranks the pairs of canoni-
cal utterance and logical form based on a paraphrase model.
However, users should deﬁne logical form templates and the
generation rules ﬁrst. [31] mines millions of operators from
unlabeled data, then learns to compose them to answer ques-
tions using evidence from multiple knowledge bases. It still
uses predeﬁned templates to map questions to queries. Simi-
larly, [19] designs three query templates and try to match the
given question N to those templates, then generates and ranks
SPARQL queries of each matched template. However, both
the templates and the generation rules are heavily relied on
the particular dataset and could not handle some other ques-
tions. For example, none of above systems could answer true-
false questions like “Does Trump have any children?”. In con-
trast, our system does not rely on templates and could answer
more kinds of questions. We evaluate [19] on the QALD-6
benchmark and the results could be found in Table 7.Second, different from most semantic parsing based sys-
tems, we push down the disambiguation into the query
evaluation stage. Existing solutions, like [26] and [18], gen-
erate the SPARQLs as the intermediate results in the ques-
tion understanding stage. Obviously,
they need to do
disambiguation in this step. For example, DEANNA [18]
proposes an integer
linear programming (ILP)-based
method to address the disambiguation issue. As we know,
ILP is a classical NP-hard problem. Then, in the query eval-
uation stage, the existing methods need to answer these
generated SPARQL queries. Answering SPARQL queriesbasketball players that
are higher than 2 meters.equals to ﬁnding subgraph matches of query graphs Q over
RDF graph [32], which is also an NP-hard problem.Third, our approach have stronger representation power
than most existing solutions. Information retrieval solutions
like [2], ﬁnd the topic entity and try to predicate the relation-
ship between the answer and the topic entity which can
only solve simple questions with one triple. For the ques-
tions have two entities, they utilize predeﬁned patterns in
dependency parse tree to decompose the complex question
to two simple question. However, the precision of such sys-
tem highly depends on the accuracy of the dependency
parse tree, which is pretty low when the question is com-
plex. In contrast, our work (especially NFF) is more robust
to the errors of dependency parse trees.Two recent semantic parsing methods [21] and [22]
achieve the state-of-the-art precisions on WebQuestions
benchmark. [21] builds query graphs from question sen-
tence according to a state transition chain. It ﬁrst recognizes
a topic entity and an inference the relation between the topic
entity and the answer. Further it allows other entities to
restrict the answer node. The representation power of [21] is
limited because the ﬁnal query graph structure must be a
tree with diameter less than 3. [22] improves semantic
parsing via answer type inference. It transforms a question
to a “subject, relation, object” order by dependency parse
tree patterns and proposes a BLSTM model to predict the
answer type. Finally the answer type can be used to prune
the candidate logic forms generated by the semantic parsing
baseline. This approach cannot tackle the questions uncov-
ered by patterns or complex questions. Different from the
above systems, our approach has stronger representation
power as we do not restrict the query graph’s structure.8 CONCLUSIONIn this paper, we propose a graph data-driven framework to
answer natural language questions over RDF graphs. Differ-
ent from existing work, we allow the ambiguity both of
phrases and structure in the question understanding stage.
We push down the disambiguation into the query evalua-
tion stage. Based on the query results over RDF graphs, we
can address the ambiguity issue efﬁciently. In other words,
we combine the disambiguation and query evaluation in an
the graph data-driven
uniform process. Consequently,
framework not only improves the precision but also speeds
up the whole performance of RDF Q/A system.ACKNOWLEDGMENTSThis work was supported by The National Key Research and
Development Program of China under grant 2016YFB1000603HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS837and NSFC under grants 61622201, 61532010, and 61370055. Jef-
frey Xu Yu was supported by the Research Grants Council of
the Hong Kong SAR, China No. 14221716 and No. 12258116.REFERENCES[1] V. Lopez, C. Unger, P. Cimiano, and E. Motta, “Evaluating question
answering over linked data,” J. Web Sem., vol. 21, pp. 3–13, 2013.
[2] K. Xu, S. Reddy, Y. Feng, S. Huang, and D. Zhao, “Question answer-
ing on freebase via relation extraction and textual evidence,” in Proc.
54th Annu. Meet. Assoc. Comput. Linguistics, 2016, pp. 2326–2336.
J. Bao, N. Duan, M. Zhou, and T. Zhao, “Knowledge-based ques-
tion answering as machine translation,” in Proc. 52nd Annu. Meet.
Assoc. Comput. Linguistics, 2014, pp. 967–976.[3][4] M. Yahya, K. Berberich, S. Elbassuoni, and G. Weikum, “Robust
question answering over the web of linked data,” in Proc. 22nd
ACM Int. Conf. Inf. Knowl. Manage., 2013, pp. 1107–1116.[5] D. Deng, G. Li, J. Feng, Y. Duan, and Z. Gong, “A uniﬁed frame-
work for approximate dictionary-based entity extraction,” VLDB
J., vol. 24, no. 1, pp. 143–167, 2015.[6] W. M. Soon, H. T. Ng, and D. C. Y. Lim, “A machine learning
approach to coreference resolution of noun phrases,” Comput. Lin-
guist., vol. 27, no. 4, pp. 521–544, 2001.[7] M.-C. de Marneffe and C. D. Manning, “Stanford typed depen-
[Online]. Available: https://nlp.dencies manual,” (2016).
stanford.edu/software/dependencies_manual.pdf[8] V. I. Spitkovsky and A. X. Chang, “A cross-lingual dictionary for
english wikipedia concepts,” in Proc. 8th Int. Conf. Language
Resources Eval., 2012, pp. 3168–3175.[9] A. Chisholm and B. Hachey, “Entity disambiguation with weblinks,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 145–156, 2015.[10] X. Ling, S. Singh, and D. S. Weld, “Design challenges for entity link-
ing,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 315–328, 2015.
[11] N. Nakashole, G. Weikum, and F. M. Suchanek, “Discovering and
exploring relations on the web,” Proc. VLDB Endowment, vol. 5,
no. 12, 2012.[12] N. Nakashole, G. Weikum, and F. M. Suchanek, “PATTY: A tax-
onomy of relational patterns with semantic types,” in Proc. Joint
Conf. Empirical Methods Natural Language Process. Comput. Natural
Language Learn., 2012, pp. 1135–1145.[13] A. Fader, S. Soderland, and O. Etzioni, “Identifying relations for
open information extraction,” in Proc. Conf. Empirical Methods Nat-
ural Language Process., 2011, pp. 1535–1545.[14] C. D. Manning, P. Raghavan, and H. Sch€utze, Introduction to Infor-mation Retrieval. New York: Cambridge Univ. Press, 2008.[15] T.Joachims, “Optimizing search engines using clickthrough
data,” in Proc. ACM Conf. Knowl. Discovery Data Mining, 2002,
pp. 133–142.[16] P. Zhao and J. Han, “On graph query optimization in large
networks,” Proc. VLDB Endowment, vol. 3, no. 1, pp. 340–351, 2010.
J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on
freebase from question-answer pairs,” in Proc. Conf. Empirical
Methods Natural Language Process., 2013, pp. 1533–1544.[17][18] M. Yahya, K. Berberich, S. Elbassuoni, M. Ramanath, V. Tresp,
and G. Weikum, “Natural language questions for the web of
data,” in Proc. Joint Conf. Empirical Methods Natural Language Pro-
cess. Computat. Natural Language Learn., 2012, pp. 379–390.[20][19] H. Bast and E. Haussmann, “More accurate question answering
on freebase,” in Proc. 24th ACM Int. Conf. Inf. Knowl. Manag., 2015,
pp. 1431–1440.
J. Berant and P. Liang, “Semantic parsing via paraphrasing,” in Proc.
52nd Annu. Meet. Assoc. Comput. Linguistics, 2014, pp. 1415–1425.
[21] W. Yih, M. Chang, X. He, and J. Gao, “Semantic parsing via staged
query graph generation: Question answering with knowledge
base,” in Proc. 53rd Annu. Meet. Assoc. Comput. Linguistics 7th Int.
Joint Conf. Natural Language Process. Asian Fed. Natural Language
Process., 2015, pp. 1321–1331.[22] S. Yavuz, I. Gur, Y. Su, M. Srivatsa, and X. Yan, “Improving
semantic parsing via answer type inference,” in Proc. Conf. Empiri-
cal Methods Natural Language Process., 2016, pp. 149–159.[23] C. Bizer, et al., “DBpedia - a crystallization point for the web ofdata,” J. Web Sem., vol. 7, no. 3, pp. 154–165, 2009.[24] G. M. Mazzeo and C. Zaniolo, “Answering controlled natural lan-
guage questions on RDF knowledge bases,” in Proc. 19th Int. Conf.
Extending Database Technol., 2016, pp. 608–611.[25] R. F. Simmons, “Natural language question-answering systems:1969,” Commun. ACM, vol. 13, no. 1, pp. 15–30, Jan. 1970.[26] C. Unger, L. B€uhmann, J. Lehmann, A.-C. N. Ngomo, D. Gerber,
and P. Cimiano, “Template-based question answering over RDF
data,” in Proc. World Wide Web, 2012, pp. 639–648.[27] A. P. B. Veyseh, “Cross-lingual question answering using common
semantic space,” in Proc. TextGraphs@NAACL-HLT: 10th Workshop
Graph-based Methods Natural Language Process., 2016, pp. 15–19.
[28] L. Dong, F. Wei, M. Zhou, and K. Xu, “Question answering over free-
base with multi-column convolutional neural networks,” in Proc. 53rd
Annu. Meet. Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Lan-
guage Process. Asian Fed. Natural Language Process., 2015, pp. 260–269.[29] A. Bordes, S. Chopra, and J. Weston, “Question answering with
subgraph embeddings,” in Proc. 2014 Conf. Empirical Methods Nat-
ural Language Process., 2014, pp. 615–620.[30] X. Yao and B. V. Durme, “Information extraction over structured
data: Question answering with freebase,” in Proc. 52nd Annu.
Meet. Assoc. Comput. Linguistics, 2014, pp. 956–966.[31] A. Fader, L. Zettlemoyer, and O. Etzioni, “Open question answering
over curated and extracted knowledge bases,” in Proc. 20th ACM
SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 1156–1165.
[32] L. Zou, J. Mo, L. Chen, M. T. €Ozsu, and D. Zhao, “gStore: Answer-
ing SPARQL queries via subgraph matching,” Proc. VLDB Endow-
ment, vol. 4, no. 8, pp. 482–493, 2011.Sen Hu received the BS degree in computer sci-
ence and technology from the Beijing University
of Posts and Telecommunications in 2015. He is
currently working toward the PhD degree in the
Institute of Computer Science and Technology at
Peking University, focusing on knowledge graph
and question answering.Lei Zou received the BS and PhD degrees in
computer science from the Huazhong University
of Science and Technology (HUST), in 2003 and
2009, respectively. Now, he is an associate pro-
fessor in the Institute of Computer Science and
Technology at Peking University. He is also a fac-
ulty member in the Big Data Center at Peking
University and the Beijing Institute of Big Data
Research. His research interests include graph
database and semantic data management.Jeffrey Yu Xu has held teaching positions in the
Institute of Information Sciences an Electronics,
University of Tsukuba, and in the Department of
Computer Science, Australian National University,
Australia. Currently, he is professor in the Depart-
ment of Systems Engineering and Engineering
Management, Chinese University of Hong Kong,
Hong Kong. His current research interests include
graph database, graph mining, and social network
analysis.Haixun Wang received the bachelor’s and mas-
ter’s degrees in computer science from Shanghai
Jiao Tong University in 1994 and 1996, respec-
tively, and the PhD degree in computer science
from the University of California, Louisiana, in
2000. He joined Google Research, Mountain
View, California, in 2013. His research interests
include text analytics, natural language process-
ing, knowledge base, semantic network, artiﬁcial
intelligence, graph data management, etc.Dongyan Zhao received the BS, MS, and PhD
degree from Peking University in 1991, 1994,
and 2000, respectively. Now, he is a professor in
the Institute of Computer Science and Technol-
ogy of Peking University. His research interest is
on information processing and knowledge man-
agement,
including computer network, graph
database, and intelligent agent.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181.2 Our Approach
Although there are still
two stages “question under-
standing” and “query evaluation” in our method, we do notThe second framework takes another perspective. When
there exist some implicit or uncertain relations in N, the
relation-ﬁrst framework often fails to extract such relations.
Therefore, the second framework starts with extracting
nodes from the question sentence N and connects these
nodes to form a query graph. Furthermore, different from
the relation-ﬁrst
framework
allows for the ambiguity of query graph structure at the
beginning. It does not intend to build QS in the question
understanding step. Instead, it builds a super graph QU of
QS that includes uncertain edges. To match QU over the
underlying RDF graph G, we allow for mismatching some
edges in QU ,
i.e., approximate match (Deﬁnition 5). WeSpeciﬁcally, we resolve the ambiguity of natural language
questions at the time when matches of query are found. The
cost of disambiguation is saved if there is no match found.
We call this as the graph data-driven approach for RDF Q/A.
We illustrate the intuition of our method by an example.
Example 1. Consider a subgraph of graph G in Fig. 1a (the
(cid:1)(cid:1)!
subgraph induced by vertices u1, u2, u3 and c1). Edge u2c1
(cid:1)(cid:1)!
says that “Resident Evil: Retribution is a ﬁlm”. Edge u2u1
says that “The budget of Resident Evil: Retribution is $ 65
(cid:1)(cid:1)! says that “Paul W. S. Anderson directed
million”. Edge u2u3
the ﬁlm Resident Evil: Retribution”. The natural language
question N1 is “What is the budget of the ﬁlm directed by
Paul Anderson”. Obviously, the subgraph formed by edges
(cid:1)(cid:1)! is a match of N1. “6.5E7” is a correct
(cid:1)(cid:1)!, u2u1
u2c1
answer. On the other hand, we cannot ﬁnd a match (of N1)
containing h Paul_Anderson_(actor)i inc G, i.e., the phrase
“Paul Anderson” (in N1) cannot map to hPaul_Anderson_
(actor)i. Therefore, we address the ambiguity issue of
phrase linking when the matches are found. We can also
resolve the ambiguity of query graph structure following
the same idea. More details will be discussed in Section 5.
The above example illustrates the intuition of our graph
data-driven approach. A fundamental issue in our method
is how to deﬁne a “match” between a subgraph of G and a
natural language question N. Because N is unstructured
data and G is graph structure data, we should ﬁll the gap
between them. Therefore, we propose a semantic query
graph QS (deﬁned in Deﬁnition 1) to represent the question
semantics of N. An example of QS is given in Fig. 1c, which
represents the semantic of the question N. Answering natu-
ral language question equals to ﬁnding matches of QS over
the underlying RDF graph G. To build QS, we propose two
different frameworks: relation (edge)-ﬁrst and node-ﬁrst.the node-ﬁrstframework,In the ﬁrst framework, we ﬁrst extract semantic relations
based on the dependency tree structure of question senten-
ces to build a semantic query graph QS. A semantic relation
is a triple hrel; arg1; arg2i, where rel is a relation phrase, and
arg1 and arg2 are its associated node phrases. For instance,
h“directed by”,“ﬁlm”,“Paul Anderson”i is a semantic rela-
tion. In QS, two edges share one common endpoint if the
two corresponding relations share one common node
phrase. Each node (entity/class mention) and edge (relation
mention) in QS may have multiple candidates. The ﬁrst
framework addresses the ambiguity of phrase linking when
the matches (see Deﬁnition 2) of QS are found. Note that the
ﬁrst framework does not address the ambiguity of query
graph’s structure and assumes that the query graph can be
uniquely ﬁxed at the question understanding step.(cid:1)(cid:1)! and u2u3generate SPARQL at the question understanding step as
existing solutions do. As we know, a SPARQL query can
also be represented as a query graph, which does not
include any ambiguity. Instead, our method builds a query
graph that represents users’ query intention, but it allows
for the ambiguity at the question understanding stage, such
as the ambiguity of phrase linking and query graph struc-
ture. We resolve the ambiguity when the matches are found
at the query evaluation.Fig. 1. Question answering over RDF dataset.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8252.1 Semantic Query Graph
We deﬁne a semantic query graph (Deﬁnition 1) to repre-
sent the query intention of the question N in a graph struc-
tured way.1. Sixty-ﬁve millionThe core of our graph data-driven solution lies in two
aspects: one is how to build a semantic query graph QS accu-
rately and the other one is how to ﬁnd matches efﬁciently. In
order to address the above issues, we propose two different
frameworks. The ﬁrst one is called “relation (edge)-ﬁrst”. It
means that we always extract relations from the natural lan-
guage question sentence N and represent them as edges.
Then, we assemble these edges to form a semantic queryThere are two key issues in RDF Q/A problem. The ﬁrst
one is how to represent the query intention of the natural lan-
guage question N in a structural way. The second one is how
to address the ambiguity of natural language N. In this paper,
we focus on the ambiguity of phrase linking and query graph
structure (composition) that are mentioned in Section 1.1.Let us see Fig. 2. The subgraph included by vertices c1, u1,
u2 and u3 (in RDF graph G) denotes a match of semantic query
graph QS in Fig. 2b. When the matches are found, we resolve
the ambiguity, e.g., “Paul Anderson” should refer to hPaul_W.
_S._Andersoni rather than others., meanwhile that we ﬁnd the
answers to the question, i.e., “6.5E7”1 is the ﬁlm budget.The problem of this paper is to ﬁnd the answers to a natural
language question N over a RDF graph G. Table 1 lists the
notations used throughout this paper.2 OVERVIEW(4) We conduct extensive experiments over several real
RDF datasets (including QALD benchmark and
WebQuestions benchmark) and compare our system
with some state-of-the-art systems. The performance
of our approach beat the other systems on QALD
benchmark while close to the best on the WebQues-
tions benchmark.If vi is mapping to an entity ui, i ¼ 1; . . . ; n, ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n, ui is an
entity whose type is ci (i.e., there is a triple hui rdf:type
cii in RDF graph) and ci must be in Cvi ; and
(cid:1)(cid:1)! 2 M. Furthermore,
8vivj 2 QS , uiuj
(cid:1)(cid:1)!) is in
(cid:1)(cid:1)! (or ujui
the predicate Pij associated with uiuj
Cvivj , 1 (cid:3) i; j (cid:3) n.(cid:1)(cid:1)! 2 M _ ujui(3)(2)(1) We propose two graph data-driven frameworks for
RDF Q/A task, different from exiting solutions, in
which the disambiguation and query evaluation are
combined together.
framework, we
address ambiguity of phrase linking at the query
evaluation; while in the second framework,
the
ambiguity of phrase linking and query graph’s struc-
ture are both resolved. The graph data-driven frame-
works not only improve the precision but also speed
up query processing time greatly.
In the ofﬂine processing, we propose a graph mining
algorithm to build a relation mention dictionary, i.e.,
mapping natural language phrases to possible predi-
cates, which is used for question understanding in
RDF Q/A.
In the online processing, in order to speed up query
evaluation, we propose efﬁcient top-k (approximate)
graph matching algorithms of matching QS and QU
over RDF graph.(1)As mentioned in the introduction, we want to ﬁnd a
“match” of the semantic query graph QS over RDF graph G.
When the matches are found, we resolve the ambiguity of
natural language question sentence; meanwhile we ﬁnd the
answers to the question. Generally, a “match” is deﬁned
based on subgraph isomorphism. Given a node vi
in a
semantic query graph QS, if vi is an entity phrase or a class
phrase, we can use entity linking algorithm [5] to retrieve all
entity/class (in RDF graph G) that possibly correspond to vi,
denoted as CðviÞ; if vi is a wild-card (such as wh-word), we
assume that CðviÞ contains all vertices in RDF graph G. Anal-
ogously, each edge vivj in QS also maps to a list of candidate
predicates, denoted as Cvivj . Consider the semantic query
graph QS in Fig. 2b. We also visualizes the candidates
for each vertex and edge in QS in Fig. 2c. For example, v3
(“Paul Anderson”) corresponds to hPaul_Anderson_(actor)i,
hPaul_S._Andersoni and hPaul_W._S._Andersoni; and edge
“v2v3” maps to hdirectori, hwriteri and hproduceri. Formally,
we deﬁne the match as follows.
Deﬁnition 2 (Match). Consider a semantic query graph QS
with n nodes fv1; . . . ; vng. Each node vi has a candidate list
Cvi , i ¼ 1; . . . ; n. Each edge vivj also has a candidate list Cvivj ,
where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph M containing n vertices
fu1; . . . ; ung in RDF graph G is a match of QS if and only if
the following conditions hold:(3)(2)In the ﬁrstresolve the ambiguity of phrase linking and query graph
structure together when the approximate matches are
found. Actually, the approximate matching position (in
RDF graph G) deﬁnes the semantic query graph QS that we
aim to build. In other words, we push down resolving the
ambiguity of QS’s structure to the query evaluation stage.
In a nutshell, we make the following contribution.Given the question sentences N1, the corresponding
semantic query graphs QS
1 , nodes
v1, v2 and v3 are associated with “what” (wild-card), “ﬁlm”
(a class phrase) and “Paul Anderson” (an entity phrase),
respectively. The relation phrase “(be) budget of ” denotes
the relation between v1 and v2, as well as the relation phrase
“directed by” between v2 and v3.GðV; EÞ
N
Q
QS
QU
Y
DE=DR
vi/ui
Cvi /CvivjRDF graph and vertex and edge sets
A natural language question
A SPARQL query (of N)
The Semantic Query Graph (of N)
The Super Semantic Query Graph (of N)
The dependency tree (of N)
The entity/relation mention dictionary
A vertex in query graph / RDF graph
Candidate mappings of vertex vi / edge vivj1 is given in Fig. 2b. In QSDeﬁnition 1 (Semantic Query Graph). A semantic query
graph (denoted as QS) is a graph, in which each vertex vi is
associated with an entity phrase, class phrase or wild-cards in
the question sentence N; and each edge vivj is associated with a
relation phrase in the question sentence N, 1 (cid:3) i; j (cid:3) jV ðQSÞj.NotationDeﬁnition and DescriptionTABLE 1
Notations826IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20182.2.1 Question Understanding
The goal of the question understanding in the ﬁrst frame-
work is to build a semantic query graph QS for representing
users’ query intention in N. Speciﬁcally, we ﬁrst extract all
semantic relations in N, each of which corresponds to an
edge in QS. The semantic relation extraction is based on the
dependency tree of users’ question sentence and a relation
mention dictionary (see more details in Section 4.1). If the
two semantic relations have one common node, they share
one endpoint in QS. In the running example, we get two
semantic relations, i.e., h“directed by”, “ﬁlm”,“Paul Ander-
son”i and h“budget of”, “what”,“ﬁlm”i, as shown in Fig. 2.
They can be combined through the common node phrase
“ﬁlm” as showed in Fig. 2c. In addition, if two node phrasesConsidering the above two obstacles, we design a robust
framework even in the presence of implicit relations and
mistakes in the dependency parse tree. There are two key
points in the second framework:2.3 Node-First Framework
The relation-ﬁrst framework has two main obstacles. The
ﬁrst is that some relations are difﬁcult to be extracted. If the
relation does not explicitly appeared in the question sen-
tence, it is difﬁcult to extract such semantic relations, since
our relation extraction relies on the relation mention in the
relation mention dictionary. Let us consider two examples
“show me all ﬁlms started by a Chinese actor”, “show me all
ﬁlms stared by an actor who was born in China”. Obviously,
the latter question has one explicit relation mention “(be)
born in”, where the relation in the former one is implicitly
mentioned. Therefore, it is difﬁcult to extract these implicit
relations. Second, in the relation-ﬁrst framework, semantic
relation extraction relies on the syntactic dependency tree of
users’ question sentence and heuristic linguistic rules. If the
syntactic dependency tree has some mistakes, it inevitably
leads to wrong semantic query graph QS’s structure and
wrong answers.In the running example, h“directed by”, “ﬁlm”,“Paul
Anderson”i is a semantic relation, in which “directed by” is a
relation mention (phrase), “who” and “actor” are its associ-
ated node phrases. We can also ﬁnd another semantic relation
h“budget of”, “what”,“ﬁlm”i from the question sentence N1.2.2 Relation-First Framework
Given a natural language question sentence N, the relation-
ﬁrst framework begins with extracting semantic relations
(edge together with two end points) from N.
Deﬁnition 3 (Semantic Relation). A semantic relation is a
triple hrel; arg1; arg2i, where rel is a relation mention, arg1
and arg2 are the two node phrases.Each subgraph match has a score, which is derived from
the conﬁdences of each edge and vertex mapping. Deﬁnition
8 deﬁnes the score, which we will discuss later. Our goal is to
ﬁnd all subgraph matches with the top-k scores. A best-ﬁrst
algorithm is proposed in Section 4.2 to address this issue.
Each subgraph match of QS implies an answer to the natural
language question N, meanwhile, the ambiguity is resolved.graph. The second framework takes another perspective,
called “node-ﬁrst”. It starts with ﬁnding nodes (entity/class
phrases and wild-cards) and try to introduce edges to con-
nect them to form a semantic query graph QS. Furthermore,
another major difference between the two frameworks is
that the node-ﬁrst framework deﬁnes a super graph (called
QU ) of QS when there exist some implicit or uncertain rela-
tions in the question sentence. In other words, the node-ﬁrst
framework is not to ﬁx the QS’s structure before subgraph
matching evaluation as the relation-ﬁrst framework does.2.2.2 Query Executing
As mentioned earlier, a semantic query graph QS is a
structural representation of N. In order to answer N, we
need to ﬁnd subgraphs of RDF graph G that match QS. The
match is deﬁned according to the subgraph isomorphism
(see Deﬁnition 2)refer to same thing after “coreference resolution” [6], we
also combine the corresponding two semantic relations.Fig. 2. Question answering with semantic query graph in relation-ﬁrst framework.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS827tains every vertex of Q.ond framework.
Example 2. Consider N2 in Fig. 3. “What is the budget of the
ﬁlm directed by Paul Anderson and starred by a Chinese
actor?”. The correct SPARQL query of N2 has two addi-
tional triples than N1, which are t1 ¼ h?ﬁlm,starring, ?actori
and t2 ¼ h?actor, country,Chinai. The relation-ﬁrst frame-
work cannot generate t2 because the predicate “country”
has no explicit relation mention in N2. In the node-ﬁrst
framework, we introduce an edge between v4 (“actor”) and
v5 (“Chinese”) in Fig. 3b, whose edge label is empty. For
detected relation mention “starred by”, it is difﬁcult to
determine its corresponding two nodes. There are three can-
didate nodes: “Paul Anderson”, “ﬁlm”, and “actor”. In QU ,
we introduce two edges between “ﬁlm” and “actor”; and
“Paul Anderson” and “actor”. In the query evaluation step,
we perform the approximate match (deﬁned in Deﬁnition 5)
to match QU with RDF graph G, i.e., ﬁnding the occurrences
of QU in RDF graph G with (possible) mismatching edges.2. A spanning subgraph for graph Q is a subgraph of Q which con-we propose a simple yet effective assumption:
Assumption 1. Two nodes v1 and v2 has a semantic relation if
and only if there exists no other node v(cid:4) that occurs in the sim-
ple path between v1 and v2 of the dependency parse tree of ques-
tion sentence N.To eliminate more noises and reduce the search space,2.3.1 Question Understanding
Given a natural language question sentence N, we ﬁrst
extract all constant nodes from N by applying entity extrac-
tion algorithms, which are referred to entities or classes. We
also extract all wh-words (such as who, what and which
et al.) from N as variable nodes. Then, to build QU , we need
to introduce an edge between two nodes if there is a seman-
tic relation between them. A naive solution is to introduce
an edge between any two nodes. Obviously, this method
introduces more noises and ambiguity for the query graph’s
structure. On the other hand, the approximate match in the
node-ﬁrst framework allows mis-matching one or more
edges in QU . The naive solution leads to Oð2nÞ possible
matching structures in the ﬁnal evaluation step, where n is
the number of nodes in QU . This is quite costly.The following example illustrates the intuition of the sec-(2) We do not intend to build a semantic query graph QS
at the question understanding step. Instead, we build
a super semantic query graph QU , which possibly has
some uncertain or implicit relations (i.e., edges). In
other words, we allows the structure ambiguity of
query graph in the question understanding step,
which will be resolved at the query evaluation step.
A super semantic query graph QU is analogue to QS (see Deﬁ-
nition 4), but allows for explicit or uncertain relations (edges).
Deﬁnition 4 (Super Semantic Query Graph). A super
semantic query graph (denoted as QU ) is a graph, in which
each vertex vi is associated with an entity phrase, class phrase or
wild-card in the question sentence N; and each edge vivj is asso-
ciated with a relation in N, 1 (cid:3) i; j (cid:3) jV ðQU Þj. If the relation is
explicit, the edge label is the relation mention occurring in N;
otherwise, the edge label is empty when the relation is implicit.In this example, the ﬁnal match is denoted using bold lines
in Fig. 3, in which the edge between “Paul Anderson” and
“actor” (in QU ) is not matched.
It is easy to infer that an approximate match of QU equals to
an exact match of a connected spanning subgraph2 of QU ,
where the spanning subgraph is the semantic query graph
QS that we aim to build. Therefore, in the second framework,
we ﬁx the semantic query graph QS when the matches are
found; meanwhile the answers to the question have been
found. In other words, we resolve the “structure ambiguity”
of query graph at the time the matches are found. We also
brieﬂy discuss the two steps of the node-ﬁrst framework as
follows. More technical details are given in Section 5.The ﬁrst step is to extract node phrases (such as
entity phrase, class phrase and wh-words) from the
question sentence N, instead of relation extraction in
the ﬁrst framework.(1)Fig. 3. Question answering with super semantic query graph in node-ﬁrst framework.828IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018In this paper, we do not discuss how to extract relation
mentions along with their corresponding entity pairs. Lots
of NLP literature about relation extraction study this prob-
lem, such as Patty [12] and ReVerb [13]. For example, Patty
[12] utilizes the dependency structure in sentences and4. These grammatical relationships (called dependencies) that are
deﬁned in [7]. For example, “nsubj” refers to a nominal subject. It is a
noun phrase which is the syntactic subject of a clause.3. It is called part-of-speech tag, also grammatical tagging or word-
category disambiguation, which is the process of marking up a word in
a text (corpus) as corresponding to a particular part of speech, such as
nouns, verbs, adjectives, adverbs, etc.3.2 Build Relation Mention Dictionary
A relation mention is a surface string that occurs between a
pair of entities in a sentence [11], such as “be directed by” and
“budget of” in the running example. We need to build a rela-
tion mention dictionary DR, such as Table 4, to map relation
mentions to some candidate predicates or predicate paths.is ciIf vi is mapping to an entity ui, i ¼ 1; . . . ; n; ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n; ui is an
is a triple
entity whosetypethere(i.e.,2.1.Then, based on the data-driven’s idea, we try to match QU
over RDF graph G. Different from the exact match of QS, in
the node-ﬁrst framework, we deﬁne the approximate match
(allowing dis-matching edges) of super semantic query
graph QU as follows:
Deﬁnition 5 (Approximate Match). Consider a super
semantic query graph QU with n vertices v1; . . . ; vn. Each ver-
tex vi has a candidate list Cvi , i ¼ 1; . . . ; n. Each edge vivj also
has a candidate list of Cvivj , where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph
M containing n vertices u1; . . . ; un in RDF graph G is an
approximate match of QU if and only if the following condi-
tions hold:3.1 Build Entity Mention Dictionary
An entity mention is a surface string that refers to entities.
For example, “Paul Anderson” could refer to the person
hPaul_W._S._Andersoni or hPaul_S._Andersoni. We need to
build an entity mention dictionary DE, such as Table 2, to
map entity mentions to some candidate entities with
conﬁdence probabilities. There are lots of existing work
about entity-mention dictionary construction [8], [9] and the
dictionary-based entity linking [5], [10]. A popular way to
build such a dictionary DE is by crawling Web pages and
aggregating anchor links that point to Wikipedia entity
pages. The frequency with which a mention (anchor text),
m, links to a particular entity (anchor link), c, allows one to
estimate the conditional probability pðcjmÞ [8]. Entity-men-
tion dictionary construction is not our technical contribu-
tion, in this paper, we adopt CrossWikis dictionary [8],
which was computed from a Google crawler of the Web.
The dictionary contains more than 175 million unique
strings with the entities they may represent.2.3.2 Query Executing
First, we ﬁnd candidates for each node and edge in QU ,
which is analogue to the query evaluation of QS in the ﬁrst
framework. According to the entity mention dictionary DE,
for each node, we can obtain a list of candidate entities, clas-
ses. If it is a wh-word, we assume that it can map all vertices
in RDF graph G. For each edge label (i.e., the relation men-
tion relv1v2 ), we also map it to all possible candidate predi-
cates based on the relation mention dictionary DR. If the
edge label relv1v2
is empty, e.g., the edge label between
nodes “Chinese” and “actor” is empty, we generate candi-
date predicates by applying a data mining method on G.
Section 4.1.3 gives more technical details.In the ofﬂine phase, we build two dictionaries, which are
entity mention dictionary DE and relation mention dictio-
nary DR. They will be used to extract entities and relations
from users’ question sentences in the online phase. Note
that both DE and DR are used in our two frameworks (rela-
tion-ﬁrst framework and node-ﬁrst framework).3 OFFLINE PHASELet us recall Example 2. We ﬁrst extract ﬁve nodes:
“what”, “ﬁlm”, “Paul Anderson”, “Chinese”, “actor” from
the question N2. Fig. 5 illustrates the dependency parse tree
Y ðN2Þ of question sentence N2. According to the assumption,
we introduce an edge v1v2 between two nodes v1 and v2 if
there is no other node v(cid:4) in the simple path between v1 and v2
over Y ðN2Þ. The words along the simple path between v1
and v2 form the edge label of v1v2. For example, the edge
label between nodes “what” and “ﬁlm” is “ (be) budget of”.
The edge label between nodes “Chinese” and “node” is
empty, which is the implicit relation. For nodes “Paul Ander-
son” and “actor”, there is no other nodes along the simple
path between them. According to Assumption 1, we intro-
duce an edge between them and the edge label is “directed
by started by”. Due to the same reason, there is another edge
between nodes “ﬁlm” and “actor”. Finally, we obtain the
super semantic query graph QU as shown in Fig. 3b.The only difference between the approximate match and
match is item (3) of Deﬁnitions 2 and 5: some edges of QU
may not be matched. Let us recall Example 2. The ﬁnal
approximate match is denoted by the bold lines in Fig. 3d.
The edge between node “Paul Anderson” and “actor” (in
QU ) is not matched. The approximate match is used to
address the ambiguity of the query graph’s structure.(cid:1)(cid:1)! is in Cvivj , 1 (cid:3) i; j (cid:3) n.huirdf : typecii in RDF graph) and ci must be in Cvi ;
and
(cid:1)(cid:1)! 2 M ) vivj 2 QU . Furthermore, the predicate
8uiuj
Pij associated with uiuj3.“Paul Anderson”
“Paul Anderson”
“USA”
“America”
. . .. . .hPaul_S._Andersoni
hPaul_W._S._Andersoni
hUnited_Statesi
hUnited_Statesi
. . .. . .Conﬁdence
Probability
0.8
0.6
1.0
1.0
. . .. . .Although this method also depends on the dependency
parse tree, it is not like the ﬁrst framework, in which,
extracting semantic relations and node phrases (to build
QS) heavily depend on the parse tree’s structure, POS tag3
and dependency relation (such as subj, obj and et al.)4 In
other words, the node-ﬁrst framework (i.e., the second
framework) is more robust to dependency errors.Entity MentionReferring EntityTABLE 2
Entity Mention Dictionary DEHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS829the ﬁrst condition and y is a subtree of y0.5. We set the threshold as four in our experiments. More details
about the parameter setting will be discussed in Appendix B, available
in the online supplemental material.(2) We cannot ﬁnd a subtree y0 of Y , where y0 also satisﬁesEach node in y contains one word in rel and y includes
all words in rel.(1)Therefore, in our work, we ﬁrst apply Stanford Parser [7]
to N to obtain the dependency tree Y . Let us recall the run-
ning example. Fig. 4 shows the dependency tree of N1,
denoted as Y ðN1Þ. The next question is to ﬁnd relation men-
tions occurring in Y ðN1Þ.
Deﬁnition 7. Let us consider a dependency tree Y of a natural
language question N and a relation mention rel. We say that
rel occurs in Y if and only if there exists a connected subtree y
(of Y ) satisfying the following conditions:jT j
jfreli 2 T jL 2 PSðreliÞgj þ 1idfðL; T Þ ¼ logT ¼ frel1; . . . ; relng is deﬁned as follows:The idf-value of L over the whole relation mention seti ÞjL 2 Pathsðvj
i; v0ji Þ 2 PSðreliÞgji; v0j
Pathsðvji; v0j
i Þ;tfðL; PSðreliÞÞ ¼jfPathsðvjIn order to extract the semantic relations in N, we need to
identify the relation mentions in question N. Obviously, we
can simply regard N as a sequence of words. The problem
is to ﬁnd which relation phrases (also regarded as a
sequence of words) are subsequences of N. However, the
ordering of words in a natural language sentence is not
ﬁxed, such as inverted sentences and preposition fronting. For
example, consider a question “In which movies did Li Bingb-
ing star?”. Obviously, “star in” is a relation mention though
it is not a subsequence of N. The phenomenon is known as
“long-distance dependency”. Some NLP (natural language
processing) literature suggest that the dependency structure
is more stable for the relation extraction [12].PSðreliÞ is deﬁned as follows:Intuitively, if a predicate path is frequent in PSðreliÞ, it is
a good candidate that has semantic equivalence with rela-
tion mention reli. However, the above simple intuition may
introduce noises. For example, we ﬁnd that (hasGender,
hasGender) is the most frequent predicate path in PS
(“uncle of”). Obviously, it is not a good predicate path to
represent the semantic of relation mention “uncle of”. In
order to eliminate noises, we borrow the intuition of tf-idf
measure [14]. Although (hasGender, hasGender) is frequent
in PS (“uncle of”), it is also frequent in the path sets of other
relation mentions, such as PS (“is parent of”), PS (“is advi-
sor of”) and so on. Thus, (hasGender, hasGender) is not an
important feature for PS (“uncle of”). Formally, we deﬁne tf-
idf value of a predicate path L in the following deﬁnition.
Note that if L is a length-1 predicate path, L is a predicate P .
Deﬁnition 6. Given a predicate path L, the tf-value of L in4 RELATION-FIRST FRAMEWORK
4.1 Building Semantic Query Graph
This Section discusses how to identify semantic relations
in a natural language question N, based on which, we build
a semantic query graph QS to represent the query intention
in N.For efﬁciency considerations, we only ﬁnd simple paths
with no longer than a threshold5. We adopt a bi-directional
BFS (breath-ﬁrst-search) search from vertices vj
to
ﬁnd Pathsðvj
i ; v0j
i Þ. Note that we ignore edge directions (in
RDF graph) in a BFS process.i and v0jiAlgorithm 1 in Appendix A, which can be found on
the Computer Society Digital Library at http://doi.
ieeecomputersociety.org/10.1109/TKDE.2017.2766634,
shows the details of ﬁnding top-k predicate paths for
each relation mention. All relation mentions and their corre-
sponding k predicate paths including tf-idf values are col-
lected to form a relation mention dictionary DR.in RDF graph G, denoted as Pathsðvj
i Þj1 (cid:3) j (cid:3) mg.i ; v0jGiven a relation mention reli, considering each pair
i Þ in Sup ðreliÞ, we ﬁnd all simple paths between vj
i; v0j
ðvj
i
and v0j
i Þ. Let
i
PSðreliÞ ¼ fPathsðvji; v0jSuppose that we have a mention set T ¼ frel1; . . . ; relng,
where each reli is a relation mention, i ¼ 1; . . . ; n. Each reli
has a support set of entity pairs that occur in RDF graph,
i.e., Sup ðreliÞ ¼ f ðv1
i Þ; . . . ; ðvm
i Þg. For each reli,
i ¼ 1; . . . ; n, the goal is to mine top-k possible predicates or
predicate paths formed by consecutive predicate edges in
RDF graph, which have semantic equivalence with relation
mention reli.dðrel; LÞ ¼ tf(cid:5)idfðL; PSðreliÞ; T Þ(1)mention rel to predicate or predicate path L as follows.i ; v0mi ; v01We deﬁne the conﬁdence probability of mapping relationtf(cid:5)idfðL; PSðreliÞ; T Þ ¼ tfðL; PSðreliÞÞ (cid:6) idfðL; T ÞReVerb [13] adopts the n-gram to ﬁnd relation mentions and
the corresponding support set. In this work, we assume that
the relation mentions and their support sets are given. For
example, Table 3 shows two sample relation mentions and
their supporting entity pairs.The tf-idf value of L is deﬁned as follows:(hResident_Evili, hPaul_W._S._Andersoni),
(hRoman_Holidayi, hWilliam_Wyleri),. . .. . .
(hTed_Kennedyi, hJohn_F._Kennedy,_Jr.i)
(hPeter_Corri, hJim_Corri),. . .. . .“uncle of”“directed by”Relation MentionSupporting Entity PairsTABLE 3
Relation Mentions and Supporting Entity PairsTABLE 4
Relation Mention Dictionary DR830IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Assume that we ﬁnd an embedding subtree y of a rela-
tion mention rel. We recognize arg1 by checking for each
phrase w in y whether w is an entity/class mention or there
exists the above subject-like relations (by checking the edge
labels in the dependency tree) between w and one of its4.1.3 Phrases Mapping
In this Section, we discuss how to map the relation mentions
and node phrases to candidate predicates/predicate paths
and entities/classes, respectively.(2)subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
object-like relations: obj, pobj, dobj, iobjAfter obtaining all semantic relations in a natural lan-
guage N, we need to build a semantic query graph QS.
Fig. 2b shows an example of QS. In order to build a semantic
query graph QS, we represent each semantic relation
hrel; arg1; arg2i as an edge. Two edges share one common
endpoint if their corresponding semantic relations have one
common node phrase. The formal deﬁnition of a semantic
query graph has been given in Deﬁnition 1.(1)4.1.2 Finding Associated Nodes
After ﬁnding a relation mention in Y , we then look for the
two associated nodes. If a phrase was recognized as entity/
class mention, it is regarded as a node. Besides, the nodes
are recognized also based on the grammatical subject-like
and object-like relations around the embedding, which are
listed as follow:(cid:2) Rule 3: If the parent of the root node of t has subject-
like relations with its neighbors, add the child to arg1.
(cid:2) Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the ﬁrst noun phrase in t to arg1/arg2.
If we still cannot ﬁnd node phrases arg1/arg2 after
applying the above heuristical rules, we just discard the
relation mention rel in the further consideration. Finally, we
can ﬁnd all relation mentions occurring in N together with
their embeddings and their node phrases arg1/arg2.
Example 3. Let us recall dependency tree Y in Fig. 4. We get
“what” as the ﬁrst node of relation mention “budget of”
by applying Rule 4. And we can ﬁnd another node “ﬁlm”
as it is a class mention. Therefore, the ﬁrst semantic rela-
tion is h“budget of”, “what”, “ﬁlm”i. Likewise, we can
also ﬁnd another semantic relation h“direct by”, “ﬁlm”,
“Paul Anderson”i.4.1.1 Relation Recognition
Given a natural language question N, we propose an algo-
rithm (Algorithm 2 in Appendix A, available in the online sup-
plemental material) to identify all relation mentions in N. In
the ofﬂine phase, we build an inverted index over all relation
mentions in the relation mention dictionary DR. Speciﬁcally,
for each word, it links to a list of relation mentions containing
the word. The basic idea of Algorithm 2 is as follows: For each
node (i.e., a word) wi in Y , we ﬁnd the candidate pattern list
PLi (Lines 1-2). Then, for each node wi, we check whether
there exists a subtree rooted at wi including all words of some
relation mentions in PLi. In order to address this issue, we
propose a depth-ﬁrst search strategy. We probe each path
rooted at wi (Line 3). The search branch stops at a node w0,
where there does not exists a relation mention including w0
and all words along the path between w0 and wi (Note that, w0
is a descendant node of wi.)(Lines 3-4 in Probe function.) We
utilize rel½w(cid:7) to indicate the presence of word w of rel in the
subtree rooted at wi (Line 6). When we ﬁnish all search
branches, if rel½w(cid:7) ¼ 1 for all words w in relation mention rel,
it means that we have found a relation mention rel occurring
in Y and the embedding subtree is rooted at wi (Lines 8-11).
We can ﬁnd the exact embedding (i.e., the subtree) by probing
the paths rooted at wi. We omit the trivial details due to the
space limit. The time complexity of Algorithm 2 is OðjY j2Þ.(cid:2) Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.words, such as prepositions, auxiliaries.(cid:2) Rule 1: Extend the embedding t with some lightOn the other hand, when arg1/arg2 is empty after this
step, we introduce several heuristic rules (based some
computational linguistics knowledge [3], [7]) to increase the
recall for ﬁnding nodes. The heuristic rules are applied until
arg1/arg2 becomes none empty.children (note that, the child is not in the embedding sub-
tree). If a subject-like relationship exists, we add the child to
arg1. Likewise, arg2 is recognized by the object-like rela-
tions. When there are still more than one candidates for
each node, we choose the nearest one to rel.Given a dependency tree Y of a natural language question
N and a relation mention set T ¼ frel1; . . . ; relng, we need to
ﬁnd which relation mentions (in T ) are occurring in Y .Fig. 5. Building super semantic query graph.In this case, y is an embedding of relation mention rel in Y .Fig. 4. Relationship extraction in Y ðN1Þ.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS831Based on Assumption 1 (see Section 2.3.1), we construct the
super semantic query graph QU as follows: Given a node set V
(which has been recognized in the ﬁrst step) and a depen-
dency tree Y of question sentence, for any two nodes vi and vj
(2 V ), we introduce an edge between vi and vj if and only if
the simple path between vi and vj does not contain other node
in V . We propose a DFS based algorithm (see Algorithm 4 in
Appendix A, available in the online supplemental material,6. Note that if more than one match have the identical score in the
top-k results, they are only counted once. In other words, we may
return more than k matches if some matches share the same scoreThe ﬁrst pruning method is to reduce the candidates of
each list (i.e, Cvi and Cvivj ) as many as possible. If a vertex ui
in Cvi cannot be in any subgraph match of QS, ui can be ﬁl-
tered out directly. Let us recall Fig. 2. Vertex u5 is a candi-
date in Cv3 . However, u5 does not have an adjacent
predicate that is mapping to phrase “direct by” in edge v2v3.5.1.2 Structure Construction
Given that all nodes have been recognized, the next step is to
build a super semantic query graph QU . As mentioned in Sec-
tion 2.3, although our method still relies on the dependency
tree of the question sentence, it is more robust to dependency
errors compared with the relation-ﬁrst framework.Given a semantic query graph QS, our goal is to ﬁnd all sub-
graph matches of QS (over RDF graph G) with the top-k match
scores.6 To solve this problem, we designed an enumerative
algorithm (Algorithm 3 in Appendix A, available in the online
supplemental material) with two main pruning methods.where argi is the phrase of vertex vi, and ui is an entity or a
class in RDF graph G, and relvivj is the relation mention of
edge vivj and Pij is a predicate of edge uiuj
The default value of weight a is 0.5, which means the entity
score and relation score have equivalent status. If we have
enough training data, a can be learned by some ranking mod-
els such as SVM-rank [15]. Details can be found in Section 6.5.1.1 Node Recognition
The ﬁrst step is to recognize all nodes from the question sen-
tence N. Generally, we extract entities, classes and wild-
cards as nodes. We adopt the dictionary-based entity linking
approach [5] to ﬁnd entities and classes. We collect all wh-
words and nouns which could not map to any entities and
classes as wild-cards. For example, given a question sen-
tence N2 = “What is the budget of the ﬁlm directed by Paul
Anderson and starred by a Chinese actor?”, the node recog-
nition result is illustrated in Fig. 3a, i.e., “what”, “ﬁlm”,
“Paul Anderson”, “Chinese”, “actor”.(cid:1)(cid:1)!.
(cid:1)(cid:1)! or ujuivivj2EðQS Þlog ðdðrelvivj ; PijÞÞ(2)þ ð1 (cid:5) aÞvi2V ðQS Þ
Xlog ðdðargi; uiÞÞScoreðMÞ ¼ aX5 NODE-FIRST FRAMEWORK
5.1 Building Super Semantic Query Graph
There are three steps in building Super Semantic Query
graph QU : node recognition, query graph structure con-
struction and phrase mapping.4.2 Query Executing
Given a semantic query graph QS, we discuss how to ﬁnd
top-k subgraph matches over RDF graph G in this Section.
The formal deﬁnition of a subgraph match is given in Deﬁ-
nition 2. We assume that all candidate lists are ranked in the
non-ascending order of the conﬁdence probability. Figs. 2b
and 2c show an example of QS and the candidate lists,
respectively. Each subgraph match of QS has a score. It is
computed from the conﬁdence probabilities of each edge
and vertex mapping. The score is deﬁned as follows.
Deﬁnition 8. Given a semantic query graph QS with n nodes
fv1; . . . ; vng, a subgraph M containing n vertices fu1; . . . ; ung
in RDF graph G is a match of QS. The match score is deﬁned
as follows:The second method is to stop the search process based on
the top-k match score as early as possible. Obviously, enu-
merating all possible combination is inefﬁcient. If we main-
tain an appropriate enumeration order so that the current
matches are always better than undiscovered matches, we
can terminate the search space as early as possible. The
pseudo codes are given in Algorithm 3 in Appendix A, avail-
able in the online supplemental material. For ease of presen-
tation, we use “candidate list” to symbol relation candidate
list and entity/class candidate list together. Once we deter-
mine a candidate for each candidate list in QS, we obtain a
“selection”. The selection is expressed by a n-length vector,
which n is the total number of candidate list (Line 2 in Algo-
rithm 3). Initially the vector value is 0 which means we select
the ﬁrst candidate for each candidate list (Lines 3-4). Every
time we get the best selection from the heap top of H. We can
build a query graph Q(cid:4) by replacing all vertex/edge labels in
QS using the selected candidates (Lines 5-6). Line 7 applies
an existing subgraph isomorphism algorithm such as VF2 to
ﬁnd all subgraph matches of Q(cid:4) over G. Then we maintain
the maximum heap H to guarantee each selection we get
from H has the highest score among all untried selection as
showed in Line 8-10. For each candidate list Li, we add one
at the ith bit in current selection G to get a new selection and
put it into H. Thus we can early termination when we ﬁnd k
matches as showed in lines 11-12 in Algorithm 3.Mapping Vertices of QS. Let us consider any vertex v in QS.
The phrase associated with v is arg. If arg is a wild-card
(such as wh-word), it can be mapped to all vertices in RDF
graph G. Otherwise, given an constant arg (entity/class
mention), we adopt the dictionary-based entity linking
approach [5] to ﬁnd the candidate entities or classes. We use
notation Cv to denote all candidates with regard to vertex v
in QS. For example, “ﬁlm” in v2 (in Fig. 2) can be linked to a
class node hﬁlmi or an entity node hFilmexi. If arg is
mapped to an entity u or a class c, we use dðarg; uÞ or
dðarg; cÞ to denote the conﬁdence probability.Mapping Edges of QS. Each edge vivj in QS has a relation
mention relvivj . According to the relation mention dictionary
DR (see Section 3.2), it is straightforward to map relvivj to
some predicates P or predicate paths L. The list is denoted
as Cvivj . For simplicity of notations, we use L in the follow-
ing discussion. Each mapping is associated with a conﬁ-
dence probability dðrel; LÞ (deﬁned in Equation (1)). For
example, edge v2v3 has a relation mention relv2v3 = “direct
Its candidate list Cv2v3 contains three candidates,
by”.
hdirectori, hwriteri, and hproduceri, as shown in Fig. 2c.It means that there exists no subgraph match of QS contain-
ing u5. Therefore, u5 can be pruned safely. This is called
neighborhood-based pruning. It is often used in subgraph
search problem, such as [16].832IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Obviously, the above solution is not efﬁcient, since there
are lots of common computations if two spanning subgraphs
share common structures with each other. Therefore, we pro-
pose another bottom-up solution. The pseudo codes are
given in Algorithm 5 in Appendix A, available in the
online supplemental material. Different from the baseline
algorithm, we do not decide the query graph at the begin-
ning. Instead we try to construct the “correct” graph7. http://qald.sebastianwalter.org/[12]. contains a large
resource for textual patterns that denote binary relations
between entities. We use two different relation mention
datasets, wordnet-wikipedia and freebase-wikipedia. The
statistics are given in Table 6. The experiments of ofﬂine
performance can be found in Appendix B, available in the
online supplemental material.5.2 Query Executing
Given a super semantic query graph QU , we discuss how to
ﬁnd approximate matches over RDF graph G with the top-k
match scores, where the approximate match is deﬁned in
Deﬁnition 5 and the match score is analogue to Deﬁnition 8.
As mentioned in Deﬁnition 5, some edges (in QU ) are
allowed dis-matching but all nodes should be matched. Con-
sequently, the approximate match of QU is the same with the
exact match (see Deﬁnition 2) of one connected spanning sub-
graph of QU . Thus, a straightforward solution is to enumerate
all spanning subgraphs Si of QU . For each Si, we call Algo-
rithm 3 to ﬁnd the top-k matches of Si. Finally, we collect all
top-k matches for each Si to form answer set RS, and report
k matches with the largest match scores in RS.Patty Relation Mention DatasetFreebase. (https://developers.google.com/freebase/) is a
collaboratively edited knowledge base. We use the version
of Freebase 2013, which is same with [20]. The statistics are
given in Table 5.6.1 Datasets
DBpedia RDF Repository. (http://blog.dbpedia.org/) is a
comm-unity effort to extract structured information from
Wikipedia and to make this information available on the
Web [23]. We use the version of DBpedia 2014 and the statis-
tics are given in Table 5.We evaluate our system on DBpedia and Freebase with two
benchmarks separately. For DBpedia, we use QALD7 as the
benchmark. As we know, QALD is a series of open-domain
question answering campaigns, which mainly based on
DBpedia. We compare our method with all systems in
QALD-6 competition as well as DEANNA [18] and Aqqu
[19]. For Freebase, we use WebQuestions [17] as the bench-
mark and compare our method with Sempre [17], Para-
Sempre [20], Aqqu [19], STAGG [21] and Yavuz et al.[22].
To build the relation mention dictionary, we utilize relation
phrases in Patty dataset [12]. We also use the CrossWikis [8]
as the entity mention dictionary. All experiments are imple-
mented in a PC server with Intel Xeon CPU 2 GB Hz, 64 GB
memory running Windows 2008. Our two frameworks (the
relation-ﬁrst framework and the node-ﬁrst framework) are
denoted as RFF and NFF, respectively.Similar with the bridging operation in [17], we generate
the candidate predicates as following. If two nodes are both
constants (i.e., entities or classes), such as v4 and v5 in Fig. 3b
(i.e., “Chinese actor”), we locate the two nodes at RDF graph
G and ﬁnd the predicate between them. If one node vi is a
wild-card and the other one vj is an entity or class, we locate
vj in RDF graph G and select the most frequent adjacent
predicates as the candidate predicates to match edge vivj.(2) Assume that at least one node (vi or vj) is an entity or
a class. It is impossible that two connected nodes are
both wh-words.Since there is an implicit relation between two nodes
vi and vj, we assume that the distance between vi
and vj in RDF graph G is short enough.(1)6 EXPERIMENTSMapping Unlabeled Edges of QU . For an unlabeled edge
vivj, the relation between node vi and vj is implicit in given
question. For example, edge v4v5 denotes an implicit rela-
tion, the correspond word sequence in N2 is “Chinese
actor”. We try to infer the implicit relation between the two
given nodes vi and vj based on underlying knowledge
graph. First, we have the following assumptions:To improve the search performance, we can also perform
threshold-based pruning (like A(cid:4)-style algorithm) and early
terminate some search branches. For example, for a given
partial structure Q, we estimate the upper bound of the
match score if continually expanding Q. We can derive the
upper bound assuming that all un-mached vertices and
edges (of QU ) can match the candidates with the largest
score. If the upper bound is still smaller than the threshold
d, we can terminate the search branch. We do not discuss
this tangential issue any further.5.1.3 Phrases Mapping
In this Section, we discuss how to ﬁnd candidate predicates
and entities/classes for edges and nodes. The methods of map-
ping nodes and labeled edges are the same as phrases map-
ping of QS (see Section 4.1.3). We only concentrate on how to
map the unlabeled edges to predicates in RDF graph G.structure by expanding the current partial structure. Gen-
erally, in each step, we extend the current partial struc-
ture Q by expanding one more edge vix, i.e., Q ¼ Q [ vix
(Line 6 in Algorithm 5). Initially, Q only includes one
starting vertex s in QU . We select the vertex with the
smallest number of candidates as the starting vertex s. If
the new expanded partial structure Q can ﬁnd matches
over RDF graph G (Lines 7-11), we continue the search
branch. Furthermore, if Q has already been a spanning
subgraph of QU (Lines 9-11), we record the matches of Q
together with the match scores in answer set RS. We only
keep the current top-k matches in RS and the current
threshold d. If Q cannot ﬁnd matches over RDF graph G
(Lines 12-13), we backtrack the search branch.For the question sentence N2, the super semantic query
graph QU is shown in Fig. 5. The node labels are those asso-
ciated entity/class mentions or other phrases. The edge
label of vivj is the words along the simple path between vi
and vj in the dependency tree Y ðN2Þ. For example, the path
between “what” and “ﬁlm” in the dependency tree contains
three words: “is”, “budget” and “of”, thus, the edge label
between v1 and v2 (in QU ) is “(be) budget of ”. If the simple
path does not contain any word (such at the path between
“actor” and “Chinese”), the edge label is empty.with time complexity OðjY jÞ) to ﬁnd neighbors for each node
and build the super semantic query graph QU .HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8338. The result of QALD-6 campaign is available at http://qald.
sebastianwalter.org/6/documents/qald-6_results.pdf, and our team is
named NbFramework.Efﬁciency Evaluation. We compare the running time of our
two frameworks with DEANNA [18] using QALD-6 data-
set. Fig. 6 shows the experiment results. We test all ques-
tions that can be answered correctly by both DEANNA and
our methods. In the question understanding, DEANNA
needs to generate SPARQLs, our systems generates seman-
tic query graph QS or super semantic query graph QU . The
former has the exponential time complexity, but our meth-
ods have the polynomial time complexity in the question
understanding stage, as we reserved the ambiguity. The rea-
son of NFF is faster than RFF is that RFF spends more time
on relation extraction from a whole dependency tree Y .
Actually, RFF spends OðjY j2Þ time to extraction relations
and build QS (see Algorithm 2 in Appendix, available in the
online supplemental material) while NFF costs OðjY jÞ timeTable 8 shows the results on the test set of WebQuestions,
which contains 2032 questions. Different
from QALD
benchmark, WebQuestions has low diversity and most
questions are simple questions. The average F1 of our sys-
tem (49.6 percent) is little less than the state-of-art work [21]
(52.5 percent) and Yavuz et al. [22] (52.6 percent). Compared
by [22] and [21], our approach performs not very well inEffectiveness Evaluation. Our NFF method joined QALD-6
competition and won the second place at F-1 measure.8 NFF
can answer 68 questions correctly, while the relation-ﬁrst
framework (RFF) can answer 40 questions correctly. Gener-
ally, NFF can beat all systems in QALD-6 campaign in F-1
except for CANaLI [24]. Note that CANaLI aims to answer
controlled natural language questions, in which, users need to
specify the precise entities and predicates (denoted by URIs)
in the question sentences. In other words, CANaLI asks users
to do disambiguation task for phrase linking and CANaLI is
not a fully natural language question answering system.relation extraction, which relies on the relation mention dic-
tionary. Actually, the advantage of our approach lies in
answering complex questions (i.e., multi-hop relation ques-
tions), such as some questions in QALD benchmark. As the
codes of [22] and [21] are not available to us, we compare
our method with Aqqu [19] on QALD. Aqqu performs well
on WebQuestions (49.4 percent) but has a poor performance
on QALD benchmark (38 percent in Table 7). It is because
that the questions in WebQuestions are simpler than QALD
and most of them could be translated into a “one-triple”
query, i.e, have only one entity and one relation. Aqqu
deﬁnes three query templates and try to match test ques-
tions to predeﬁned templates. These three templates cover
almost all of the questions in the WebQuestions benchmark
[19]. However, when Aqqu meets some other questions
which have different representation and could not be
matched to predeﬁned templates,
it would get wrong
answers. For instance, Aqqu could not answer “true-false”
questions such as “Does Trump have any children?”. How-
ever, those questions could be answered correctly by our
system because we do not rely on particular dataset and do
not use any predeﬁned query templates.For WebQuestions dataset, we use SVM-rank [15] to
learn the weight a of aggregation function (see Deﬁnition 8)
as there are enough training data in WebQuestions. To train
SVM-rank model, we generate several candidate query
graphs with certain entities and relations for each training
question. After matching these query graphs, we calculate
the F1 score as their ranking score. The ﬁnal a in our experi-
ment is 0.136. As there are only 350 training questions of
QALD-6, learning a perfect weight is hard. Therefore, we
use the default value a ¼ 0:5 directly.6.2 Online Performance
Exp 1. (End-to-End Performance) We evaluate our system
both on QALD benchmark and WebQuestions benchmark.
For QALD dataset, we show the experiment results in the
QALD competition report format to enable the comparison
with all systems in QALD-6 (in Table 7). We also repro-
duced DEANNA [18] and Aqqu [19] using the codes pub-
lished by authors. For WebQuestions dataset, we show the
average F1 to compare with previous works. We repro-
duced Aqqu [19] and report the results of other works in
Table 8. In Table 7, “Processed” denotes the number of test
questions that can be processed and “Right” refers to the
number of questions that were answered correctly.NFF
RFF
Sempre
ParaSempre
Aqqu
STAGG
Yavuz et al. (2016)49.6%
31.2%
35.7%
39.9%
49.4%
52.5%
52.6%Average F1# of Textual Patterns
# of Entity Pairs
Average Entity Pair # for each Patternwordnet-
wikipedia
350,568
3,862,304
11freebase-
wikipedia
1,631,530
15,802,947
9TABLE 8
Evaluating WebQuestions Testing QuestionsNFF
RFF
CANaLI
UTQA
KWGAnswer
SemGraphQA
UIQA1
UIQA2
DEANNA
Aqqu100
100
100
100
100
100
44
36
100
10068
40
83
63
52
20
21
14
20
360.70
0.43
0.89
0.69
0.59
0.25
0.63
0.53
0.21
0.370.89
0.77
0.89
0.82
0.85
0.70
0.54
0.43
0.74
0.39F-1
0.78
0.55
0.89
0.75
0.70
0.37
0.25
0.17
0.33
0.38TABLE 6
Statistics of Relation Mention DatasetNumber of Entities
Number of Triples
Number of Predicates
Size of RDF Graphs (in GB)5.4 million
110 million
9,708
8.741 million
596 million
19,456
56.9Processed Right Recall PrecisionDBpediaFreebaseTABLE 7
Evaluating QALD-6 Testing Questions
(Total Question Number = 100)TABLE 5
Statistics of RDF Graph834IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Q/A (natural language question answering) has a quite
long history since the seventies of last century [25]. Gener-
ally, the solutions of knowledge base QA can be mainly
divided into two categories.Exp 3. (Efﬁciency of Query Evaluation in NFF Framework) We
evaluate the efﬁciency of the two approximate subgraphThe ﬁnal accuracy of RFF and NFF are 0.40 and 0.68,
respectively, which means 40 and 68 percent of questions
that can be answered correctly in the two frameworks. In
some cases, even if we can generate a correct QS or QU , we
may get the wrong answers. The reason of that is mainly
because of out-of-dictionary entities/relations or complex
aggregation operations that cannot be handled by our frame-
works. The details of error analysis will be given in Exp 4.7 RELATED WORKThere are three reasons for the failure of some questions in
NFF. The ﬁrst reason is the node recognition problem. Some
phrases were recognized as nodes by mistake. For example,
“Who composed the soundtrack for Cameron’s Titanic”. We
regarded the noun “soundtrack” as a variable node, however,
it should be ignored. The second one is the failure of phrase
mapping, which means we could not ﬁnd the correct referred
entity/relation for a given mention. For example, “What is
Batman’s real name”. The correct relation halterEgoi is not
occurred in the candidate list of mention “real name” in our
relation mention dictionary DR. The third one is that our
method cannot answer some complex aggregation questions.
We give the ratio of each reason with an example in Table 11.By comparing the ﬁrst step (i.e, relation recognition and
node recognition) between RFF and NFF in 100 test ques-
tions, we can see that the node recognition (in NFF) is much
more accurate than relation recognition (in RFF), where the
former’s accuracy is 0.92 and the latter is 0.65. This is the
motivation of NFF framework. Furthermore, the accuracy
of QS is 0.54, which means that 11 questions found wrong
associated argument nodes after recognizing correct rela-
tions. On the contrary, the accuracy of QU is same as the
node recognition (0.92), which means that once all nodes
were recognized correctly, we can build a correct super
semantic query graph QU . In other words, Assumption 1 (in
Section 2.3) of building QU is effective.There are four reasons for the failure of some questions
in RFF. The ﬁrst reason is the relation recognition problem,
which accounted for 58 percent. That because many rela-
tions could not be captured by mentions, such as the ques-
tion “Who was on the Apollo 11 mission”. Some relations
even be implicit such as “Czech movie”. The second one is
wrong nodes. For example, “In which countries do people
speak Japanese?”, the correct semantic relation is hspeak,
Japanese, countryi, however, we found the semantic rela-
tion hspeak, people, countryi. The latter two reasons are
same as the reasons in NFF. Notice that relation mapping
failure is a part of relation recognition failure. We give the
ratio of each reason with an example in Table 10.Exp 2. (Pipeline Accuracy of Two Frameworks) In this experi-
ment, we evaluate the accuracies of main steps in both RFF
and NFF using 100 test questions of QALD-6. Table 9 shows
the experiment results. QALD-6 competition report released
the gold standard SPARQL statement for each question sen-
tence in QALD-6. For each sentence N, we suppose that the
generated semantic query graph is QS and super semantic
query graph is QU and the correct SPARQL query is Q. In the
relation-ﬁrst framework (RFF), we say that “relation recog-
nition” is correct if exists a correct one-to-one mapping from
relation mentions (in QS) to predicate edges in SPARQL
query graph Q. Furthermore, we say that QS is correct if QS
is isomorphism to Q. Analogously, if there exists a one-to-
one mapping from nodes in QU to vertices in Q, we say that
the node recognition is correct. QU is correct if exists a con-
nected spanning graph of QU that is isomorphism to Q.Exp 4. (Failure Analysis) We provide the failure analysis of
our two methods. We consider about QALD benchmark
because it is harder than WebQuestions and more diversi-
ﬁed. The failure analysis will help the improvement of our
RDF Q/A system’s precision.matching algorithms in Section 5.2 using the 100 test ques-
tions in QALD-6. The results of 10 questions randomly
selected and the average time of 100 questions are showed in
Fig. 7. For half of the cases, the bottom-up algorithm (Algo-
rithm 5) has obvious advantages, which veriﬁed our analysis
in Section 5.2. In some cases, the performance gap is not clear,
since QU of these questions is an acyclic graph, which means
the problem of approximate matching QU is degenerated into
matching QS. Generally, the average time of the bottom-up
algorithm is faster than the baseline solution by twice.to build QU (see Algorithm 4 in Appendix, available in the
online supplemental material).RFF
NFF Node Recognition: 0.92Step2
Building QS: 0.54
Building QU : 0.920.40
0.68Relation Recognition: 0.65Step1FinalTABLE 9
Pipeline AccuracyFig. 7. Evaluation methods comparison.Fig. 6. Online running time comparison.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS835This work was supported by The National Key Research and
Development Program of China under grant 2016YFB1000603Second, different from most semantic parsing based sys-
tems, we push down the disambiguation into the query
evaluation stage. Existing solutions, like [26] and [18], gen-
erate the SPARQLs as the intermediate results in the ques-
tion understanding stage. Obviously,
they need to do
disambiguation in this step. For example, DEANNA [18]
proposes an integer
linear programming (ILP)-based
method to address the disambiguation issue. As we know,
ILP is a classical NP-hard problem. Then, in the query eval-
uation stage, the existing methods need to answer these
generated SPARQL queries. Answering SPARQL queriesACKNOWLEDGMENTSIn this paper, we propose a graph data-driven framework to
answer natural language questions over RDF graphs. Differ-
ent from existing work, we allow the ambiguity both of
phrases and structure in the question understanding stage.
We push down the disambiguation into the query evalua-
tion stage. Based on the query results over RDF graphs, we
can address the ambiguity issue efﬁciently. In other words,
we combine the disambiguation and query evaluation in an
the graph data-driven
uniform process. Consequently,
framework not only improves the precision but also speeds
up the whole performance of RDF Q/A system.Our work belongs to the ﬁrst category and differs from
existing systems in three points. First, different from tem-
plate-based works such as [17], [19], [20], [31], our method
does not adopt any manually deﬁned templates. To gap the
mismatch between natural language and the knowledge base,
[20] generates canonical utterances for each candidate logical
form of the given question N, then it ranks the pairs of canoni-
cal utterance and logical form based on a paraphrase model.
However, users should deﬁne logical form templates and the
generation rules ﬁrst. [31] mines millions of operators from
unlabeled data, then learns to compose them to answer ques-
tions using evidence from multiple knowledge bases. It still
uses predeﬁned templates to map questions to queries. Simi-
larly, [19] designs three query templates and try to match the
given question N to those templates, then generates and ranks
SPARQL queries of each matched template. However, both
the templates and the generation rules are heavily relied on
the particular dataset and could not handle some other ques-
tions. For example, none of above systems could answer true-
false questions like “Does Trump have any children?”. In con-
trast, our system does not rely on templates and could answer
more kinds of questions. We evaluate [19] on the QALD-6
benchmark and the results could be found in Table 7.8 CONCLUSIONTwo recent semantic parsing methods [21] and [22]
achieve the state-of-the-art precisions on WebQuestions
benchmark. [21] builds query graphs from question sen-
tence according to a state transition chain. It ﬁrst recognizes
a topic entity and an inference the relation between the topic
entity and the answer. Further it allows other entities to
restrict the answer node. The representation power of [21] is
limited because the ﬁnal query graph structure must be a
tree with diameter less than 3. [22] improves semantic
parsing via answer type inference. It transforms a question
to a “subject, relation, object” order by dependency parse
tree patterns and proposes a BLSTM model to predict the
answer type. Finally the answer type can be used to prune
the candidate logic forms generated by the semantic parsing
baseline. This approach cannot tackle the questions uncov-
ered by patterns or complex questions. Different from the
above systems, our approach has stronger representation
power as we do not restrict the query graph’s structure.The other category is information retrieval-based, where the
systems are not intended to parse the question to a formal
semantic interpretation.
they select candidate
Instead,
answers ﬁrst and then rank them by various methods [2],
[27], [28], [29], [30]. [29] utilizes subgraph embedding to pre-
dict the conﬁdence of candidate answers. [28] maximize the
similarity between the distributed representation of a ques-
tion and its answer candidates using Multi-Column Convo-
lutional Neural Networks (MCCNN), while [2] aims to
predicate the correct relations between topic entity and
answer candidates with text evidence.Third, our approach have stronger representation power
than most existing solutions. Information retrieval solutions
like [2], ﬁnd the topic entity and try to predicate the relation-
ship between the answer and the topic entity which can
only solve simple questions with one triple. For the ques-
tions have two entities, they utilize predeﬁned patterns in
dependency parse tree to decompose the complex question
to two simple question. However, the precision of such sys-
tem highly depends on the accuracy of the dependency
parse tree, which is pretty low when the question is com-
plex. In contrast, our work (especially NFF) is more robust
to the errors of dependency parse trees.The ﬁrst one is semantic parsing-based, where natural lan-
guage questions are translated into logical forms, such as
simple (cid:2)-DCS [17], [20], query graph [21], or executable
queries such as SPARQL [18], [19], [26]. [20] deﬁned a set of
logical form templates. DEANNA [18] builds a disambigua-
tion graph and reduces disambiguation as an integer linear
programming problem.equals to ﬁnding subgraph matches of query graphs Q over
RDF graph [32], which is also an NP-hard problem.basketball players that
are higher than 2 meters.Complex Aggregation9 (28 %) Q29: Show me allQ4: Who was on the
Apollo 11 mission?
Q55: In which countries do
people speak Japanese?
Q32: Who developed Slack?
Q80: How short is the
shortest active NBA player?5 (16 %) Q22: Which computer
scientist won an oscar?
10 (31 %) Q100: What is Batman’s
real name?Entity Mapping
Complex Aggregation5 (9 %)
9 (15 %)Relation MappingEntity MappingNodes Failure11 (18 %)soundtrack for Cameron’s
Titanic?Node Recognition
FailureRelation Failure35 (58 %)#(Ratio)
8 (25 %) Q27: Who composed theReason#(Ratio)Sample ExampleReasonSample ExampleTABLE 10
Failure Analysis of Relation-First FrameworkTABLE 11
Failure Analysis of Node-ﬁrst Framework836IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181969,” Commun. ACM, vol. 13, no. 1, pp. 15–30, Jan. 1970.[25] R. F. Simmons, “Natural language question-answering systems:[24] G. M. Mazzeo and C. Zaniolo, “Answering controlled natural lan-
guage questions on RDF knowledge bases,” in Proc. 19th Int. Conf.
Extending Database Technol., 2016, pp. 608–611.Dongyan Zhao received the BS, MS, and PhD
degree from Peking University in 1991, 1994,
and 2000, respectively. Now, he is a professor in
the Institute of Computer Science and Technol-
ogy of Peking University. His research interest is
on information processing and knowledge man-
agement,
including computer network, graph
database, and intelligent agent.data,” J. Web Sem., vol. 7, no. 3, pp. 154–165, 2009.[23] C. Bizer, et al., “DBpedia - a crystallization point for the web of[22] S. Yavuz, I. Gur, Y. Su, M. Srivatsa, and X. Yan, “Improving
semantic parsing via answer type inference,” in Proc. Conf. Empiri-
cal Methods Natural Language Process., 2016, pp. 149–159.[19] H. Bast and E. Haussmann, “More accurate question answering
on freebase,” in Proc. 24th ACM Int. Conf. Inf. Knowl. Manag., 2015,
pp. 1431–1440.
J. Berant and P. Liang, “Semantic parsing via paraphrasing,” in Proc.
52nd Annu. Meet. Assoc. Comput. Linguistics, 2014, pp. 1415–1425.
[21] W. Yih, M. Chang, X. He, and J. Gao, “Semantic parsing via staged
query graph generation: Question answering with knowledge
base,” in Proc. 53rd Annu. Meet. Assoc. Comput. Linguistics 7th Int.
Joint Conf. Natural Language Process. Asian Fed. Natural Language
Process., 2015, pp. 1321–1331.Haixun Wang received the bachelor’s and mas-
ter’s degrees in computer science from Shanghai
Jiao Tong University in 1994 and 1996, respec-
tively, and the PhD degree in computer science
from the University of California, Louisiana, in
2000. He joined Google Research, Mountain
View, California, in 2013. His research interests
include text analytics, natural language process-
ing, knowledge base, semantic network, artiﬁcial
intelligence, graph data management, etc.[20][18] M. Yahya, K. Berberich, S. Elbassuoni, M. Ramanath, V. Tresp,
and G. Weikum, “Natural language questions for the web of
data,” in Proc. Joint Conf. Empirical Methods Natural Language Pro-
cess. Computat. Natural Language Learn., 2012, pp. 379–390.Jeffrey Yu Xu has held teaching positions in the
Institute of Information Sciences an Electronics,
University of Tsukuba, and in the Department of
Computer Science, Australian National University,
Australia. Currently, he is professor in the Depart-
ment of Systems Engineering and Engineering
Management, Chinese University of Hong Kong,
Hong Kong. His current research interests include
graph database, graph mining, and social network
analysis.[16] P. Zhao and J. Han, “On graph query optimization in large
networks,” Proc. VLDB Endowment, vol. 3, no. 1, pp. 340–351, 2010.
J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on
freebase from question-answer pairs,” in Proc. Conf. Empirical
Methods Natural Language Process., 2013, pp. 1533–1544.[17]Joachims, “Optimizing search engines using clickthrough
data,” in Proc. ACM Conf. Knowl. Discovery Data Mining, 2002,
pp. 133–142.[15] T.mation Retrieval. New York: Cambridge Univ. Press, 2008.[14] C. D. Manning, P. Raghavan, and H. Sch€utze, Introduction to Infor-[13] A. Fader, S. Soderland, and O. Etzioni, “Identifying relations for
open information extraction,” in Proc. Conf. Empirical Methods Nat-
ural Language Process., 2011, pp. 1535–1545.Lei Zou received the BS and PhD degrees in
computer science from the Huazhong University
of Science and Technology (HUST), in 2003 and
2009, respectively. Now, he is an associate pro-
fessor in the Institute of Computer Science and
Technology at Peking University. He is also a fac-
ulty member in the Big Data Center at Peking
University and the Beijing Institute of Big Data
Research. His research interests include graph
database and semantic data management.[12] N. Nakashole, G. Weikum, and F. M. Suchanek, “PATTY: A tax-
onomy of relational patterns with semantic types,” in Proc. Joint
Conf. Empirical Methods Natural Language Process. Comput. Natural
Language Learn., 2012, pp. 1135–1145.[10] X. Ling, S. Singh, and D. S. Weld, “Design challenges for entity link-
ing,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 315–328, 2015.
[11] N. Nakashole, G. Weikum, and F. M. Suchanek, “Discovering and
exploring relations on the web,” Proc. VLDB Endowment, vol. 5,
no. 12, 2012.links,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 145–156, 2015.[9] A. Chisholm and B. Hachey, “Entity disambiguation with web[8] V. I. Spitkovsky and A. X. Chang, “A cross-lingual dictionary for
english wikipedia concepts,” in Proc. 8th Int. Conf. Language
Resources Eval., 2012, pp. 3168–3175.Sen Hu received the BS degree in computer sci-
ence and technology from the Beijing University
of Posts and Telecommunications in 2015. He is
currently working toward the PhD degree in the
Institute of Computer Science and Technology at
Peking University, focusing on knowledge graph
and question answering.dencies manual,” (2016).
stanford.edu/software/dependencies_manual.pdf[7] M.-C. de Marneffe and C. D. Manning, “Stanford typed depen-
[Online]. Available: https://nlp.[6] W. M. Soon, H. T. Ng, and D. C. Y. Lim, “A machine learning
approach to coreference resolution of noun phrases,” Comput. Lin-
guist., vol. 27, no. 4, pp. 521–544, 2001.[31] A. Fader, L. Zettlemoyer, and O. Etzioni, “Open question answering
over curated and extracted knowledge bases,” in Proc. 20th ACM
SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 1156–1165.
[32] L. Zou, J. Mo, L. Chen, M. T. €Ozsu, and D. Zhao, “gStore: Answer-
ing SPARQL queries via subgraph matching,” Proc. VLDB Endow-
ment, vol. 4, no. 8, pp. 482–493, 2011.[5] D. Deng, G. Li, J. Feng, Y. Duan, and Z. Gong, “A uniﬁed frame-
work for approximate dictionary-based entity extraction,” VLDB
J., vol. 24, no. 1, pp. 143–167, 2015.[4] M. Yahya, K. Berberich, S. Elbassuoni, and G. Weikum, “Robust
question answering over the web of linked data,” in Proc. 22nd
ACM Int. Conf. Inf. Knowl. Manage., 2013, pp. 1107–1116.[30] X. Yao and B. V. Durme, “Information extraction over structured
data: Question answering with freebase,” in Proc. 52nd Annu.
Meet. Assoc. Comput. Linguistics, 2014, pp. 956–966.[1] V. Lopez, C. Unger, P. Cimiano, and E. Motta, “Evaluating question
answering over linked data,” J. Web Sem., vol. 21, pp. 3–13, 2013.
[2] K. Xu, S. Reddy, Y. Feng, S. Huang, and D. Zhao, “Question answer-
ing on freebase via relation extraction and textual evidence,” in Proc.
54th Annu. Meet. Assoc. Comput. Linguistics, 2016, pp. 2326–2336.
J. Bao, N. Duan, M. Zhou, and T. Zhao, “Knowledge-based ques-
tion answering as machine translation,” in Proc. 52nd Annu. Meet.
Assoc. Comput. Linguistics, 2014, pp. 967–976.[29] A. Bordes, S. Chopra, and J. Weston, “Question answering with
subgraph embeddings,” in Proc. 2014 Conf. Empirical Methods Nat-
ural Language Process., 2014, pp. 615–620.[3][27] A. P. B. Veyseh, “Cross-lingual question answering using common
semantic space,” in Proc. TextGraphs@NAACL-HLT: 10th Workshop
Graph-based Methods Natural Language Process., 2016, pp. 15–19.
[28] L. Dong, F. Wei, M. Zhou, and K. Xu, “Question answering over free-
base with multi-column convolutional neural networks,” in Proc. 53rd
Annu. Meet. Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Lan-
guage Process. Asian Fed. Natural Language Process., 2015, pp. 260–269.REFERENCESand NSFC under grants 61622201, 61532010, and 61370055. Jef-
frey Xu Yu was supported by the Research Grants Council of
the Hong Kong SAR, China No. 14221716 and No. 12258116.[26] C. Unger, L. B€uhmann, J. Lehmann, A.-C. N. Ngomo, D. Gerber,
and P. Cimiano, “Template-based question answering over RDF
data,” in Proc. World Wide Web, 2012, pp. 639–648.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8371041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181.2 Our Approach
Although there are still
two stages “question under-
standing” and “query evaluation” in our method, we do notThe second framework takes another perspective. When
there exist some implicit or uncertain relations in N, the
relation-ﬁrst framework often fails to extract such relations.
Therefore, the second framework starts with extracting
nodes from the question sentence N and connects these
nodes to form a query graph. Furthermore, different from
the relation-ﬁrst
framework
allows for the ambiguity of query graph structure at the
beginning. It does not intend to build QS in the question
understanding step. Instead, it builds a super graph QU of
QS that includes uncertain edges. To match QU over the
underlying RDF graph G, we allow for mismatching some
edges in QU ,
i.e., approximate match (Deﬁnition 5). WeSpeciﬁcally, we resolve the ambiguity of natural language
questions at the time when matches of query are found. The
cost of disambiguation is saved if there is no match found.
We call this as the graph data-driven approach for RDF Q/A.
We illustrate the intuition of our method by an example.
Example 1. Consider a subgraph of graph G in Fig. 1a (the
(cid:1)(cid:1)!
subgraph induced by vertices u1, u2, u3 and c1). Edge u2c1
(cid:1)(cid:1)!
says that “Resident Evil: Retribution is a ﬁlm”. Edge u2u1
says that “The budget of Resident Evil: Retribution is $ 65
(cid:1)(cid:1)! says that “Paul W. S. Anderson directed
million”. Edge u2u3
the ﬁlm Resident Evil: Retribution”. The natural language
question N1 is “What is the budget of the ﬁlm directed by
Paul Anderson”. Obviously, the subgraph formed by edges
(cid:1)(cid:1)! is a match of N1. “6.5E7” is a correct
(cid:1)(cid:1)!, u2u1
u2c1
answer. On the other hand, we cannot ﬁnd a match (of N1)
containing h Paul_Anderson_(actor)i inc G, i.e., the phrase
“Paul Anderson” (in N1) cannot map to hPaul_Anderson_
(actor)i. Therefore, we address the ambiguity issue of
phrase linking when the matches are found. We can also
resolve the ambiguity of query graph structure following
the same idea. More details will be discussed in Section 5.
The above example illustrates the intuition of our graph
data-driven approach. A fundamental issue in our method
is how to deﬁne a “match” between a subgraph of G and a
natural language question N. Because N is unstructured
data and G is graph structure data, we should ﬁll the gap
between them. Therefore, we propose a semantic query
graph QS (deﬁned in Deﬁnition 1) to represent the question
semantics of N. An example of QS is given in Fig. 1c, which
represents the semantic of the question N. Answering natu-
ral language question equals to ﬁnding matches of QS over
the underlying RDF graph G. To build QS, we propose two
different frameworks: relation (edge)-ﬁrst and node-ﬁrst.the node-ﬁrstframework,In the ﬁrst framework, we ﬁrst extract semantic relations
based on the dependency tree structure of question senten-
ces to build a semantic query graph QS. A semantic relation
is a triple hrel; arg1; arg2i, where rel is a relation phrase, and
arg1 and arg2 are its associated node phrases. For instance,
h“directed by”,“ﬁlm”,“Paul Anderson”i is a semantic rela-
tion. In QS, two edges share one common endpoint if the
two corresponding relations share one common node
phrase. Each node (entity/class mention) and edge (relation
mention) in QS may have multiple candidates. The ﬁrst
framework addresses the ambiguity of phrase linking when
the matches (see Deﬁnition 2) of QS are found. Note that the
ﬁrst framework does not address the ambiguity of query
graph’s structure and assumes that the query graph can be
uniquely ﬁxed at the question understanding step.(cid:1)(cid:1)! and u2u3generate SPARQL at the question understanding step as
existing solutions do. As we know, a SPARQL query can
also be represented as a query graph, which does not
include any ambiguity. Instead, our method builds a query
graph that represents users’ query intention, but it allows
for the ambiguity at the question understanding stage, such
as the ambiguity of phrase linking and query graph struc-
ture. We resolve the ambiguity when the matches are found
at the query evaluation.Fig. 1. Question answering over RDF dataset.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8252.1 Semantic Query Graph
We deﬁne a semantic query graph (Deﬁnition 1) to repre-
sent the query intention of the question N in a graph struc-
tured way.1. Sixty-ﬁve millionThe core of our graph data-driven solution lies in two
aspects: one is how to build a semantic query graph QS accu-
rately and the other one is how to ﬁnd matches efﬁciently. In
order to address the above issues, we propose two different
frameworks. The ﬁrst one is called “relation (edge)-ﬁrst”. It
means that we always extract relations from the natural lan-
guage question sentence N and represent them as edges.
Then, we assemble these edges to form a semantic queryThere are two key issues in RDF Q/A problem. The ﬁrst
one is how to represent the query intention of the natural lan-
guage question N in a structural way. The second one is how
to address the ambiguity of natural language N. In this paper,
we focus on the ambiguity of phrase linking and query graph
structure (composition) that are mentioned in Section 1.1.Let us see Fig. 2. The subgraph included by vertices c1, u1,
u2 and u3 (in RDF graph G) denotes a match of semantic query
graph QS in Fig. 2b. When the matches are found, we resolve
the ambiguity, e.g., “Paul Anderson” should refer to hPaul_W.
_S._Andersoni rather than others., meanwhile that we ﬁnd the
answers to the question, i.e., “6.5E7”1 is the ﬁlm budget.The problem of this paper is to ﬁnd the answers to a natural
language question N over a RDF graph G. Table 1 lists the
notations used throughout this paper.2 OVERVIEW(4) We conduct extensive experiments over several real
RDF datasets (including QALD benchmark and
WebQuestions benchmark) and compare our system
with some state-of-the-art systems. The performance
of our approach beat the other systems on QALD
benchmark while close to the best on the WebQues-
tions benchmark.If vi is mapping to an entity ui, i ¼ 1; . . . ; n, ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n, ui is an
entity whose type is ci (i.e., there is a triple hui rdf:type
cii in RDF graph) and ci must be in Cvi ; and
(cid:1)(cid:1)! 2 M. Furthermore,
8vivj 2 QS , uiuj
(cid:1)(cid:1)!) is in
(cid:1)(cid:1)! (or ujui
the predicate Pij associated with uiuj
Cvivj , 1 (cid:3) i; j (cid:3) n.(cid:1)(cid:1)! 2 M _ ujui(3)(2)(1) We propose two graph data-driven frameworks for
RDF Q/A task, different from exiting solutions, in
which the disambiguation and query evaluation are
combined together.
framework, we
address ambiguity of phrase linking at the query
evaluation; while in the second framework,
the
ambiguity of phrase linking and query graph’s struc-
ture are both resolved. The graph data-driven frame-
works not only improve the precision but also speed
up query processing time greatly.
In the ofﬂine processing, we propose a graph mining
algorithm to build a relation mention dictionary, i.e.,
mapping natural language phrases to possible predi-
cates, which is used for question understanding in
RDF Q/A.
In the online processing, in order to speed up query
evaluation, we propose efﬁcient top-k (approximate)
graph matching algorithms of matching QS and QU
over RDF graph.(1)As mentioned in the introduction, we want to ﬁnd a
“match” of the semantic query graph QS over RDF graph G.
When the matches are found, we resolve the ambiguity of
natural language question sentence; meanwhile we ﬁnd the
answers to the question. Generally, a “match” is deﬁned
based on subgraph isomorphism. Given a node vi
in a
semantic query graph QS, if vi is an entity phrase or a class
phrase, we can use entity linking algorithm [5] to retrieve all
entity/class (in RDF graph G) that possibly correspond to vi,
denoted as CðviÞ; if vi is a wild-card (such as wh-word), we
assume that CðviÞ contains all vertices in RDF graph G. Anal-
ogously, each edge vivj in QS also maps to a list of candidate
predicates, denoted as Cvivj . Consider the semantic query
graph QS in Fig. 2b. We also visualizes the candidates
for each vertex and edge in QS in Fig. 2c. For example, v3
(“Paul Anderson”) corresponds to hPaul_Anderson_(actor)i,
hPaul_S._Andersoni and hPaul_W._S._Andersoni; and edge
“v2v3” maps to hdirectori, hwriteri and hproduceri. Formally,
we deﬁne the match as follows.
Deﬁnition 2 (Match). Consider a semantic query graph QS
with n nodes fv1; . . . ; vng. Each node vi has a candidate list
Cvi , i ¼ 1; . . . ; n. Each edge vivj also has a candidate list Cvivj ,
where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph M containing n vertices
fu1; . . . ; ung in RDF graph G is a match of QS if and only if
the following conditions hold:(3)(2)In the ﬁrstresolve the ambiguity of phrase linking and query graph
structure together when the approximate matches are
found. Actually, the approximate matching position (in
RDF graph G) deﬁnes the semantic query graph QS that we
aim to build. In other words, we push down resolving the
ambiguity of QS’s structure to the query evaluation stage.
In a nutshell, we make the following contribution.Given the question sentences N1, the corresponding
semantic query graphs QS
1 , nodes
v1, v2 and v3 are associated with “what” (wild-card), “ﬁlm”
(a class phrase) and “Paul Anderson” (an entity phrase),
respectively. The relation phrase “(be) budget of ” denotes
the relation between v1 and v2, as well as the relation phrase
“directed by” between v2 and v3.GðV; EÞ
N
Q
QS
QU
Y
DE=DR
vi/ui
Cvi /CvivjRDF graph and vertex and edge sets
A natural language question
A SPARQL query (of N)
The Semantic Query Graph (of N)
The Super Semantic Query Graph (of N)
The dependency tree (of N)
The entity/relation mention dictionary
A vertex in query graph / RDF graph
Candidate mappings of vertex vi / edge vivj1 is given in Fig. 2b. In QSDeﬁnition 1 (Semantic Query Graph). A semantic query
graph (denoted as QS) is a graph, in which each vertex vi is
associated with an entity phrase, class phrase or wild-cards in
the question sentence N; and each edge vivj is associated with a
relation phrase in the question sentence N, 1 (cid:3) i; j (cid:3) jV ðQSÞj.NotationDeﬁnition and DescriptionTABLE 1
Notations826IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20182.2.1 Question Understanding
The goal of the question understanding in the ﬁrst frame-
work is to build a semantic query graph QS for representing
users’ query intention in N. Speciﬁcally, we ﬁrst extract all
semantic relations in N, each of which corresponds to an
edge in QS. The semantic relation extraction is based on the
dependency tree of users’ question sentence and a relation
mention dictionary (see more details in Section 4.1). If the
two semantic relations have one common node, they share
one endpoint in QS. In the running example, we get two
semantic relations, i.e., h“directed by”, “ﬁlm”,“Paul Ander-
son”i and h“budget of”, “what”,“ﬁlm”i, as shown in Fig. 2.
They can be combined through the common node phrase
“ﬁlm” as showed in Fig. 2c. In addition, if two node phrasesConsidering the above two obstacles, we design a robust
framework even in the presence of implicit relations and
mistakes in the dependency parse tree. There are two key
points in the second framework:2.3 Node-First Framework
The relation-ﬁrst framework has two main obstacles. The
ﬁrst is that some relations are difﬁcult to be extracted. If the
relation does not explicitly appeared in the question sen-
tence, it is difﬁcult to extract such semantic relations, since
our relation extraction relies on the relation mention in the
relation mention dictionary. Let us consider two examples
“show me all ﬁlms started by a Chinese actor”, “show me all
ﬁlms stared by an actor who was born in China”. Obviously,
the latter question has one explicit relation mention “(be)
born in”, where the relation in the former one is implicitly
mentioned. Therefore, it is difﬁcult to extract these implicit
relations. Second, in the relation-ﬁrst framework, semantic
relation extraction relies on the syntactic dependency tree of
users’ question sentence and heuristic linguistic rules. If the
syntactic dependency tree has some mistakes, it inevitably
leads to wrong semantic query graph QS’s structure and
wrong answers.In the running example, h“directed by”, “ﬁlm”,“Paul
Anderson”i is a semantic relation, in which “directed by” is a
relation mention (phrase), “who” and “actor” are its associ-
ated node phrases. We can also ﬁnd another semantic relation
h“budget of”, “what”,“ﬁlm”i from the question sentence N1.2.2 Relation-First Framework
Given a natural language question sentence N, the relation-
ﬁrst framework begins with extracting semantic relations
(edge together with two end points) from N.
Deﬁnition 3 (Semantic Relation). A semantic relation is a
triple hrel; arg1; arg2i, where rel is a relation mention, arg1
and arg2 are the two node phrases.Each subgraph match has a score, which is derived from
the conﬁdences of each edge and vertex mapping. Deﬁnition
8 deﬁnes the score, which we will discuss later. Our goal is to
ﬁnd all subgraph matches with the top-k scores. A best-ﬁrst
algorithm is proposed in Section 4.2 to address this issue.
Each subgraph match of QS implies an answer to the natural
language question N, meanwhile, the ambiguity is resolved.graph. The second framework takes another perspective,
called “node-ﬁrst”. It starts with ﬁnding nodes (entity/class
phrases and wild-cards) and try to introduce edges to con-
nect them to form a semantic query graph QS. Furthermore,
another major difference between the two frameworks is
that the node-ﬁrst framework deﬁnes a super graph (called
QU ) of QS when there exist some implicit or uncertain rela-
tions in the question sentence. In other words, the node-ﬁrst
framework is not to ﬁx the QS’s structure before subgraph
matching evaluation as the relation-ﬁrst framework does.2.2.2 Query Executing
As mentioned earlier, a semantic query graph QS is a
structural representation of N. In order to answer N, we
need to ﬁnd subgraphs of RDF graph G that match QS. The
match is deﬁned according to the subgraph isomorphism
(see Deﬁnition 2)refer to same thing after “coreference resolution” [6], we
also combine the corresponding two semantic relations.Fig. 2. Question answering with semantic query graph in relation-ﬁrst framework.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS827tains every vertex of Q.ond framework.
Example 2. Consider N2 in Fig. 3. “What is the budget of the
ﬁlm directed by Paul Anderson and starred by a Chinese
actor?”. The correct SPARQL query of N2 has two addi-
tional triples than N1, which are t1 ¼ h?ﬁlm,starring, ?actori
and t2 ¼ h?actor, country,Chinai. The relation-ﬁrst frame-
work cannot generate t2 because the predicate “country”
has no explicit relation mention in N2. In the node-ﬁrst
framework, we introduce an edge between v4 (“actor”) and
v5 (“Chinese”) in Fig. 3b, whose edge label is empty. For
detected relation mention “starred by”, it is difﬁcult to
determine its corresponding two nodes. There are three can-
didate nodes: “Paul Anderson”, “ﬁlm”, and “actor”. In QU ,
we introduce two edges between “ﬁlm” and “actor”; and
“Paul Anderson” and “actor”. In the query evaluation step,
we perform the approximate match (deﬁned in Deﬁnition 5)
to match QU with RDF graph G, i.e., ﬁnding the occurrences
of QU in RDF graph G with (possible) mismatching edges.2. A spanning subgraph for graph Q is a subgraph of Q which con-we propose a simple yet effective assumption:
Assumption 1. Two nodes v1 and v2 has a semantic relation if
and only if there exists no other node v(cid:4) that occurs in the sim-
ple path between v1 and v2 of the dependency parse tree of ques-
tion sentence N.To eliminate more noises and reduce the search space,2.3.1 Question Understanding
Given a natural language question sentence N, we ﬁrst
extract all constant nodes from N by applying entity extrac-
tion algorithms, which are referred to entities or classes. We
also extract all wh-words (such as who, what and which
et al.) from N as variable nodes. Then, to build QU , we need
to introduce an edge between two nodes if there is a seman-
tic relation between them. A naive solution is to introduce
an edge between any two nodes. Obviously, this method
introduces more noises and ambiguity for the query graph’s
structure. On the other hand, the approximate match in the
node-ﬁrst framework allows mis-matching one or more
edges in QU . The naive solution leads to Oð2nÞ possible
matching structures in the ﬁnal evaluation step, where n is
the number of nodes in QU . This is quite costly.The following example illustrates the intuition of the sec-(2) We do not intend to build a semantic query graph QS
at the question understanding step. Instead, we build
a super semantic query graph QU , which possibly has
some uncertain or implicit relations (i.e., edges). In
other words, we allows the structure ambiguity of
query graph in the question understanding step,
which will be resolved at the query evaluation step.
A super semantic query graph QU is analogue to QS (see Deﬁ-
nition 4), but allows for explicit or uncertain relations (edges).
Deﬁnition 4 (Super Semantic Query Graph). A super
semantic query graph (denoted as QU ) is a graph, in which
each vertex vi is associated with an entity phrase, class phrase or
wild-card in the question sentence N; and each edge vivj is asso-
ciated with a relation in N, 1 (cid:3) i; j (cid:3) jV ðQU Þj. If the relation is
explicit, the edge label is the relation mention occurring in N;
otherwise, the edge label is empty when the relation is implicit.In this example, the ﬁnal match is denoted using bold lines
in Fig. 3, in which the edge between “Paul Anderson” and
“actor” (in QU ) is not matched.
It is easy to infer that an approximate match of QU equals to
an exact match of a connected spanning subgraph2 of QU ,
where the spanning subgraph is the semantic query graph
QS that we aim to build. Therefore, in the second framework,
we ﬁx the semantic query graph QS when the matches are
found; meanwhile the answers to the question have been
found. In other words, we resolve the “structure ambiguity”
of query graph at the time the matches are found. We also
brieﬂy discuss the two steps of the node-ﬁrst framework as
follows. More technical details are given in Section 5.The ﬁrst step is to extract node phrases (such as
entity phrase, class phrase and wh-words) from the
question sentence N, instead of relation extraction in
the ﬁrst framework.(1)Fig. 3. Question answering with super semantic query graph in node-ﬁrst framework.828IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018In this paper, we do not discuss how to extract relation
mentions along with their corresponding entity pairs. Lots
of NLP literature about relation extraction study this prob-
lem, such as Patty [12] and ReVerb [13]. For example, Patty
[12] utilizes the dependency structure in sentences and4. These grammatical relationships (called dependencies) that are
deﬁned in [7]. For example, “nsubj” refers to a nominal subject. It is a
noun phrase which is the syntactic subject of a clause.3. It is called part-of-speech tag, also grammatical tagging or word-
category disambiguation, which is the process of marking up a word in
a text (corpus) as corresponding to a particular part of speech, such as
nouns, verbs, adjectives, adverbs, etc.3.2 Build Relation Mention Dictionary
A relation mention is a surface string that occurs between a
pair of entities in a sentence [11], such as “be directed by” and
“budget of” in the running example. We need to build a rela-
tion mention dictionary DR, such as Table 4, to map relation
mentions to some candidate predicates or predicate paths.is ciIf vi is mapping to an entity ui, i ¼ 1; . . . ; n; ui must
be in list Cvi ; and
If vi is mapping to a class ci, i ¼ 1; . . . ; n; ui is an
is a triple
entity whosetypethere(i.e.,2.1.Then, based on the data-driven’s idea, we try to match QU
over RDF graph G. Different from the exact match of QS, in
the node-ﬁrst framework, we deﬁne the approximate match
(allowing dis-matching edges) of super semantic query
graph QU as follows:
Deﬁnition 5 (Approximate Match). Consider a super
semantic query graph QU with n vertices v1; . . . ; vn. Each ver-
tex vi has a candidate list Cvi , i ¼ 1; . . . ; n. Each edge vivj also
has a candidate list of Cvivj , where 1 (cid:3) i 6¼ j (cid:3) n. A subgraph
M containing n vertices u1; . . . ; un in RDF graph G is an
approximate match of QU if and only if the following condi-
tions hold:3.1 Build Entity Mention Dictionary
An entity mention is a surface string that refers to entities.
For example, “Paul Anderson” could refer to the person
hPaul_W._S._Andersoni or hPaul_S._Andersoni. We need to
build an entity mention dictionary DE, such as Table 2, to
map entity mentions to some candidate entities with
conﬁdence probabilities. There are lots of existing work
about entity-mention dictionary construction [8], [9] and the
dictionary-based entity linking [5], [10]. A popular way to
build such a dictionary DE is by crawling Web pages and
aggregating anchor links that point to Wikipedia entity
pages. The frequency with which a mention (anchor text),
m, links to a particular entity (anchor link), c, allows one to
estimate the conditional probability pðcjmÞ [8]. Entity-men-
tion dictionary construction is not our technical contribu-
tion, in this paper, we adopt CrossWikis dictionary [8],
which was computed from a Google crawler of the Web.
The dictionary contains more than 175 million unique
strings with the entities they may represent.2.3.2 Query Executing
First, we ﬁnd candidates for each node and edge in QU ,
which is analogue to the query evaluation of QS in the ﬁrst
framework. According to the entity mention dictionary DE,
for each node, we can obtain a list of candidate entities, clas-
ses. If it is a wh-word, we assume that it can map all vertices
in RDF graph G. For each edge label (i.e., the relation men-
tion relv1v2 ), we also map it to all possible candidate predi-
cates based on the relation mention dictionary DR. If the
edge label relv1v2
is empty, e.g., the edge label between
nodes “Chinese” and “actor” is empty, we generate candi-
date predicates by applying a data mining method on G.
Section 4.1.3 gives more technical details.In the ofﬂine phase, we build two dictionaries, which are
entity mention dictionary DE and relation mention dictio-
nary DR. They will be used to extract entities and relations
from users’ question sentences in the online phase. Note
that both DE and DR are used in our two frameworks (rela-
tion-ﬁrst framework and node-ﬁrst framework).3 OFFLINE PHASELet us recall Example 2. We ﬁrst extract ﬁve nodes:
“what”, “ﬁlm”, “Paul Anderson”, “Chinese”, “actor” from
the question N2. Fig. 5 illustrates the dependency parse tree
Y ðN2Þ of question sentence N2. According to the assumption,
we introduce an edge v1v2 between two nodes v1 and v2 if
there is no other node v(cid:4) in the simple path between v1 and v2
over Y ðN2Þ. The words along the simple path between v1
and v2 form the edge label of v1v2. For example, the edge
label between nodes “what” and “ﬁlm” is “ (be) budget of”.
The edge label between nodes “Chinese” and “node” is
empty, which is the implicit relation. For nodes “Paul Ander-
son” and “actor”, there is no other nodes along the simple
path between them. According to Assumption 1, we intro-
duce an edge between them and the edge label is “directed
by started by”. Due to the same reason, there is another edge
between nodes “ﬁlm” and “actor”. Finally, we obtain the
super semantic query graph QU as shown in Fig. 3b.The only difference between the approximate match and
match is item (3) of Deﬁnitions 2 and 5: some edges of QU
may not be matched. Let us recall Example 2. The ﬁnal
approximate match is denoted by the bold lines in Fig. 3d.
The edge between node “Paul Anderson” and “actor” (in
QU ) is not matched. The approximate match is used to
address the ambiguity of the query graph’s structure.(cid:1)(cid:1)! is in Cvivj , 1 (cid:3) i; j (cid:3) n.huirdf : typecii in RDF graph) and ci must be in Cvi ;
and
(cid:1)(cid:1)! 2 M ) vivj 2 QU . Furthermore, the predicate
8uiuj
Pij associated with uiuj3.“Paul Anderson”
“Paul Anderson”
“USA”
“America”
. . .. . .hPaul_S._Andersoni
hPaul_W._S._Andersoni
hUnited_Statesi
hUnited_Statesi
. . .. . .Conﬁdence
Probability
0.8
0.6
1.0
1.0
. . .. . .Although this method also depends on the dependency
parse tree, it is not like the ﬁrst framework, in which,
extracting semantic relations and node phrases (to build
QS) heavily depend on the parse tree’s structure, POS tag3
and dependency relation (such as subj, obj and et al.)4 In
other words, the node-ﬁrst framework (i.e., the second
framework) is more robust to dependency errors.Entity MentionReferring EntityTABLE 2
Entity Mention Dictionary DEHU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS829the ﬁrst condition and y is a subtree of y0.5. We set the threshold as four in our experiments. More details
about the parameter setting will be discussed in Appendix B, available
in the online supplemental material.(2) We cannot ﬁnd a subtree y0 of Y , where y0 also satisﬁesEach node in y contains one word in rel and y includes
all words in rel.(1)Therefore, in our work, we ﬁrst apply Stanford Parser [7]
to N to obtain the dependency tree Y . Let us recall the run-
ning example. Fig. 4 shows the dependency tree of N1,
denoted as Y ðN1Þ. The next question is to ﬁnd relation men-
tions occurring in Y ðN1Þ.
Deﬁnition 7. Let us consider a dependency tree Y of a natural
language question N and a relation mention rel. We say that
rel occurs in Y if and only if there exists a connected subtree y
(of Y ) satisfying the following conditions:jT j
jfreli 2 T jL 2 PSðreliÞgj þ 1idfðL; T Þ ¼ logT ¼ frel1; . . . ; relng is deﬁned as follows:The idf-value of L over the whole relation mention seti ÞjL 2 Pathsðvj
i; v0ji Þ 2 PSðreliÞgji; v0j
Pathsðvji; v0j
i Þ;tfðL; PSðreliÞÞ ¼jfPathsðvjIn order to extract the semantic relations in N, we need to
identify the relation mentions in question N. Obviously, we
can simply regard N as a sequence of words. The problem
is to ﬁnd which relation phrases (also regarded as a
sequence of words) are subsequences of N. However, the
ordering of words in a natural language sentence is not
ﬁxed, such as inverted sentences and preposition fronting. For
example, consider a question “In which movies did Li Bingb-
ing star?”. Obviously, “star in” is a relation mention though
it is not a subsequence of N. The phenomenon is known as
“long-distance dependency”. Some NLP (natural language
processing) literature suggest that the dependency structure
is more stable for the relation extraction [12].PSðreliÞ is deﬁned as follows:Intuitively, if a predicate path is frequent in PSðreliÞ, it is
a good candidate that has semantic equivalence with rela-
tion mention reli. However, the above simple intuition may
introduce noises. For example, we ﬁnd that (hasGender,
hasGender) is the most frequent predicate path in PS
(“uncle of”). Obviously, it is not a good predicate path to
represent the semantic of relation mention “uncle of”. In
order to eliminate noises, we borrow the intuition of tf-idf
measure [14]. Although (hasGender, hasGender) is frequent
in PS (“uncle of”), it is also frequent in the path sets of other
relation mentions, such as PS (“is parent of”), PS (“is advi-
sor of”) and so on. Thus, (hasGender, hasGender) is not an
important feature for PS (“uncle of”). Formally, we deﬁne tf-
idf value of a predicate path L in the following deﬁnition.
Note that if L is a length-1 predicate path, L is a predicate P .
Deﬁnition 6. Given a predicate path L, the tf-value of L in4 RELATION-FIRST FRAMEWORK
4.1 Building Semantic Query Graph
This Section discusses how to identify semantic relations
in a natural language question N, based on which, we build
a semantic query graph QS to represent the query intention
in N.For efﬁciency considerations, we only ﬁnd simple paths
with no longer than a threshold5. We adopt a bi-directional
BFS (breath-ﬁrst-search) search from vertices vj
to
ﬁnd Pathsðvj
i ; v0j
i Þ. Note that we ignore edge directions (in
RDF graph) in a BFS process.i and v0jiAlgorithm 1 in Appendix A, which can be found on
the Computer Society Digital Library at http://doi.
ieeecomputersociety.org/10.1109/TKDE.2017.2766634,
shows the details of ﬁnding top-k predicate paths for
each relation mention. All relation mentions and their corre-
sponding k predicate paths including tf-idf values are col-
lected to form a relation mention dictionary DR.in RDF graph G, denoted as Pathsðvj
i Þj1 (cid:3) j (cid:3) mg.i ; v0jGiven a relation mention reli, considering each pair
i Þ in Sup ðreliÞ, we ﬁnd all simple paths between vj
i; v0j
ðvj
i
and v0j
i Þ. Let
i
PSðreliÞ ¼ fPathsðvji; v0jSuppose that we have a mention set T ¼ frel1; . . . ; relng,
where each reli is a relation mention, i ¼ 1; . . . ; n. Each reli
has a support set of entity pairs that occur in RDF graph,
i.e., Sup ðreliÞ ¼ f ðv1
i Þ; . . . ; ðvm
i Þg. For each reli,
i ¼ 1; . . . ; n, the goal is to mine top-k possible predicates or
predicate paths formed by consecutive predicate edges in
RDF graph, which have semantic equivalence with relation
mention reli.dðrel; LÞ ¼ tf(cid:5)idfðL; PSðreliÞ; T Þ(1)mention rel to predicate or predicate path L as follows.i ; v0mi ; v01We deﬁne the conﬁdence probability of mapping relationtf(cid:5)idfðL; PSðreliÞ; T Þ ¼ tfðL; PSðreliÞÞ (cid:6) idfðL; T ÞReVerb [13] adopts the n-gram to ﬁnd relation mentions and
the corresponding support set. In this work, we assume that
the relation mentions and their support sets are given. For
example, Table 3 shows two sample relation mentions and
their supporting entity pairs.The tf-idf value of L is deﬁned as follows:(hResident_Evili, hPaul_W._S._Andersoni),
(hRoman_Holidayi, hWilliam_Wyleri),. . .. . .
(hTed_Kennedyi, hJohn_F._Kennedy,_Jr.i)
(hPeter_Corri, hJim_Corri),. . .. . .“uncle of”“directed by”Relation MentionSupporting Entity PairsTABLE 3
Relation Mentions and Supporting Entity PairsTABLE 4
Relation Mention Dictionary DR830IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Assume that we ﬁnd an embedding subtree y of a rela-
tion mention rel. We recognize arg1 by checking for each
phrase w in y whether w is an entity/class mention or there
exists the above subject-like relations (by checking the edge
labels in the dependency tree) between w and one of its4.1.3 Phrases Mapping
In this Section, we discuss how to map the relation mentions
and node phrases to candidate predicates/predicate paths
and entities/classes, respectively.(2)subject-like relations: subj, nsubj, nsubjpass, csubj,
csubjpass, xsubj, poss, partmod;
object-like relations: obj, pobj, dobj, iobjAfter obtaining all semantic relations in a natural lan-
guage N, we need to build a semantic query graph QS.
Fig. 2b shows an example of QS. In order to build a semantic
query graph QS, we represent each semantic relation
hrel; arg1; arg2i as an edge. Two edges share one common
endpoint if their corresponding semantic relations have one
common node phrase. The formal deﬁnition of a semantic
query graph has been given in Deﬁnition 1.(1)4.1.2 Finding Associated Nodes
After ﬁnding a relation mention in Y , we then look for the
two associated nodes. If a phrase was recognized as entity/
class mention, it is regarded as a node. Besides, the nodes
are recognized also based on the grammatical subject-like
and object-like relations around the embedding, which are
listed as follow:(cid:2) Rule 3: If the parent of the root node of t has subject-
like relations with its neighbors, add the child to arg1.
(cid:2) Rule 4: If one of arg1/arg2 is empty, add the nearest
wh-word or the ﬁrst noun phrase in t to arg1/arg2.
If we still cannot ﬁnd node phrases arg1/arg2 after
applying the above heuristical rules, we just discard the
relation mention rel in the further consideration. Finally, we
can ﬁnd all relation mentions occurring in N together with
their embeddings and their node phrases arg1/arg2.
Example 3. Let us recall dependency tree Y in Fig. 4. We get
“what” as the ﬁrst node of relation mention “budget of”
by applying Rule 4. And we can ﬁnd another node “ﬁlm”
as it is a class mention. Therefore, the ﬁrst semantic rela-
tion is h“budget of”, “what”, “ﬁlm”i. Likewise, we can
also ﬁnd another semantic relation h“direct by”, “ﬁlm”,
“Paul Anderson”i.4.1.1 Relation Recognition
Given a natural language question N, we propose an algo-
rithm (Algorithm 2 in Appendix A, available in the online sup-
plemental material) to identify all relation mentions in N. In
the ofﬂine phase, we build an inverted index over all relation
mentions in the relation mention dictionary DR. Speciﬁcally,
for each word, it links to a list of relation mentions containing
the word. The basic idea of Algorithm 2 is as follows: For each
node (i.e., a word) wi in Y , we ﬁnd the candidate pattern list
PLi (Lines 1-2). Then, for each node wi, we check whether
there exists a subtree rooted at wi including all words of some
relation mentions in PLi. In order to address this issue, we
propose a depth-ﬁrst search strategy. We probe each path
rooted at wi (Line 3). The search branch stops at a node w0,
where there does not exists a relation mention including w0
and all words along the path between w0 and wi (Note that, w0
is a descendant node of wi.)(Lines 3-4 in Probe function.) We
utilize rel½w(cid:7) to indicate the presence of word w of rel in the
subtree rooted at wi (Line 6). When we ﬁnish all search
branches, if rel½w(cid:7) ¼ 1 for all words w in relation mention rel,
it means that we have found a relation mention rel occurring
in Y and the embedding subtree is rooted at wi (Lines 8-11).
We can ﬁnd the exact embedding (i.e., the subtree) by probing
the paths rooted at wi. We omit the trivial details due to the
space limit. The time complexity of Algorithm 2 is OðjY j2Þ.(cid:2) Rule 2: If the root node of t has subject/object-like
relations with its parent node in Y , add the parent
node to arg1.words, such as prepositions, auxiliaries.(cid:2) Rule 1: Extend the embedding t with some lightOn the other hand, when arg1/arg2 is empty after this
step, we introduce several heuristic rules (based some
computational linguistics knowledge [3], [7]) to increase the
recall for ﬁnding nodes. The heuristic rules are applied until
arg1/arg2 becomes none empty.children (note that, the child is not in the embedding sub-
tree). If a subject-like relationship exists, we add the child to
arg1. Likewise, arg2 is recognized by the object-like rela-
tions. When there are still more than one candidates for
each node, we choose the nearest one to rel.Given a dependency tree Y of a natural language question
N and a relation mention set T ¼ frel1; . . . ; relng, we need to
ﬁnd which relation mentions (in T ) are occurring in Y .Fig. 5. Building super semantic query graph.In this case, y is an embedding of relation mention rel in Y .Fig. 4. Relationship extraction in Y ðN1Þ.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS831Based on Assumption 1 (see Section 2.3.1), we construct the
super semantic query graph QU as follows: Given a node set V
(which has been recognized in the ﬁrst step) and a depen-
dency tree Y of question sentence, for any two nodes vi and vj
(2 V ), we introduce an edge between vi and vj if and only if
the simple path between vi and vj does not contain other node
in V . We propose a DFS based algorithm (see Algorithm 4 in
Appendix A, available in the online supplemental material,6. Note that if more than one match have the identical score in the
top-k results, they are only counted once. In other words, we may
return more than k matches if some matches share the same scoreThe ﬁrst pruning method is to reduce the candidates of
each list (i.e, Cvi and Cvivj ) as many as possible. If a vertex ui
in Cvi cannot be in any subgraph match of QS, ui can be ﬁl-
tered out directly. Let us recall Fig. 2. Vertex u5 is a candi-
date in Cv3 . However, u5 does not have an adjacent
predicate that is mapping to phrase “direct by” in edge v2v3.5.1.2 Structure Construction
Given that all nodes have been recognized, the next step is to
build a super semantic query graph QU . As mentioned in Sec-
tion 2.3, although our method still relies on the dependency
tree of the question sentence, it is more robust to dependency
errors compared with the relation-ﬁrst framework.Given a semantic query graph QS, our goal is to ﬁnd all sub-
graph matches of QS (over RDF graph G) with the top-k match
scores.6 To solve this problem, we designed an enumerative
algorithm (Algorithm 3 in Appendix A, available in the online
supplemental material) with two main pruning methods.where argi is the phrase of vertex vi, and ui is an entity or a
class in RDF graph G, and relvivj is the relation mention of
edge vivj and Pij is a predicate of edge uiuj
The default value of weight a is 0.5, which means the entity
score and relation score have equivalent status. If we have
enough training data, a can be learned by some ranking mod-
els such as SVM-rank [15]. Details can be found in Section 6.5.1.1 Node Recognition
The ﬁrst step is to recognize all nodes from the question sen-
tence N. Generally, we extract entities, classes and wild-
cards as nodes. We adopt the dictionary-based entity linking
approach [5] to ﬁnd entities and classes. We collect all wh-
words and nouns which could not map to any entities and
classes as wild-cards. For example, given a question sen-
tence N2 = “What is the budget of the ﬁlm directed by Paul
Anderson and starred by a Chinese actor?”, the node recog-
nition result is illustrated in Fig. 3a, i.e., “what”, “ﬁlm”,
“Paul Anderson”, “Chinese”, “actor”.(cid:1)(cid:1)!.
(cid:1)(cid:1)! or ujuivivj2EðQS Þlog ðdðrelvivj ; PijÞÞ(2)þ ð1 (cid:5) aÞvi2V ðQS Þ
Xlog ðdðargi; uiÞÞScoreðMÞ ¼ aX5 NODE-FIRST FRAMEWORK
5.1 Building Super Semantic Query Graph
There are three steps in building Super Semantic Query
graph QU : node recognition, query graph structure con-
struction and phrase mapping.4.2 Query Executing
Given a semantic query graph QS, we discuss how to ﬁnd
top-k subgraph matches over RDF graph G in this Section.
The formal deﬁnition of a subgraph match is given in Deﬁ-
nition 2. We assume that all candidate lists are ranked in the
non-ascending order of the conﬁdence probability. Figs. 2b
and 2c show an example of QS and the candidate lists,
respectively. Each subgraph match of QS has a score. It is
computed from the conﬁdence probabilities of each edge
and vertex mapping. The score is deﬁned as follows.
Deﬁnition 8. Given a semantic query graph QS with n nodes
fv1; . . . ; vng, a subgraph M containing n vertices fu1; . . . ; ung
in RDF graph G is a match of QS. The match score is deﬁned
as follows:The second method is to stop the search process based on
the top-k match score as early as possible. Obviously, enu-
merating all possible combination is inefﬁcient. If we main-
tain an appropriate enumeration order so that the current
matches are always better than undiscovered matches, we
can terminate the search space as early as possible. The
pseudo codes are given in Algorithm 3 in Appendix A, avail-
able in the online supplemental material. For ease of presen-
tation, we use “candidate list” to symbol relation candidate
list and entity/class candidate list together. Once we deter-
mine a candidate for each candidate list in QS, we obtain a
“selection”. The selection is expressed by a n-length vector,
which n is the total number of candidate list (Line 2 in Algo-
rithm 3). Initially the vector value is 0 which means we select
the ﬁrst candidate for each candidate list (Lines 3-4). Every
time we get the best selection from the heap top of H. We can
build a query graph Q(cid:4) by replacing all vertex/edge labels in
QS using the selected candidates (Lines 5-6). Line 7 applies
an existing subgraph isomorphism algorithm such as VF2 to
ﬁnd all subgraph matches of Q(cid:4) over G. Then we maintain
the maximum heap H to guarantee each selection we get
from H has the highest score among all untried selection as
showed in Line 8-10. For each candidate list Li, we add one
at the ith bit in current selection G to get a new selection and
put it into H. Thus we can early termination when we ﬁnd k
matches as showed in lines 11-12 in Algorithm 3.Mapping Vertices of QS. Let us consider any vertex v in QS.
The phrase associated with v is arg. If arg is a wild-card
(such as wh-word), it can be mapped to all vertices in RDF
graph G. Otherwise, given an constant arg (entity/class
mention), we adopt the dictionary-based entity linking
approach [5] to ﬁnd the candidate entities or classes. We use
notation Cv to denote all candidates with regard to vertex v
in QS. For example, “ﬁlm” in v2 (in Fig. 2) can be linked to a
class node hﬁlmi or an entity node hFilmexi. If arg is
mapped to an entity u or a class c, we use dðarg; uÞ or
dðarg; cÞ to denote the conﬁdence probability.Mapping Edges of QS. Each edge vivj in QS has a relation
mention relvivj . According to the relation mention dictionary
DR (see Section 3.2), it is straightforward to map relvivj to
some predicates P or predicate paths L. The list is denoted
as Cvivj . For simplicity of notations, we use L in the follow-
ing discussion. Each mapping is associated with a conﬁ-
dence probability dðrel; LÞ (deﬁned in Equation (1)). For
example, edge v2v3 has a relation mention relv2v3 = “direct
Its candidate list Cv2v3 contains three candidates,
by”.
hdirectori, hwriteri, and hproduceri, as shown in Fig. 2c.It means that there exists no subgraph match of QS contain-
ing u5. Therefore, u5 can be pruned safely. This is called
neighborhood-based pruning. It is often used in subgraph
search problem, such as [16].832IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Obviously, the above solution is not efﬁcient, since there
are lots of common computations if two spanning subgraphs
share common structures with each other. Therefore, we pro-
pose another bottom-up solution. The pseudo codes are
given in Algorithm 5 in Appendix A, available in the
online supplemental material. Different from the baseline
algorithm, we do not decide the query graph at the begin-
ning. Instead we try to construct the “correct” graph7. http://qald.sebastianwalter.org/[12]. contains a large
resource for textual patterns that denote binary relations
between entities. We use two different relation mention
datasets, wordnet-wikipedia and freebase-wikipedia. The
statistics are given in Table 6. The experiments of ofﬂine
performance can be found in Appendix B, available in the
online supplemental material.5.2 Query Executing
Given a super semantic query graph QU , we discuss how to
ﬁnd approximate matches over RDF graph G with the top-k
match scores, where the approximate match is deﬁned in
Deﬁnition 5 and the match score is analogue to Deﬁnition 8.
As mentioned in Deﬁnition 5, some edges (in QU ) are
allowed dis-matching but all nodes should be matched. Con-
sequently, the approximate match of QU is the same with the
exact match (see Deﬁnition 2) of one connected spanning sub-
graph of QU . Thus, a straightforward solution is to enumerate
all spanning subgraphs Si of QU . For each Si, we call Algo-
rithm 3 to ﬁnd the top-k matches of Si. Finally, we collect all
top-k matches for each Si to form answer set RS, and report
k matches with the largest match scores in RS.Patty Relation Mention DatasetFreebase. (https://developers.google.com/freebase/) is a
collaboratively edited knowledge base. We use the version
of Freebase 2013, which is same with [20]. The statistics are
given in Table 5.6.1 Datasets
DBpedia RDF Repository. (http://blog.dbpedia.org/) is a
comm-unity effort to extract structured information from
Wikipedia and to make this information available on the
Web [23]. We use the version of DBpedia 2014 and the statis-
tics are given in Table 5.We evaluate our system on DBpedia and Freebase with two
benchmarks separately. For DBpedia, we use QALD7 as the
benchmark. As we know, QALD is a series of open-domain
question answering campaigns, which mainly based on
DBpedia. We compare our method with all systems in
QALD-6 competition as well as DEANNA [18] and Aqqu
[19]. For Freebase, we use WebQuestions [17] as the bench-
mark and compare our method with Sempre [17], Para-
Sempre [20], Aqqu [19], STAGG [21] and Yavuz et al.[22].
To build the relation mention dictionary, we utilize relation
phrases in Patty dataset [12]. We also use the CrossWikis [8]
as the entity mention dictionary. All experiments are imple-
mented in a PC server with Intel Xeon CPU 2 GB Hz, 64 GB
memory running Windows 2008. Our two frameworks (the
relation-ﬁrst framework and the node-ﬁrst framework) are
denoted as RFF and NFF, respectively.Similar with the bridging operation in [17], we generate
the candidate predicates as following. If two nodes are both
constants (i.e., entities or classes), such as v4 and v5 in Fig. 3b
(i.e., “Chinese actor”), we locate the two nodes at RDF graph
G and ﬁnd the predicate between them. If one node vi is a
wild-card and the other one vj is an entity or class, we locate
vj in RDF graph G and select the most frequent adjacent
predicates as the candidate predicates to match edge vivj.(2) Assume that at least one node (vi or vj) is an entity or
a class. It is impossible that two connected nodes are
both wh-words.Since there is an implicit relation between two nodes
vi and vj, we assume that the distance between vi
and vj in RDF graph G is short enough.(1)6 EXPERIMENTSMapping Unlabeled Edges of QU . For an unlabeled edge
vivj, the relation between node vi and vj is implicit in given
question. For example, edge v4v5 denotes an implicit rela-
tion, the correspond word sequence in N2 is “Chinese
actor”. We try to infer the implicit relation between the two
given nodes vi and vj based on underlying knowledge
graph. First, we have the following assumptions:To improve the search performance, we can also perform
threshold-based pruning (like A(cid:4)-style algorithm) and early
terminate some search branches. For example, for a given
partial structure Q, we estimate the upper bound of the
match score if continually expanding Q. We can derive the
upper bound assuming that all un-mached vertices and
edges (of QU ) can match the candidates with the largest
score. If the upper bound is still smaller than the threshold
d, we can terminate the search branch. We do not discuss
this tangential issue any further.5.1.3 Phrases Mapping
In this Section, we discuss how to ﬁnd candidate predicates
and entities/classes for edges and nodes. The methods of map-
ping nodes and labeled edges are the same as phrases map-
ping of QS (see Section 4.1.3). We only concentrate on how to
map the unlabeled edges to predicates in RDF graph G.structure by expanding the current partial structure. Gen-
erally, in each step, we extend the current partial struc-
ture Q by expanding one more edge vix, i.e., Q ¼ Q [ vix
(Line 6 in Algorithm 5). Initially, Q only includes one
starting vertex s in QU . We select the vertex with the
smallest number of candidates as the starting vertex s. If
the new expanded partial structure Q can ﬁnd matches
over RDF graph G (Lines 7-11), we continue the search
branch. Furthermore, if Q has already been a spanning
subgraph of QU (Lines 9-11), we record the matches of Q
together with the match scores in answer set RS. We only
keep the current top-k matches in RS and the current
threshold d. If Q cannot ﬁnd matches over RDF graph G
(Lines 12-13), we backtrack the search branch.For the question sentence N2, the super semantic query
graph QU is shown in Fig. 5. The node labels are those asso-
ciated entity/class mentions or other phrases. The edge
label of vivj is the words along the simple path between vi
and vj in the dependency tree Y ðN2Þ. For example, the path
between “what” and “ﬁlm” in the dependency tree contains
three words: “is”, “budget” and “of”, thus, the edge label
between v1 and v2 (in QU ) is “(be) budget of ”. If the simple
path does not contain any word (such at the path between
“actor” and “Chinese”), the edge label is empty.with time complexity OðjY jÞ) to ﬁnd neighbors for each node
and build the super semantic query graph QU .HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8338. The result of QALD-6 campaign is available at http://qald.
sebastianwalter.org/6/documents/qald-6_results.pdf, and our team is
named NbFramework.Efﬁciency Evaluation. We compare the running time of our
two frameworks with DEANNA [18] using QALD-6 data-
set. Fig. 6 shows the experiment results. We test all ques-
tions that can be answered correctly by both DEANNA and
our methods. In the question understanding, DEANNA
needs to generate SPARQLs, our systems generates seman-
tic query graph QS or super semantic query graph QU . The
former has the exponential time complexity, but our meth-
ods have the polynomial time complexity in the question
understanding stage, as we reserved the ambiguity. The rea-
son of NFF is faster than RFF is that RFF spends more time
on relation extraction from a whole dependency tree Y .
Actually, RFF spends OðjY j2Þ time to extraction relations
and build QS (see Algorithm 2 in Appendix, available in the
online supplemental material) while NFF costs OðjY jÞ timeTable 8 shows the results on the test set of WebQuestions,
which contains 2032 questions. Different
from QALD
benchmark, WebQuestions has low diversity and most
questions are simple questions. The average F1 of our sys-
tem (49.6 percent) is little less than the state-of-art work [21]
(52.5 percent) and Yavuz et al. [22] (52.6 percent). Compared
by [22] and [21], our approach performs not very well inEffectiveness Evaluation. Our NFF method joined QALD-6
competition and won the second place at F-1 measure.8 NFF
can answer 68 questions correctly, while the relation-ﬁrst
framework (RFF) can answer 40 questions correctly. Gener-
ally, NFF can beat all systems in QALD-6 campaign in F-1
except for CANaLI [24]. Note that CANaLI aims to answer
controlled natural language questions, in which, users need to
specify the precise entities and predicates (denoted by URIs)
in the question sentences. In other words, CANaLI asks users
to do disambiguation task for phrase linking and CANaLI is
not a fully natural language question answering system.relation extraction, which relies on the relation mention dic-
tionary. Actually, the advantage of our approach lies in
answering complex questions (i.e., multi-hop relation ques-
tions), such as some questions in QALD benchmark. As the
codes of [22] and [21] are not available to us, we compare
our method with Aqqu [19] on QALD. Aqqu performs well
on WebQuestions (49.4 percent) but has a poor performance
on QALD benchmark (38 percent in Table 7). It is because
that the questions in WebQuestions are simpler than QALD
and most of them could be translated into a “one-triple”
query, i.e, have only one entity and one relation. Aqqu
deﬁnes three query templates and try to match test ques-
tions to predeﬁned templates. These three templates cover
almost all of the questions in the WebQuestions benchmark
[19]. However, when Aqqu meets some other questions
which have different representation and could not be
matched to predeﬁned templates,
it would get wrong
answers. For instance, Aqqu could not answer “true-false”
questions such as “Does Trump have any children?”. How-
ever, those questions could be answered correctly by our
system because we do not rely on particular dataset and do
not use any predeﬁned query templates.For WebQuestions dataset, we use SVM-rank [15] to
learn the weight a of aggregation function (see Deﬁnition 8)
as there are enough training data in WebQuestions. To train
SVM-rank model, we generate several candidate query
graphs with certain entities and relations for each training
question. After matching these query graphs, we calculate
the F1 score as their ranking score. The ﬁnal a in our experi-
ment is 0.136. As there are only 350 training questions of
QALD-6, learning a perfect weight is hard. Therefore, we
use the default value a ¼ 0:5 directly.6.2 Online Performance
Exp 1. (End-to-End Performance) We evaluate our system
both on QALD benchmark and WebQuestions benchmark.
For QALD dataset, we show the experiment results in the
QALD competition report format to enable the comparison
with all systems in QALD-6 (in Table 7). We also repro-
duced DEANNA [18] and Aqqu [19] using the codes pub-
lished by authors. For WebQuestions dataset, we show the
average F1 to compare with previous works. We repro-
duced Aqqu [19] and report the results of other works in
Table 8. In Table 7, “Processed” denotes the number of test
questions that can be processed and “Right” refers to the
number of questions that were answered correctly.NFF
RFF
Sempre
ParaSempre
Aqqu
STAGG
Yavuz et al. (2016)49.6%
31.2%
35.7%
39.9%
49.4%
52.5%
52.6%Average F1# of Textual Patterns
# of Entity Pairs
Average Entity Pair # for each Patternwordnet-
wikipedia
350,568
3,862,304
11freebase-
wikipedia
1,631,530
15,802,947
9TABLE 8
Evaluating WebQuestions Testing QuestionsNFF
RFF
CANaLI
UTQA
KWGAnswer
SemGraphQA
UIQA1
UIQA2
DEANNA
Aqqu100
100
100
100
100
100
44
36
100
10068
40
83
63
52
20
21
14
20
360.70
0.43
0.89
0.69
0.59
0.25
0.63
0.53
0.21
0.370.89
0.77
0.89
0.82
0.85
0.70
0.54
0.43
0.74
0.39F-1
0.78
0.55
0.89
0.75
0.70
0.37
0.25
0.17
0.33
0.38TABLE 6
Statistics of Relation Mention DatasetNumber of Entities
Number of Triples
Number of Predicates
Size of RDF Graphs (in GB)5.4 million
110 million
9,708
8.741 million
596 million
19,456
56.9Processed Right Recall PrecisionDBpediaFreebaseTABLE 7
Evaluating QALD-6 Testing Questions
(Total Question Number = 100)TABLE 5
Statistics of RDF Graph834IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Q/A (natural language question answering) has a quite
long history since the seventies of last century [25]. Gener-
ally, the solutions of knowledge base QA can be mainly
divided into two categories.Exp 3. (Efﬁciency of Query Evaluation in NFF Framework) We
evaluate the efﬁciency of the two approximate subgraphThe ﬁnal accuracy of RFF and NFF are 0.40 and 0.68,
respectively, which means 40 and 68 percent of questions
that can be answered correctly in the two frameworks. In
some cases, even if we can generate a correct QS or QU , we
may get the wrong answers. The reason of that is mainly
because of out-of-dictionary entities/relations or complex
aggregation operations that cannot be handled by our frame-
works. The details of error analysis will be given in Exp 4.7 RELATED WORKThere are three reasons for the failure of some questions in
NFF. The ﬁrst reason is the node recognition problem. Some
phrases were recognized as nodes by mistake. For example,
“Who composed the soundtrack for Cameron’s Titanic”. We
regarded the noun “soundtrack” as a variable node, however,
it should be ignored. The second one is the failure of phrase
mapping, which means we could not ﬁnd the correct referred
entity/relation for a given mention. For example, “What is
Batman’s real name”. The correct relation halterEgoi is not
occurred in the candidate list of mention “real name” in our
relation mention dictionary DR. The third one is that our
method cannot answer some complex aggregation questions.
We give the ratio of each reason with an example in Table 11.By comparing the ﬁrst step (i.e, relation recognition and
node recognition) between RFF and NFF in 100 test ques-
tions, we can see that the node recognition (in NFF) is much
more accurate than relation recognition (in RFF), where the
former’s accuracy is 0.92 and the latter is 0.65. This is the
motivation of NFF framework. Furthermore, the accuracy
of QS is 0.54, which means that 11 questions found wrong
associated argument nodes after recognizing correct rela-
tions. On the contrary, the accuracy of QU is same as the
node recognition (0.92), which means that once all nodes
were recognized correctly, we can build a correct super
semantic query graph QU . In other words, Assumption 1 (in
Section 2.3) of building QU is effective.There are four reasons for the failure of some questions
in RFF. The ﬁrst reason is the relation recognition problem,
which accounted for 58 percent. That because many rela-
tions could not be captured by mentions, such as the ques-
tion “Who was on the Apollo 11 mission”. Some relations
even be implicit such as “Czech movie”. The second one is
wrong nodes. For example, “In which countries do people
speak Japanese?”, the correct semantic relation is hspeak,
Japanese, countryi, however, we found the semantic rela-
tion hspeak, people, countryi. The latter two reasons are
same as the reasons in NFF. Notice that relation mapping
failure is a part of relation recognition failure. We give the
ratio of each reason with an example in Table 10.Exp 2. (Pipeline Accuracy of Two Frameworks) In this experi-
ment, we evaluate the accuracies of main steps in both RFF
and NFF using 100 test questions of QALD-6. Table 9 shows
the experiment results. QALD-6 competition report released
the gold standard SPARQL statement for each question sen-
tence in QALD-6. For each sentence N, we suppose that the
generated semantic query graph is QS and super semantic
query graph is QU and the correct SPARQL query is Q. In the
relation-ﬁrst framework (RFF), we say that “relation recog-
nition” is correct if exists a correct one-to-one mapping from
relation mentions (in QS) to predicate edges in SPARQL
query graph Q. Furthermore, we say that QS is correct if QS
is isomorphism to Q. Analogously, if there exists a one-to-
one mapping from nodes in QU to vertices in Q, we say that
the node recognition is correct. QU is correct if exists a con-
nected spanning graph of QU that is isomorphism to Q.Exp 4. (Failure Analysis) We provide the failure analysis of
our two methods. We consider about QALD benchmark
because it is harder than WebQuestions and more diversi-
ﬁed. The failure analysis will help the improvement of our
RDF Q/A system’s precision.matching algorithms in Section 5.2 using the 100 test ques-
tions in QALD-6. The results of 10 questions randomly
selected and the average time of 100 questions are showed in
Fig. 7. For half of the cases, the bottom-up algorithm (Algo-
rithm 5) has obvious advantages, which veriﬁed our analysis
in Section 5.2. In some cases, the performance gap is not clear,
since QU of these questions is an acyclic graph, which means
the problem of approximate matching QU is degenerated into
matching QS. Generally, the average time of the bottom-up
algorithm is faster than the baseline solution by twice.to build QU (see Algorithm 4 in Appendix, available in the
online supplemental material).RFF
NFF Node Recognition: 0.92Step2
Building QS: 0.54
Building QU : 0.920.40
0.68Relation Recognition: 0.65Step1FinalTABLE 9
Pipeline AccuracyFig. 7. Evaluation methods comparison.Fig. 6. Online running time comparison.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS835This work was supported by The National Key Research and
Development Program of China under grant 2016YFB1000603Second, different from most semantic parsing based sys-
tems, we push down the disambiguation into the query
evaluation stage. Existing solutions, like [26] and [18], gen-
erate the SPARQLs as the intermediate results in the ques-
tion understanding stage. Obviously,
they need to do
disambiguation in this step. For example, DEANNA [18]
proposes an integer
linear programming (ILP)-based
method to address the disambiguation issue. As we know,
ILP is a classical NP-hard problem. Then, in the query eval-
uation stage, the existing methods need to answer these
generated SPARQL queries. Answering SPARQL queriesACKNOWLEDGMENTSIn this paper, we propose a graph data-driven framework to
answer natural language questions over RDF graphs. Differ-
ent from existing work, we allow the ambiguity both of
phrases and structure in the question understanding stage.
We push down the disambiguation into the query evalua-
tion stage. Based on the query results over RDF graphs, we
can address the ambiguity issue efﬁciently. In other words,
we combine the disambiguation and query evaluation in an
the graph data-driven
uniform process. Consequently,
framework not only improves the precision but also speeds
up the whole performance of RDF Q/A system.Our work belongs to the ﬁrst category and differs from
existing systems in three points. First, different from tem-
plate-based works such as [17], [19], [20], [31], our method
does not adopt any manually deﬁned templates. To gap the
mismatch between natural language and the knowledge base,
[20] generates canonical utterances for each candidate logical
form of the given question N, then it ranks the pairs of canoni-
cal utterance and logical form based on a paraphrase model.
However, users should deﬁne logical form templates and the
generation rules ﬁrst. [31] mines millions of operators from
unlabeled data, then learns to compose them to answer ques-
tions using evidence from multiple knowledge bases. It still
uses predeﬁned templates to map questions to queries. Simi-
larly, [19] designs three query templates and try to match the
given question N to those templates, then generates and ranks
SPARQL queries of each matched template. However, both
the templates and the generation rules are heavily relied on
the particular dataset and could not handle some other ques-
tions. For example, none of above systems could answer true-
false questions like “Does Trump have any children?”. In con-
trast, our system does not rely on templates and could answer
more kinds of questions. We evaluate [19] on the QALD-6
benchmark and the results could be found in Table 7.8 CONCLUSIONTwo recent semantic parsing methods [21] and [22]
achieve the state-of-the-art precisions on WebQuestions
benchmark. [21] builds query graphs from question sen-
tence according to a state transition chain. It ﬁrst recognizes
a topic entity and an inference the relation between the topic
entity and the answer. Further it allows other entities to
restrict the answer node. The representation power of [21] is
limited because the ﬁnal query graph structure must be a
tree with diameter less than 3. [22] improves semantic
parsing via answer type inference. It transforms a question
to a “subject, relation, object” order by dependency parse
tree patterns and proposes a BLSTM model to predict the
answer type. Finally the answer type can be used to prune
the candidate logic forms generated by the semantic parsing
baseline. This approach cannot tackle the questions uncov-
ered by patterns or complex questions. Different from the
above systems, our approach has stronger representation
power as we do not restrict the query graph’s structure.The other category is information retrieval-based, where the
systems are not intended to parse the question to a formal
semantic interpretation.
they select candidate
Instead,
answers ﬁrst and then rank them by various methods [2],
[27], [28], [29], [30]. [29] utilizes subgraph embedding to pre-
dict the conﬁdence of candidate answers. [28] maximize the
similarity between the distributed representation of a ques-
tion and its answer candidates using Multi-Column Convo-
lutional Neural Networks (MCCNN), while [2] aims to
predicate the correct relations between topic entity and
answer candidates with text evidence.Third, our approach have stronger representation power
than most existing solutions. Information retrieval solutions
like [2], ﬁnd the topic entity and try to predicate the relation-
ship between the answer and the topic entity which can
only solve simple questions with one triple. For the ques-
tions have two entities, they utilize predeﬁned patterns in
dependency parse tree to decompose the complex question
to two simple question. However, the precision of such sys-
tem highly depends on the accuracy of the dependency
parse tree, which is pretty low when the question is com-
plex. In contrast, our work (especially NFF) is more robust
to the errors of dependency parse trees.The ﬁrst one is semantic parsing-based, where natural lan-
guage questions are translated into logical forms, such as
simple (cid:2)-DCS [17], [20], query graph [21], or executable
queries such as SPARQL [18], [19], [26]. [20] deﬁned a set of
logical form templates. DEANNA [18] builds a disambigua-
tion graph and reduces disambiguation as an integer linear
programming problem.equals to ﬁnding subgraph matches of query graphs Q over
RDF graph [32], which is also an NP-hard problem.basketball players that
are higher than 2 meters.Complex Aggregation9 (28 %) Q29: Show me allQ4: Who was on the
Apollo 11 mission?
Q55: In which countries do
people speak Japanese?
Q32: Who developed Slack?
Q80: How short is the
shortest active NBA player?5 (16 %) Q22: Which computer
scientist won an oscar?
10 (31 %) Q100: What is Batman’s
real name?Entity Mapping
Complex Aggregation5 (9 %)
9 (15 %)Relation MappingEntity MappingNodes Failure11 (18 %)soundtrack for Cameron’s
Titanic?Node Recognition
FailureRelation Failure35 (58 %)#(Ratio)
8 (25 %) Q27: Who composed theReason#(Ratio)Sample ExampleReasonSample ExampleTABLE 10
Failure Analysis of Relation-First FrameworkTABLE 11
Failure Analysis of Node-ﬁrst Framework836IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181969,” Commun. ACM, vol. 13, no. 1, pp. 15–30, Jan. 1970.[25] R. F. Simmons, “Natural language question-answering systems:[24] G. M. Mazzeo and C. Zaniolo, “Answering controlled natural lan-
guage questions on RDF knowledge bases,” in Proc. 19th Int. Conf.
Extending Database Technol., 2016, pp. 608–611.Dongyan Zhao received the BS, MS, and PhD
degree from Peking University in 1991, 1994,
and 2000, respectively. Now, he is a professor in
the Institute of Computer Science and Technol-
ogy of Peking University. His research interest is
on information processing and knowledge man-
agement,
including computer network, graph
database, and intelligent agent.data,” J. Web Sem., vol. 7, no. 3, pp. 154–165, 2009.[23] C. Bizer, et al., “DBpedia - a crystallization point for the web of[22] S. Yavuz, I. Gur, Y. Su, M. Srivatsa, and X. Yan, “Improving
semantic parsing via answer type inference,” in Proc. Conf. Empiri-
cal Methods Natural Language Process., 2016, pp. 149–159.[19] H. Bast and E. Haussmann, “More accurate question answering
on freebase,” in Proc. 24th ACM Int. Conf. Inf. Knowl. Manag., 2015,
pp. 1431–1440.
J. Berant and P. Liang, “Semantic parsing via paraphrasing,” in Proc.
52nd Annu. Meet. Assoc. Comput. Linguistics, 2014, pp. 1415–1425.
[21] W. Yih, M. Chang, X. He, and J. Gao, “Semantic parsing via staged
query graph generation: Question answering with knowledge
base,” in Proc. 53rd Annu. Meet. Assoc. Comput. Linguistics 7th Int.
Joint Conf. Natural Language Process. Asian Fed. Natural Language
Process., 2015, pp. 1321–1331.Haixun Wang received the bachelor’s and mas-
ter’s degrees in computer science from Shanghai
Jiao Tong University in 1994 and 1996, respec-
tively, and the PhD degree in computer science
from the University of California, Louisiana, in
2000. He joined Google Research, Mountain
View, California, in 2013. His research interests
include text analytics, natural language process-
ing, knowledge base, semantic network, artiﬁcial
intelligence, graph data management, etc.[20][18] M. Yahya, K. Berberich, S. Elbassuoni, M. Ramanath, V. Tresp,
and G. Weikum, “Natural language questions for the web of
data,” in Proc. Joint Conf. Empirical Methods Natural Language Pro-
cess. Computat. Natural Language Learn., 2012, pp. 379–390.Jeffrey Yu Xu has held teaching positions in the
Institute of Information Sciences an Electronics,
University of Tsukuba, and in the Department of
Computer Science, Australian National University,
Australia. Currently, he is professor in the Depart-
ment of Systems Engineering and Engineering
Management, Chinese University of Hong Kong,
Hong Kong. His current research interests include
graph database, graph mining, and social network
analysis.[16] P. Zhao and J. Han, “On graph query optimization in large
networks,” Proc. VLDB Endowment, vol. 3, no. 1, pp. 340–351, 2010.
J. Berant, A. Chou, R. Frostig, and P. Liang, “Semantic parsing on
freebase from question-answer pairs,” in Proc. Conf. Empirical
Methods Natural Language Process., 2013, pp. 1533–1544.[17]Joachims, “Optimizing search engines using clickthrough
data,” in Proc. ACM Conf. Knowl. Discovery Data Mining, 2002,
pp. 133–142.[15] T.mation Retrieval. New York: Cambridge Univ. Press, 2008.[14] C. D. Manning, P. Raghavan, and H. Sch€utze, Introduction to Infor-[13] A. Fader, S. Soderland, and O. Etzioni, “Identifying relations for
open information extraction,” in Proc. Conf. Empirical Methods Nat-
ural Language Process., 2011, pp. 1535–1545.Lei Zou received the BS and PhD degrees in
computer science from the Huazhong University
of Science and Technology (HUST), in 2003 and
2009, respectively. Now, he is an associate pro-
fessor in the Institute of Computer Science and
Technology at Peking University. He is also a fac-
ulty member in the Big Data Center at Peking
University and the Beijing Institute of Big Data
Research. His research interests include graph
database and semantic data management.[12] N. Nakashole, G. Weikum, and F. M. Suchanek, “PATTY: A tax-
onomy of relational patterns with semantic types,” in Proc. Joint
Conf. Empirical Methods Natural Language Process. Comput. Natural
Language Learn., 2012, pp. 1135–1145.[10] X. Ling, S. Singh, and D. S. Weld, “Design challenges for entity link-
ing,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 315–328, 2015.
[11] N. Nakashole, G. Weikum, and F. M. Suchanek, “Discovering and
exploring relations on the web,” Proc. VLDB Endowment, vol. 5,
no. 12, 2012.links,” Trans. Assoc. Comput. Linguistics, vol. 3, pp. 145–156, 2015.[9] A. Chisholm and B. Hachey, “Entity disambiguation with web[8] V. I. Spitkovsky and A. X. Chang, “A cross-lingual dictionary for
english wikipedia concepts,” in Proc. 8th Int. Conf. Language
Resources Eval., 2012, pp. 3168–3175.Sen Hu received the BS degree in computer sci-
ence and technology from the Beijing University
of Posts and Telecommunications in 2015. He is
currently working toward the PhD degree in the
Institute of Computer Science and Technology at
Peking University, focusing on knowledge graph
and question answering.dencies manual,” (2016).
stanford.edu/software/dependencies_manual.pdf[7] M.-C. de Marneffe and C. D. Manning, “Stanford typed depen-
[Online]. Available: https://nlp.[6] W. M. Soon, H. T. Ng, and D. C. Y. Lim, “A machine learning
approach to coreference resolution of noun phrases,” Comput. Lin-
guist., vol. 27, no. 4, pp. 521–544, 2001.[31] A. Fader, L. Zettlemoyer, and O. Etzioni, “Open question answering
over curated and extracted knowledge bases,” in Proc. 20th ACM
SIGKDD Int. Conf. Knowl. Discovery Data Mining, 2014, pp. 1156–1165.
[32] L. Zou, J. Mo, L. Chen, M. T. €Ozsu, and D. Zhao, “gStore: Answer-
ing SPARQL queries via subgraph matching,” Proc. VLDB Endow-
ment, vol. 4, no. 8, pp. 482–493, 2011.[5] D. Deng, G. Li, J. Feng, Y. Duan, and Z. Gong, “A uniﬁed frame-
work for approximate dictionary-based entity extraction,” VLDB
J., vol. 24, no. 1, pp. 143–167, 2015.[4] M. Yahya, K. Berberich, S. Elbassuoni, and G. Weikum, “Robust
question answering over the web of linked data,” in Proc. 22nd
ACM Int. Conf. Inf. Knowl. Manage., 2013, pp. 1107–1116.[30] X. Yao and B. V. Durme, “Information extraction over structured
data: Question answering with freebase,” in Proc. 52nd Annu.
Meet. Assoc. Comput. Linguistics, 2014, pp. 956–966.[1] V. Lopez, C. Unger, P. Cimiano, and E. Motta, “Evaluating question
answering over linked data,” J. Web Sem., vol. 21, pp. 3–13, 2013.
[2] K. Xu, S. Reddy, Y. Feng, S. Huang, and D. Zhao, “Question answer-
ing on freebase via relation extraction and textual evidence,” in Proc.
54th Annu. Meet. Assoc. Comput. Linguistics, 2016, pp. 2326–2336.
J. Bao, N. Duan, M. Zhou, and T. Zhao, “Knowledge-based ques-
tion answering as machine translation,” in Proc. 52nd Annu. Meet.
Assoc. Comput. Linguistics, 2014, pp. 967–976.[29] A. Bordes, S. Chopra, and J. Weston, “Question answering with
subgraph embeddings,” in Proc. 2014 Conf. Empirical Methods Nat-
ural Language Process., 2014, pp. 615–620.[3][27] A. P. B. Veyseh, “Cross-lingual question answering using common
semantic space,” in Proc. TextGraphs@NAACL-HLT: 10th Workshop
Graph-based Methods Natural Language Process., 2016, pp. 15–19.
[28] L. Dong, F. Wei, M. Zhou, and K. Xu, “Question answering over free-
base with multi-column convolutional neural networks,” in Proc. 53rd
Annu. Meet. Assoc. Comput. Linguistics 7th Int. Joint Conf. Natural Lan-
guage Process. Asian Fed. Natural Language Process., 2015, pp. 260–269.REFERENCESand NSFC under grants 61622201, 61532010, and 61370055. Jef-
frey Xu Yu was supported by the Research Grants Council of
the Hong Kong SAR, China No. 14221716 and No. 12258116.[26] C. Unger, L. B€uhmann, J. Lehmann, A.-C. N. Ngomo, D. Gerber,
and P. Cimiano, “Template-based question answering over RDF
data,” in Proc. World Wide Web, 2012, pp. 639–648.HU ET AL.: ANSWERING NATURAL LANGUAGE QUESTIONS BY SUBGRAPH MATCHING OVER KNOWLEDGE GRAPHS8371041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 20181041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.E-mail: haixun@google.com.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2)E-mail: {husen, zhaody}@pku.edu.cn.(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of thePhrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.existing solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).AS more and more structured data become available on1 INTRODUCTIONÇIndex Terms—RDF, graph database, question answeringAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Sen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAnswering Natural Language Questions by
Subgraph Matching over Knowledge Graphs824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.河南财经政法大学学报年第总第期期(3)1912022人工智能辅助检察办案的应用与展望张永进河北工程大学文法学院河北邯郸,056038)(人工智能检要∗∗ 摘+,“技术环境变革等诸多挑战
检察品质提升
检察机关面临办案压力增长
当前
:
、
、
,
迎接挑战的重要方法
被视为抓住机遇
。
、人工智能辅助
机器学习和算法技术
依托人工智能的信息化
,
、察
”并分为信息化辅助办案
检察办案得以快速发展
、
,弱智能化辅助办案和强智能化辅助办案等模式
。然而
,
运行维度上的规范匮现行人工智能辅助检察办案存在数据维度上的信息短缺
、对此应当通过开放办案数据算法维度上的技术风险
、
化解算法风险增强制度供给统筹应用维度上的发展失衡等问题
乏
。
、,、、、开发应用等机制实现人工智能与检察办案的深度融合促进检察办案与检察权运行的现代化,。,
人工智能检察辅助办案大数据算法关键词:;;;中图分类号文献标识码;
文章编号:D925:A:2095-3275(2022)03-0033-10伴随着大数据云计算和智能制造的发展人工智能已经深入到包括司法活动在内的经济社会生,、活的各个领域虽然有关人工智能法学研究还存在诸多争议但是在推进人工智能司法应用上并无根。,[1]本分歧习近平总书记指出推动大数据人工智能等科技创新成果同司法工作深度融合“年月。
中央全面深化改革委员会通过的、
关于加强科技创新支撑平安中国建设的意见”
指出。 2019
在司法9,:“》《领域充分运用人工智能大数据区块链等新兴技术加快智慧司法建设和司法领域科技创新体系建、、,设[2] 与此同时近年来在检察机关制定的发展规划文件中均涉及人工智能司法应用主题年。 2020,。”
月,
最高人民检察院下发的十四五时期检察工作发展规划指出检察机关将形成信息动态感知,《 “”、8
知识深度学习数据精准分析业务智能辅助网络安全可控的》
,
大平台共享大系统共治大数据慧治、、、”、“、
的信息化格局[3]人工智能辅助检察办案成为检察实务和研究中的热点话题由此。,。问题的提出一、近年检察机关面临诉讼爆炸的办案压力公平正义的社会需求科技进步的发展环境始终将科,、,技强检作为优化检察产品满足社会需求、
有效应对挑战的重要法宝从最初的设备科技化建设到检、。、察信息化发展再到当前的智慧检务尽管主题不同内容有别但在上述过程中始终坚持将检察办案与,、,现代科技发展共振与公正高效司法需求同步的改革目标现代科学技术的检察应用不断深化。,、案件增量指引下的效率提升挑战司法效率反映一定时期司法投入与司法产出的比例关系1.效率本身是经济学上的用语。
但并非专属经济学领域在当今法治发展中具有重要影响从。
迟来的公,。“,
待到草儿青青正并非公正马儿已经饿死等法谚上看即反映了人民对司法效率的追求对于检察” “”,。,收稿日期∗∗∗基金项目:2021-06-22
本文是年河北省社科基金项目河北检察办案中的人工智能应用研究项目编号的阶段性成果:” (:HB19FX012)。“作者简介2019
男张永进河北工程大学文法学院讲师法学博士研究方向为诉讼法学司法制度:,,,,、。33824IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 30, NO. 5, MAY 2018Answering Natural Language Questions by
Subgraph Matching over Knowledge GraphsSen Hu , Lei Zou , Jeffrey Xu Yu , Haixun Wang, and Dongyan ZhaoAbstract—RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by
RDF. To answer a natural language question, the existing work takes a two-stage approach: question understanding and query
evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most
common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic
framework to answer natural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a
semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is
reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when
matches of query are found. The cost of disambiguation is saved if there are no matching found. More speciﬁcally, we propose two
different frameworks to build the semantic query graph, one is relation (edge)-ﬁrst and the other one is node-ﬁrst. We compare our
method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experiments conﬁrm that our method not
only improves the precision but also speeds up query performance greatly.Index Terms—RDF, graph database, question answeringÇ1 INTRODUCTIONAS more and more structured data become available onexisting solutions is on question understanding. Let us con-
sider a running example in Fig. 1. The RDF dataset is given
in Fig. 1a. Given a natural language question N1 ¼ “What is
the budget of the ﬁlm directed by Paul Anderson?”, it is ﬁrst
interpreted as a SPARQL query that is evaluated to get the
answers (as shown in Fig. 1b).1.1 Motivation
The inherent hardness of RDF Q/A lies in the ambiguity of
un-structured natural language question sentences. Gener-
ally, there are two main challenges.the web, the question of how end users can access this
body of knowledge becomes of crucial importance. As a de
facto standard of a knowledge base, Resource Description
Framework(RDF) repository is a collection of triples, denoted
as hsubject, predicate, objecti, and can be represented as a
graph, where subjects and objects are vertices and predicates
are edge labels. Although SPARQL is a standard way to
access RDF data, it remains tedious and difﬁcult for end users
because of the complexity of the SPARQL syntax and the RDF
schema. An ideal system should allow end users to proﬁt
from the expressive power of Semantic Web standards (such
as RDF and SPARQLs) while at the same time hiding their
complexity behind an intuitive and easy-to-use interface [1].
Therefore, RDF question/answering (Q/A) systems have
received wide attention in both natural language processing
(NLP) [2], [3] and database areas [4].Phrase Linking. A natural language phrase wsi may have
several meanings, i.e., wsi correspond to several semantic
items in RDF graph G. As shown in Fig. 1b, the entity phrase
“Paul Anderson” can map to three persons hPaul_Anderson_
(actor)i, hPaul_S._Andersoni and hPaul_W._S._Andersoni.
For a relation phrase, “directed by” also refers to two possible
predicates hdirectori and hwriteri. Sometimes a phrase needs
to be mapped to a non-atomic structure in knowledge graph.
For example, “uncle of” refers to a predicate path (see
Table 4). In RDF Q/A systems, we should eliminate “the
ambiguity of phrase linking”.Generally, there are two stages in RDF Q/A systems:
question understanding and query evaluation. Existing systems
in the ﬁrst stage translate a natural language question N
into SPARQLs [1], and in the second stage evaluate all
SPARQLs translated in the ﬁrst stage. The focus of the(cid:2) S. Hu and D. Zhao are with Peking University, Beijing 100080, China.E-mail: {husen, zhaody}@pku.edu.cn.(cid:2)(cid:2) L. Zou is with Peking University, Beijing 100080, China, and the Beijing
Institute of Big Data Research., Beijing, China. E-mail: zoulei@pku.edu.cn.
J.X. Yu is with The Chinese University of Hong Kong, China.
E-mail: yu@se.cuhk.edu.hk.(cid:2) H. Wang is with Facebook, Menlo Park, CA 94025.E-mail: haixun@google.com.Composition. The task of composition is to construct cor-
responding query or query graph by assembling the identi-
ﬁed phrases.
In the running example, we know the
predicate hdirectori is to connect subject hﬁlmi and object
hPaul_W._S._Andersoni; consequently, we generate a triple
h?ﬁlm, director, Paul_W._S._Andersoni. However, in some
cases, it is difﬁcult to determine the correct subject and
object for a given predicate, or there may exist several possi-
ble query graph structures for a given question sentence.
We call it “the ambiguity of query graph structure”.Manuscript received 19 Feb. 2017; revised 11 Oct. 2017; accepted 13 Oct.
2017. Date of publication 26 Oct. 2017; date of current version 30 Mar. 2018.
(Corresponding author: Lei Zou.)
Recommended for acceptance by A. Singh.
For information on obtaining reprints of this article, please send e-mail to:
reprints@ieee.org, and reference the Digital Object Identiﬁer below.
Digital Object Identiﬁer no. 10.1109/TKDE.2017.2766634In this paper, we focus on how to address the two chal-
lenges. Different from existing solutions that try to solve
ambiguity in the question understanding stage, we propose
to combine disambiguation (for both phrase linking and
query graph construction) and query evaluation together.1041-4347 (cid:1) 2017 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See ht_tp://www.ieee.org/publications_standards/publications/rights/index.html for more information.